---
title: "AOH development"
author: "Christopher L. Crawford"
date: "2022-11-28"
output: html_document
editor_options: 
  chunk_output_type: console
---

# AOH dev



## {terra} AOH dev (based on Yiwen's script)

```{r load-map-files-AOH}
#### -------- load habitat map ---------- ####

### Loading suitable habitats from IUCN/IIASA #####
# iucnHabitatClass <- raster("~/Dropbox/PostDoc4_Princeton/Species Traits/iucn_habitatclassification_composite_lvl2_ver003_resampled.tif")

# jung_l2 <- rast(paste0(p_dat, "Habitats/Jung_GlobalHabitatTypes/iucn_habitatclassification_composite_lvl2_ver004.tif"))


# if Jung map:
habitat_map <- rast(paste0(p_derived, "site_jung/", site_df$site[site_index], "_jung_l2_30.tif"))

# if Yin et al. 2020 LC maps
habitat_map <- lc[[site_index]][[yr_index]]
plot(habitat_map)

# load elevation raster list

elevation_map <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "elevation/", 
              site_df$site[i], "_srtm_crop.tif")
       )
  })

site_area_ha <- lapply(
  list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
  function(i) rast(i)
)
names(site_area_ha) <- site_df$site

```

```{r aoh-dev}
# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]
species_list[, 3]
aoh_df <- tibble(species = species_list[, "binomial"],
                  IUCN_AOO = NA,
                  IUCN_AOH = NA)



i <- 1
for(i in seq_along(species_list$binomial)) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  
  # ---- extract species range polygons at the site ---- #
  
x1 <- species_ranges[species_ranges$binomial == paste0(species_list[i, "binomial"]),] # select a subset of species range polygons based on binomial
species_name <- "Lithobates palustris"

x1 <- vert_sites[vert_sites$binomial == "Lithobates palustris", ] %>% 
  st_cast() # update all features to multipolygon, for 


# ---- crop the land cover map in question to the extent of the range map ---- #
tic()
y1 <- terra::crop(#iucnHabitatClass,
  habitat_map[[11]], # site_jung_l2_30[[11]],
  x1) #%>% raster()
toc()

site_area_ha[[site_index]]



# ---- turn the species range polygons (sf) into a raster ---- #
# this involves creating a template raster to match the dimensions of the IUCN Habitat map, 
# and then using fasterize().
# if using this method, must first convert all sf objects to the same type (i.e., multipolygon)
# I can also do this using terra::rasterize(), but it's slightly slower. (~ 1 second for Wisconsin)

tic()
template_raster1 <- raster::raster(
  resolution = terra::res(site_area_ha[[site_index]]),
  ext = raster::extent(terra::ext(site_area_ha[[site_index]])[1:4]),
  ncols = terra::ncol(site_area_ha[[site_index]]),
  nrows = terra::nrow(site_area_ha[[site_index]]))


template_raster <- raster::raster(
  resolution = terra::res(y1),
  ext = raster::extent(terra::ext(y1)[1:4]),
  ncols = terra::ncol(y1),
  nrows = terra::nrow(y1))

x2 <- fasterize(x1, 
                template_raster# 
                # raster(y1)
                ) %>% rast()

x21 <- fasterize(x1,
                template_raster1# 
                # raster(y1)
                ) %>% rast()

toc()

plot(x2)
ext(x2)
ext(lc$wisconsin$y2017)

# writeRaster(x2,
            # filename = paste0(p_tmp, "random_tmp.tif"), 
            # overwrite=TRUE)
# x2 <- rast(paste0(p_tmp, "random_tmp.tif"))


# fasterize is faster than terra::rasterize(), but the step of writing the raster to file, then reloading as SpatRaster takes much longer.
# tic()
# x2t <- terra::rasterize(vect(x1), y1, # must convert sf to spatvector:
#                         #field="", 
#                         #fun = length#, sum = FALSE, 
#                         # filename = paste0(p_derived, "aoh/tmp/rasterize_tmp.tif"), overwrite=TRUE
#           )
# toc()
# 
# plot(x2t)


 # ---- update cell values to mask ---- #

# tic()
# x3 <- calc(x2_r, function(x) {x[!is.na(x)] <- 0; return(x)}) # passes a function setting all of the cell values that are not NAs to 0
# toc()

tic()
x3 <- subst(x2, 1, 0) # change cell value from 1 to 0.
# x3 <- x2 - 1 # can also do this, maybe just very slightly faster
toc()

# Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
# expanse() is much faster! But... it doesn't work with large rasters of the extent of some of my sites.

# aoh_df$IUCN_AOO[i] <- expanse(x2, unit = "km") # in km2

print(aoh_df, n = 30)

tic()
x2_area_test <- x3 %>%
  terra::cellSize(., unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE) %>% 
  as.numeric()

x2_area_test
toc()

tic()
x2_area_test1 <- terra::cellSize(x21, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
x2_area_test1
toc()


plot(x2)
plot(x3 + site_area_ha[[site_index]])
tic()
global(x3 + site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()
tic()
global(x2 * site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()

x2 * site_area_ha[[site_index]] %>%
  global(., fun = "sum", na.rm = TRUE)


# by calculating cellSize()
tic()
x2_area <- 
  terra::cellSize(x2, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

aoh_df$IUCN_AOO[i] <- x2_area

site_area_ha[[11]]
plot(site_area_ha[[11]])

# mask the IUCN habitat map to the range raster
y2 <- x3 + y1
# y2 <- app(c(x3, y1), sum) # the same, but slightly slower
# y2 <- terra::mask(x3, y1)

plot(y2)

# ------------------------------------------------------------------------- #
### Habitat Filter ###
# ------------------------------------------------------------------------- #
species_list[i, "binomial"]

z1 <- habitat_prefs %>% 
  filter(binomial == species_name,
         suitability == "Suitable") # extract the habitat classifications for the species in question

suitable_habitat_codes <- iucn_crosswalk %>% 
  filter(code %in% unique(z1$code)) %>%
  # .$lc %>% 
  .$map_code %>% 
  unique() # extract the lc code from my crosswalk that correspond to the IUCN habitat codes

suitable_habitat_rcl <- iucn_crosswalk %>% 
  filter(code %in% unique(z1$code))


# my thoughts on how to do the land cover translation
# I have decided what proportion of "forest" go into what habitat type at each site. I don't know where though, so I'll just attribute this proportionally, evenly across the whole site. So, what I should do is apply this proportionally *after* I have clipped out the suitable habitats. 

# So, I need to build a translator for the IUCN habitat prefs, and then extract by that.
# I can then, in a separate step, multiply by the proportion in question.
# I can calculate the area in each habitat type, and if a species has a subset of one habitat type that is suitable (e.g., grassland, but not savanna or shrubland), I will then adjust the habitat area down by the proportion of my lc "grassland (4)" that is considered the IUCN habitat type grassland at that site. 

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_tmp, "aoh_tmp.tif"),
           overwrite = TRUE)
toc()  # 1.894  seconds

# calculate area after habitat filter
tic()
y3_area <- 
  terra::cellSize(y3, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

plot(y3)
# ------------------------------------------------------------------------- #
### Elevation Filter ###
# ------------------------------------------------------------------------- #
elevation_map
elevation_map[[site_index]]

elevation_mask <- elevation_map[[site_index]] + y3
plot(elevation_mask)

y3_r <- raster(elevation_mask)

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_tmp, "aoh_tmp.tif"),
           overwrite = TRUE)
toc()

elevation_mask
elevation_rcl <- elevation_prefs %>% filter(binomial == species_name)

e1 <- elevation_prefs[elevation_prefs$binomial==paste0(species_list[i,1]), ]

terra::app(y3, )
ele6_t <- elevation_mask
plot(ele6_t)



tic()
ele6_rcl <- classify(elevation_mask, 
                     rcl = tibble(from = el_rcl$elevation_lower,
                                  to = el_rcl$elevation_upper, 
                                  becomes = 0),
                     include.lowest = TRUE, right = TRUE)
toc() # sweet! much faster.

plot(ele6_rcl, colNA = "pink")

# mask the range polygon by the habitat mask and the elevation mask


print(i)
write.csv(aoh_df,"~/Dropbox/PostDoc4_Princeton/Species Traits/FutureAOH.csv")
}
```

```{r aoh-direct-testing}

# cc_AOH_terra <- function(index,
#                        site_index,
#                        year_index,
#                        calc_lc = TRUE) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  tic.clearlog()
  tic(paste0("run ", index, ":", site_df$site[site_index], ", ", year_index))
  aoh_test_mg
  aoh_test_s
  index <- 3
  site_index <- 9 # 6 = mato_grosso
  year_index <- 2010:2017
  calc_lc <- TRUE
  calc_AOO <- TRUE
  
  species_ranges <- vert_sites %>%
  filter(vert_class != "gard",
         site == site_df$site[site_index]) # filter to just the site in question
  
  species_list <- species_ranges %>% st_drop_geometry() %>%
    select(site, vert_class, binomial) %>% unique() %>%
    arrange(site, vert_class, binomial)

  species_name <- species_list$binomial[index]
  # species_name <- "Lithobates palustris"
  
  habitat_map <- if (calc_lc) {
    lc[[site_index]][[paste0("y", year_index)]]
  } else {
    rast(paste0(p_derived, "site_jung/", site_df$site[site_index], "_jung_l2_30.tif"))
  }
  
  elevation_map <- rast(paste0(p_derived, "elevation/", site_df$site[site_index], "_srtm_crop.tif"))
  
  # ---- extract species range polygons at the site ---- #
  range_sf <- st_cast(species_ranges[species_ranges$binomial == species_name, ]) # select a subset of species range polygons based on binomial, and update all features to multipolygon, for fasterize()
  plot(range_sf$geometry)
  
  # plot(lc[[site_index]][[year_index]])
  plot(habitat_map)
  plot(range_sf$geometry, border = "red", add = TRUE)

  # ---- turn the species range polygons (sf) into a raster ---- #
    
  range_t <- 
    fasterize(range_sf,
              raster::raster(resolution = terra::res(habitat_map),
                             ext = raster::extent(terra::ext(habitat_map)[1:4]))
              ) %>% 
    rast() %>% # convert to SpatRaster 
    subst(1, 0) # update cell values from 1 to 0.
  
  plot(range_t)
  # ------------------------------------------------------------------------- #
  ### Habitat Filter ###
  # ------------------------------------------------------------------------- #
  z1 <- habitat_prefs %>% 
    filter(binomial == species_name,
           suitability == "Suitable") # extract the habitat classifications for the species in question
  
  habitat_prefs %>% 
    filter(binomial == species_name) %>%
    arrange(suitability) %>% print(n = 25)
  
  habitat_details %>% filter(binomial == species_name) %>% .$habitat
  
  # extract the lc codes from my crosswalk that correspond to the IUCN habitat codes
  suitable_habitat_rcl <- iucn_crosswalk %>% 
    filter(code %in% unique(z1$code))
  
  freq(habitat_map)
  iucn_crosswalk %>% print(n = 42)
  plot(site_jung_l2$mato_grosso, breaks = c(105.9,106.1))
  plot(site_jung_l2_30$mato_grosso, breaks = c(105.9,106.1))
  plot(site_jung_l2_30$mato_grosso, breaks = c(506.9,507.1))
  plot(site_jung_l2$mato_grosso, breaks = c(405.9,406.1))
  freq(site_jung_l2_30$mato_grosso)
  
  # reclassify habitat raster to 
  habitat_map1 <- lc[[site_index]][["y2017"]]
  habitat_map <- lc[[8]]#[[paste0("y", 2010:2017)]]
  
  tic()
  habitat_map_rcl <- 
    classify(
      # habitat_map1,
      habitat_map,
      rcl = select(suitable_habitat_rcl, 
                   is = ifelse(calc_lc, "lc", "map_code")
                   ) %>% unique() %>% 
               mutate(becomes = 0),
             othersNA = TRUE,
             # filename = paste0(p_tmp, "aoh_tmp.tif"),
             overwrite = TRUE)
  toc() # 5 seconds for 1, 8.178 s for 3, 11 s for 8, 28 seconds s for all 31
  
  31*5
  28
  plot(habitat_map_rcl[[1:4]])
  
  plot(habitat_map_rcl)
  # ------------------------------------------------------------------------- #
  ### Elevation Filter ###
  # ------------------------------------------------------------------------- #
  elevation_prefs_rcl <- elevation_prefs %>% filter(binomial == species_name)
  
  elevation_map_rcl <- 
    classify(
      elevation_map,
      rcl = tibble(from = elevation_prefs_rcl$elevation_lower,
                   to = elevation_prefs_rcl$elevation_upper,
                   becomes = 0),
      include.lowest = TRUE, right = TRUE)
  
  plot(elevation_map_rcl, colNA = "pink")
  
  # mask the range polygon by the habitat mask and the elevation mask
  plot(range_t)
  tic()
  aoh <- range_t + elevation_map_rcl
  aoh <- aoh + habitat_map_rcl
  toc() # 26 seconds for all 31, # 1.4 for 1 layer 
  

  # ------------------------------------------------------------------------- #
  ### Calculate areas:
  # ------------------------------------------------------------------------- #
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  if (calc_AOO) {
    range_aoo_ha <- 
    terra::cellSize(range_t, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>% .$sum
    }
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  tic()
  range_aoh_ha <- 
    terra::cellSize(aoh, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>% .$sum
  toc() # 1.8 seconds for 1, 8 seconds for 5 layers, 40 s for all 31
  
  toc(log = T)
  
  aoh_tmp <- 
    tibble(site = site_df$site[site_index],
           binomial = species_name,
           year = year_index,
           # IUCN_aoo_ha = range_aoo_ha,
           IUCN_aoh_ha = range_aoh_ha)
  
  if (calc_AOO) {
    aoh_tmp <- aoh_tmp %>%
      mutate(IUCN_aoo_ha = range_aoo_ha)
  }
  
  if (include_time) {
    aoh_tmp <- aoh_tmp %>%
      mutate(time = 
               tic.log(format = F) %>% bind_rows() %>%
               mutate(time = toc - tic) %>% .$time)
  }
  
  # Note: the slight difference between areas before and after habitat filtering is
  # the result of a small amount of 0s added to the Yin et al. 2020 land cover maps. 
  
  cat("calculated AOH for", species_name, "=", range_aoh_ha, "ha", fill = TRUE)
  aoh_tmp

```

```{r aoh-function-testing}

# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]

aoh_df <- tibble(site = site_df$site[site_index],
                 species = species_list[, "binomial"],
                 year = yr_index + 1986,
                 IUCN_aoo_ha = NA,
                 IUCN_aoh_ha = NA)


# things to load:
load(file = paste0(p_derived, "species_ranges/vert_sites.RData"), verbose = TRUE)

# for a specific site, compile list of species
species_list
aoh_df

4000 * 28 /60 / 60 / 11 # hours /11

# what if I do the lc maps in batches, do I save time? 



tic("test1")
toc(log=T)
tic("test2")
toc(log=T)

tic.clearlog()
tic.log(format = T) %>% unlist() 
tic.log(format = F) %>% bind_rows() %>%
  mutate(time = toc - tic) %>% .$time


aoh_test <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()

seq_along(species_list$binomial)

aoh_test2 <- lapply(1:2, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()

aoh_test_mg <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 6, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()


aoh_test_s2 <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2017, calc_lc = FALSE)
}) %>% bind_rows()

aoh_test_s[1:5,]
aoh_test_s2


aoh_test_lc_s <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2017, calc_lc = TRUE)
}) %>% bind_rows()
aoh_test_lc_s
aoh_tmp

vert_sites %>% filter(binomial == "Rana chensinensis", 
                      site == "shaanxi" ) %>% 
  st_geometry() %>% 
  plot(add = T, col = "red")

site_sf %>% filter(site == "shaanxi" ) %>% st_geometry() %>% plot()

aoh_test_s1

aoh_test_mg
habitat_details %>% filter(binomial == "Adenomera andreae") %>% .$habitat
habitat_prefs %>% filter(binomial == "Adenomera andreae") %>% .$habitat

synonyms 
species_synonyms %>% filter(binomial == "Adenomera andreae")

aoh_test4 <- 
  lapply(1:11, function(site_index) {
    tmp <- lapply(1, function(i) {
      cc_AOH_terra(index = i, site_index = site_index, year_index = 31, calc_lc = FALSE)
      }) %>% bind_rows()
  }) %>% bind_rows()
  

aoh_test_mult_s <- 
  lapply(3, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2015:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()

aoh_test_mult_s %>% tail

aoh_test_mult_s




aoh_tmp
aoh_test_mult_s

aoh_test_s


aoh_test3
aoh_test4

# between 24-32 seconds

# run 1:wisconsin, 31: 29.43 sec elapsed
# calculated AOH for Acris crepitans = 630173.7 ha
# run 2:wisconsin, 31: 32.413 sec elapsed
# calculated AOH for Ambystoma laterale = 1962498 ha
# run 3:wisconsin, 31: 26.02 sec elapsed
# calculated AOH for Ambystoma maculatum = 1260343 ha
# run 4:wisconsin, 31: 24.47 sec elapsed
# calculated AOH for Ambystoma tigrinum = 905840.2 ha
# run 5:wisconsin, 31: 25.846 sec elapsed
# calculated AOH for Anaxyrus americanus = 2938938 ha
# > aoh_test

aoh_test
aoh_df[1:5,]

aoh_test4

write_csv(aoh_test,
          file = paste0(p_derived, "aoh/aoh_df.csv"))

```



```{r remove-0s-from-lc}

# this doesn't really matter! I'm just comparing the AOH anyways...

tic()
lc_clean <- subst(lc[[8]][[1:4]], from = 0, to = NA_real_)
toc()
# 63 seconds for just four layers of the biggest site. 

compareGeom(lc_clean, lc[[9]])

df1 <- freq(lc_clean)
df2 <- freq(lc[[9]][[1:4]])

df1 %>% as_tibble() %>% arrange(value)
df2 %>% as_tibble() %>% arrange(value)

lc_clean <- classify(
      lc[[9]][[1:4]],
      rcl = tibble(from = elevation_rcl$elevation_lower,
                   to = elevation_rcl$elevation_upper,
                   becomes = 0),
      include.lowest = TRUE, right = TRUE)

plot(lc[[9]][[1]], breaks = c(-0.1, 0.1), maxcell = 1e8)



terra::trim()

plot(lc_clean)

tic()
lc_clean2 <- trim(lc[[9]][[1:4]], value = 0)
toc()


df3 <- freq(lc_clean2)

df3 %>% as_tibble() %>% arrange(value)

```

# {data.table} AOH

```{r load-files-for-dt-AOH}
# set parameters:

index <- 3
site_df
site_index <- 3
year_index <- 2011:2017
calc_lc <- TRUE
include_time <- TRUE
range_maps <- species_ranges

# ------------------------------------------------------------------------- #
### load in required elements prior to running the data.table function
# ------------------------------------------------------------------------- # 
# all the loading of the habitat maps before:
tic("load layers")

  hab_dt <- fread(input = paste0(p_dat_derived, "input_data.tables/",
                                 site_df$site[site_index], ".csv"))

  elevation_map <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "elevation/", 
              site_df$site[i], "_srtm_crop.tif")
       )
  })
  
  site_area_ha <- lapply(
    list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
    function(i) rast(i)
    )

  el_area_dt <- spatraster_to_dt(
    spt = c(site_area_ha[[site_index]],
            elevation_map)#, xy_switch = FALSE
    )

  setnames(el_area_dt, 
           old = grep("area", names(el_area_dt), value = T), 
           new = "area_ha")
  
  stopifnot(
    all.equal(hab_dt$x, el_area_dt$x),
    all.equal(hab_dt$y, el_area_dt$y)
    )
  
  # combine hab_dt and el_area_dt into a single data.table
  hab_dt[, ':='(area_ha = el_area_dt$area_ha,
                elevation = el_area_dt$elevation)]
  
  rm(el_area_dt) # to save memory on my machine.

  toc() #


```



```{r compare-results-dt-AOH}
tic("terra method")
aoh_terra_test_mult_s <- 
  lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 1987:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()
toc()

# tic()
# one_sp <- cc_AOH_terra(index = 3, site_index = 9, year_index = 2017, 
#              calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
# toc()

tic("data.table method")
aoh_dt_test_mult_s <- lapply(1:5, function(i) {
  cc_AOH_data.table(index = i, site_index = 9, year_index = 1987:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()

# times: 
# terra: 555.635 s
# data.table: 262.04
aoh_terra_test_mult_s$time %>% unique %>% sum /
  aoh_dt_test_mult_s$time %>% unique %>% sum
# 2.11 x faster to do it with data.table

# compare results
aoh_terra_test_mult_s
aoh_dt_test_mult_s %>% 
  select(site, binomial, year, IUCN_aoh_ha, time) %>% unique

# they match
identical(aoh_terra_test_mult_s$IUCN_aoh_ha, aoh_dt_test_mult_s %>% 
  select(site, binomial, year, IUCN_aoh_ha, time) %>% unique %>%
  .$IUCN_aoh_ha)


# 3 three heavy lifts: hab rcl, elevation rcl, and the final masking

# time comparison 124 for terra function vs. 159 for data.table method
# now, having switched the order of the data.table filtering, the data.table method takes closer to 50 seconds.
```

```{r adjust-by-lc-prop}

# what proportion of the area in each of my four land cover codes is in 
# so, if a species 
z1

adj_df <- jung_hab_type_area_df %>%
  filter(site == site_df$site[site_index],
         code %in% unique(z1$code)) %>%
  group_by(lc) %>%
  summarise(adjustment = sum(prop_lc))

jung_hab_type_area_df %>% select(-IUCNLevel) %>%
  filter(site == site_df$site[9])


aoh_dt_test_mult_s
aoh_dt_test_mult_s

aoh_dt_test_mult_s <- aoh_dt_test_mult_s %>% 
  as_tibble() %>% 
  left_join(adj_df, by = "lc") %>% 
  mutate(adj_area_ha = area_ha * adjustment)

aoh_dt_test_mult_s %>% 
  select(-IUCN_aoh_ha) %>%
  left_join(aoh_dt_test_mult_s %>% 
              group_by(site, binomial, year) %>%
              summarise(IUCN_aoh_ha = sum(area_ha),
                        adj_IUCN_aoh_ha = sum(adj_area_ha)),
            by = c("site", "binomial", "year")
  )

df_tmp

```

```{r test-wisc}
# testing with Wisconsin data.table
# FYI it takes about 45 seconds to load all the data required at the start.
hab_dt

# too memory intensive.

tic("terra method")
aoh_terra_test_mult_w <- 
  lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 1987:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()
toc()

tic("data.table method")
aoh_dt_test_mult_w <- lapply(1:5, function(i) {
  cc_AOH_data.table(index = i, site_index = 11, year_index = 1987:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()

aoh_dt_test_mult_w %>% select(site, binomial, time) %>% unique() %>%
  mutate(time_p_run = time/31)


```


## Melting data.tables

Can I gain speed by melting the data.table in order to get the area by year and land cover code in one single data.table call? 
Ultimately, no. 
This method seems to be slower by a factor of 1.3. 
Good to have learned how to melt data.tables, but table this method for now.

```{r melt-dt}
# in order to use the by function correctly, I need to melt the data.table from wide to long format, and have a column for year. 
hab_dt

# add a new index, drop x and y
hab_dt[, key := 1:nrow(.SD)]
hab_dt[, c("x", "y", paste0("y", 1987:2000)) := NULL]

tdt <- hab_dt[1:200, .(key, y2001, y2002, y2003)]

tdt

# reshape

melt_dt <- melt(tdt, id.vars = c("key"), measure.vars = paste0("y", 2001:2003))

obj_size(tdt)
obj_size(melt_dt)


# test with big one:
hab_dt

tic()
hab_dt_melt <- data.table::melt(hab_dt, id.vars = c("key"), measure.vars = paste0("y", 2001:2017))
toc()

obj_size(hab_dt)
obj_size(hab_dt_melt) # three times as big.

# how would I summarize now?
hab_dt_melt


hab_dt

# first, filter by range, elevation, etc.:
hab_dt

hab_filtered_range_el

obj_size(hab_filtered_range_el)

# --------------------- #
# add a key
rm(hab_dt)
hab_filtered_range_el[, key := 1:nrow(.SD)]

# adding a key added this much space:
(3702098608 - 3792393688) / 10^6 # 90 MB!
(3792393688 - 3070033520) / 10^6 # deleting X, Y, elevation, and range saves 722 MB 
obj_size(hab_filtered_range_el) / 10^9 # 3.792 GB

hab_filtered_range_el[, c("x", "y") := NULL]
obj_size(hab_filtered_range_el) # 3.431 GB


hab_filtered_range_el[, c("elevation", "range") := NULL]
obj_size(hab_filtered_range_el) # 3.070 GB


# subset:
obj_size(hab_filtered_range_el)

names(hab_filtered_range_el)
hab_filtered_range_el[, c(paste0("y", 1987:2010)) := NULL]


obj_size(hab_filtered_range_el)

tic()
hab_dt_melt <- data.table::melt(hab_filtered_range_el, 
                                id.vars = c("key", "area_ha"), 
                                measure.vars = paste0("y", 2011:2017))

hab_dt_melt[value %in% habitat_prefs_rcl, 
            sum(area_ha), 
            by = c("variable", "value")]

toc()


tic()
aoh_dt_test_melt_comp_s <- lapply(3, function(i) {
  cc_AOH_data.table(index = i, site_index = 9, year_index = 2011:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()
aoh_dt_test_melt_comp_s

# 
#     variable value       V1
#  1:    y2011     1 147962.5
#  2:    y2011     2 123306.9
#  3:    y2012     1 150692.8
#  4:    y2012     2 135720.2
#  5:    y2013     1 156040.7
#  6:    y2013     2 135630.5
#  7:    y2014     1 154844.5
#  8:    y2014     2 132604.9
#  9:    y2015     1 156117.8
# 10:    y2015     2 140025.3
# 11:    y2016     1 155746.2
# 12:    y2016     2 145278.5
# 13:    y2017     1 154090.6
# 14:    y2017     2 151717.8

```

```{r time-melt}
hab_dt

# having loaded hab_dt before
tic("full melt time")
species_ranges <- vert_sites %>%
  filter(vert_class != "gard",
         site == site_df$site[site_index]) # filter to just the site in question

species_list <- species_ranges %>% st_drop_geometry() %>%
  select(site, vert_class, binomial) %>% unique() %>%
  arrange(site, vert_class, binomial)

species_name <- species_list$binomial[index]
# species_name <- "Lithobates palustris"
cat("Species name:", species_name, fill = TRUE)

# ---- extract species range polygons at the site ---- #
# select a subset of species range polygons based on binomial, and 
# update all features to multipolygon, for fasterize()
range_sf <- st_cast(species_ranges[species_ranges$binomial == species_name, ]) 

# ---- turn the species range polygons (sf) into a raster ---- #
range_t <- 
  fasterize(range_sf,
            raster::raster(resolution = terra::res(elevation_map),
                           ext = raster::extent(terra::ext(elevation_map)[1:4]))
  ) %>% 
  rast() #%>% # convert to SpatRaster 
# subst(1, 0,
#       filename = paste0(tmp_location, "range_t_tmp.tif"),
#       overwrite = T) # update cell values from 1 to 0.

# plot(range_t)

range_dt <- spatraster_to_dt(spt = range_t)

# a quick test to make sure the x and y columns match, to circumvent the need
# to round x and y to get the data.table::merge() to work correctly.
stopifnot(
  all.equal(hab_dt$x, range_dt$x),
  all.equal(hab_dt$y, range_dt$y)
)

# add range to the data.table as a column
hab_dt[, range := range_dt$layer]

# ------------------------------------------------------------------------- #
### Habitat Filter ###
# ------------------------------------------------------------------------- #
z1 <- habitat_prefs %>% 
  filter(binomial == species_name,
         suitability == "Suitable") # extract the habitat classifications for the species in question

# extract the lc codes from my crosswalk that correspond to the IUCN habitat codes
habitat_prefs_rcl <- 
  iucn_crosswalk %>% 
  filter(code %in% unique(z1$code)) %>%
  select(codes = ifelse(calc_lc, "lc", "map_code")) %>% # select lc class codes, or IUCN habitat map codes, depending on the "calc_lc" switch
  unique() %>% .$codes

# ------------------------------------------------------------------------- #
### Elevation Filter ###
# ------------------------------------------------------------------------- #
elevation_prefs_rcl <- elevation_prefs %>% filter(binomial == species_name)

# ------------------------------------------------------------------------- #
### Calculate AOH, broken down by habitat type ###
# ------------------------------------------------------------------------- #

# subset data.table to only pixels within both species range and elevation range, first:
hab_filtered_range_el <- hab_dt[!is.na(range) &
                                  elevation <= elevation_prefs_rcl$elevation_upper &
                                  elevation >= elevation_prefs_rcl$elevation_lower]



# begin melt chunk:
rm(hab_dt)
hab_filtered_range_el[, key := 1:nrow(.SD)]
hab_filtered_range_el[, c("x", "y", "elevation", "range",
                          paste0("y", 1987:2010)) := NULL]

hab_dt_melt <- data.table::melt(hab_filtered_range_el, 
                                id.vars = c("key", "area_ha"), 
                                measure.vars = paste0("y", 2011:2017))

hab_dt_melt[value %in% habitat_prefs_rcl, 
            sum(area_ha), 
            by = c("variable", "value")]

toc() # 22.604 seconds for just 7 layers, which is less than the original data.table code, which runs through each column individually. Just stick with that code.
```




# Cluster results
```{r 11-test}
aoh_dt_11_test <- read_csv(paste0(p_derived, "aoh/aoh_dt_11_test.csv"))

species_list %>% 
  group_by(site)
```


```{r missing-sp}

# how many did it actually run?
aoh_dt_11_test %>% 
  group_by(site) %>% 
  summarise(n = length(unique(binomial)))

runs_actual <- aoh_dt_11_test %>% 
  select(site, binomial) %>%
  unique()

# what happened to Rana temporaria
runs <- lapply(1:11, function(i) {
  species_list %>%
    filter(site == site_df$site[i]) %>%
    head(n = 10) %>%
    mutate(index = 1:10)}) %>% bind_rows()

runs %>% print(n = 100)
runs %>% select(site, binomial)
runs_actual

missing_sp <- runs %>% 
  filter(!binomial %in% unique(runs_actual$binomial))

aoh_dt_11_test %>% 
  filter(binomial %in% missing_sp$binomial)

species_ranges %>%
  filter(binomial %in% missing_sp$binomial) %>% .[1,] %>%
  st_geometry() %>%
  plot()

aoh_dt_11_test %>% 
  select(site, binomial) %>% 
  group_by(site) %>%
  unique() %>% 
  print(n = 120)

list.files(paste0(p_derived, "aoh/"))

missing_sp
species_list %>% filter(site == site_df$site[site_index]) %>% head(n = 10)

# -------------------------------------- run function ---------------------------------- #
aoh_test_c <- lapply(1:3, function(i) {
  cc_AOH_data.table(index = i, site_index = site_index, year_index = 2011:2017, 
             calc_lc = TRUE, include_time = TRUE,
             hab_dt = hab_dt,
             range_maps = vert_sites)
}) %>% bind_rows()

aoh_test_c %>% filter(binomial == sp_name)
plot(lc[[site_index]][[31]])
plot(range_sf$geometry, add = T, border = "red")
plot(range_t, add = T)
plot(range_t)



# it's due to a mismatch in species names
non_match
missing_sp

non_match %>% arrange(site, binomial) %>% print(n = 100)

species_synonyms %>%
  filter(binomial == sp_name)

species_synonyms %>%
  filter(synonym == "Babina daunchina")


non_match %>%
  filter(binomial == "Bufotes variabilis")



missing_sp
#  site      vert_class binomial                 index
#   <chr>     <chr>      <chr>                    <int>
# 1 belarus   amp        Rana temporaria              9   # due to elevation data entry error
# 2 chongqing amp        Babina daunchina             3   # due to synonym issue
# 3 iraq      bird       Acrocephalus melanopogon     3   # no suitable habitat within the site
# 4 orenburg  amp        Bufotes variabilis           3   # suitability is unknown - removed due to this.
# 5 orenburg  amp        Rana temporaria              8   # due to elevation data entry error


missing_sp$binomial

habitat_prefs %>%
  filter(binomial %in% missing_sp$binomial) %>%
  print(n = 100)

```



```{r why-NA?}
# some values are NA... what causes this?
# this stems from cases where there is no 
aoh_dt_11_test %>% 
  filter(is.na(adj_IUCN_aoh_ha))

# why is the adjustment NA??
sp_name <- "Bufo bufo"
site_index <- 1

aoh_dt_11_test %>%
  filter(site == site_df$site[site_index], binomial == sp_name)


habitat_prefs %>%
  filter(binomial == sp_name) %>%
  arrange(code)

z1 %>% arrange(code) %>% print(n = 30)
# test_codes <- 
  z1 %>%
  left_join(iucn_crosswalk, by = "code") %>%
  select(binomial, code, map_code, lc, name, IUCNLevel) #%>%
  # print(n = 110) %>%
  # .$lc %>% unique

# based on the habitat_prefs, this species finds 1, 2, 3, and 4 suitable.
# but, there are no 14.4 habitat type at the site.. so when I join to adj_df, it gives an NA
aoh_dt_11_test %>%
  filter(site == site_df$site[site_index], binomial == sp_name) %>%
  select(site:area_ha) %>%
  
  

z1$code %>% sort() %>% length
unique(z1$code) %>% length

habitat_prefs_rcl

jung_hab_type_area_df %>%
  filter(site == site_df$site[site_index],
         #code %in% unique(z1$code)
         ) %>%
  arrange(habitat_type)


freq(site_jung_l2_30$belarus)

# the iucn crosswalk includes just those IUCN habitat types that Jung's map includes at my sites.
# based on the way that my adjustment works, I adjust the area of each of the four land cover types based on the proportion of the broader category at each site that is made up of that particular habitat type.


iucn_crosswalk <- read_csv(paste0(p_derived, "iucn_lc_crosswalk.csv"))
print(iucn_crosswalk, n = 100)
jung_hab_type_area_df %>% filter(site == site_df$site[site_index])
z1 %>% arrange(code) %>% print(n = 100)


# fix the NAs in the summarise function
aoh_dt_11_test <- aoh_dt_11_test %>%
  # filter(site == site_df$site[site_index], binomial == sp_name) %>%
  group_by(site, binomial, year) %>% 
  summarise(IUCN_aoh_ha = sum(area_ha),
            adj_IUCN_aoh_ha = sum(adj_area_ha, na.rm = TRUE)) #%>%
  # filter(is.na(adj_IUCN_aoh_ha))
```


```{r plot-aoh-test}
ggplot(data = aoh_dt_11_test #%>% filter(site == "shaanxi")
       ,
                     mapping = aes(x = year, y = adj_IUCN_aoh_ha, color = binomial)) + 
  geom_line() +
  facet_wrap(vars(site), scales = "free")

```


## Della results for all 31 layers
```{r load-31-layer-results}
# aoh_run_date <- "_2021_12_05"
aoh_lc_31_files <- list.files(paste0(p_derived, "aoh"), full.names = T) %>% 
  grep(paste0("aoh_tmp", aoh_run_date), ., value = T)

aoh_31_df <- lapply(aoh_lc_31_files, read_csv) %>% bind_rows()

aoh_31_df

aoh_31_df %>%
  filter(binomial == "Chlidonias hybrida",
         site == "shaanxi")

aoh_31_df %>%
  filter(binomial == "Agamia agami") %>%
  ggplot(mapping = aes(x = year, y = adj_IUCN_aoh_ha)) +
  geom_line()



s_sp <- aoh_31_df %>% 
  filter(site == site_df$site[9],
         # binomial == "Tscherskia triton",
         year == 2017) %>%
  select(site:year, adj_IUCN_aoh_ha) %>% unique() %>%
  .$binomial

species_to_remove
i<-9

missing_sp_31 <- lapply(1:11, function(i){
  sp_run <- aoh_31_df %>% 
    filter(site == site_df$site[i]) %>%
  select(site:year, adj_IUCN_aoh_ha) %>% unique() %>%
  select(site, binomial) %>% unique()
  
  sp_not_run <- species_list %>% filter(site == site_df$site[i]) %>%
    filter(!binomial %in% sp_run$binomial)
  sp_not_run
}) %>% bind_rows()


# number of species at each site:
species_list %>% 
  group_by(site, #vert_class
           ) %>% 
  summarise(num_sp = n())

#######
species_list
species_to_remove

aoh_31_df %>% filter(binomial == "Chlidonias hybrida",
                     site == site_df$site[9])

# e_tmp1 <- 
  aoh_31_df %>% 
  filter(adj_IUCN_aoh_ha == 0) %>%
  arrange(site, binomial, year, lc) %>% 
  select(site, binomial) %>% unique() %>%
  filter(site == site_df$site[3])
  
species_to_remove %>% filter(site == site_df$site[3]) %>% arrange(binomial)
missing_sp_31 %>% filter(site == site_df$site[3]) %>% arrange(binomial)

jung_hab_type_area_df %>% filter(site == site_df$site[1]) %>% arrange(code)
habitat_prefs %>% filter(binomial == "Anthus pratensis",
                         suitability == "Suitable") %>% arrange(code)
elevation_prefs %>% filter(binomial == "Anthus pratensis")
  
species_to_remove[[1]]


species_list %>% filter(site == site_df$site[9]) %>% .$binomial #%>% unique()

missing_sp_tmp <- species_list %>% 
  filter(site == site_df$site[9]) %>% #.$binomial %>%
  filter(!binomial %in% s_sp) %>% .$binomial %>% sort()

# all of these species are present in the habitat_prefs file and have suitable habitat
habitat_prefs %>%
  filter(binomial %in% missing_sp_tmp) %>% #.$binomial %>% unique() %>% sort() #%>% length()
  print(n = 50)

missing_sp_tmp

species_ranges %>%
  filter(binomial == missing_sp_tmp[5]) %>%
  st_geometry() %>%
  plot()

species_list %>% filter(site == site_df$site[9]) %>% print(n = 210)


plot(lc$shaanxi[[31]])

species_ranges %>%
  filter(site == site_df$site[9],
         binomial == missing_sp_tmp[1]) %>%
  st_geometry() %>%
  plot(add = T)

#
site_elevation_range[9,]

for(i in missing_sp_tmp) {
elevation_prefs %>% filter(binomial == i) %>% print()
habitat_prefs %>% filter(binomial == i) %>% print()
}

jung_hab_type_area_df %>% filter(site == site_df$site[9]) %>% arrange(habitat_type)
```

```{r expl-seff}
cat(
  paste("seff", paste0("39004952_", 1:27), collapse = "; "),
  "> text2.txt"
    )
# Use the above to make seff calls to get the full times and memory usage for the full array run
# then copy and paste this output into a 


txt <- read_csv("scripts/ref/seff_out_aoh_abn_lc.csv")
txt <- read_csv("scripts/ref/seff_out_aoh_abn_lc.csv")
txt <- read_csv("scripts/ref/seff_out_max.csv")
txt

seff <- tibble(core_index = 1:18,
               time = str_subset(txt$out, "CPU Utilized"), 
               mem = str_subset(txt$out, "Memory Utilized"),
               state = str_subset(txt$out, "State: ")
               ) %>%
  mutate(time = str_extract(time, "[0-9][0-9]:[0-9][0-9]:[0-9][0-9]"),
         mem = str_extract(mem, "[0-9][0-9].[0-9][0-9]") %>% as.numeric())

seff %>% print(n = 30)

calc_cores

```


