---
title: "AOH"
author: "Christopher L. Crawford"
date: "11/16/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r initialize}
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/0_start.R")
# install.packages("terra")
# packageVersion("terra")
# library(terra)

# load files:
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/util/_util_files.R")
```


# AOH


```{r load-raw-species-data}
# location of prepped range map data (from Zambia project)
p_range <- "/Volumes/GoogleDrive/My Drive/Zambia/agroEcoTradeoff/external/data_new/1_IUCN_dev/"
list.files(p_range) %>% grep("prep", .,  value = TRUE)



# Amphibians
load(paste0(p_range, "amp_valid_prepped.RData"), verbose = TRUE)
assign("amp_sf", amp_valid)
rm(amp_valid)
st_crs(amp_sf) <- st_crs(amp_sf)


# Birds
load(paste0(p_range, "bird_valid_prepped.RData"), verbose = TRUE)
assign("bird_sf", bird_valid)
rm(bird_valid)
st_crs(bird_sf) <- st_crs(bird_sf)


# Mammals
load(paste0(p_range, "mam_valid_prepped.RData"), verbose = TRUE)
assign("mam_sf", mam_valid)
rm(mam_valid)
st_crs(mam_sf) <- st_crs(mam_sf)


# Reptiles (GARD)
load(paste0(p_range, "gard_prep.RData"), verbose = TRUE)
gard_prep
assign("rep_sf", gard_prep)
rm(gard_prep)
st_crs(rep_sf) <- st_crs(rep_sf)


```

```{r validate}
# Amphibians

amp_sf <- amp_sf %>% sf::st_make_valid()

amp_valid_reasons <- st_is_valid(amp_sf, reason = TRUE)
length(amp_valid_reasons)
unique(amp_valid_reasons)
grep("Loop 0: Edge 9032 crosses edge 9034", amp_valid_reasons) 
# 7147:
# Vaillant's Frog
# Lithobates vaillanti

amp_sf[7147, ]


# Birds
bird_sf <- bird_sf %>% sf::st_make_valid()

bird_sf_valid_reasons <- st_is_valid(bird_sf, reason = TRUE)

length(amp_valid_reasons)
unique(amp_valid_reasons)
grep("Valid Geometry", bird_sf_valid_reasons, invert = TRUE) 



amp_sf[7147, ]

# Mammals


# Reptiles (GARD)

```

```{r crop-ranges-to-sites}
# Amphibians

names(amp_sf)
amp_s <- amp_sf[-7147, ] %>%
    st_intersection(., site_sf %>% filter(site == "shaanxi"))

amp_sc <- amp_sf[-7147, ] %>%
    st_intersection(., site_sf %>% 
                      filter(site %in% site_df$site[c(3,9)])
                    )

tic()
amp_sites <- amp_sf[-7147, ] %>% st_intersection(., site_sf)
toc() # 1402 sec

names(amp_sites)
amp_sites %>% st_drop_geometry() %>% select(binomial, category, site)

write_csv(amp_sites %>% st_drop_geometry(), 
          file = paste0(p_derived, "/amp_sites.csv"))
st_write(amp_sites, paste0(p_derived, "amp_sites.shp")) # 
save(amp_sites, file = paste0(p_derived, "amp_sites.RData"))
# load(file = paste0(p_derived, "amp_sites.RData"), verbose = TRUE)



# Birds
bird_s <- bird_sf %>%
    st_intersection(., site_sf %>% filter(site == "shaanxi"))

```

```{r mam-sites}
mam_sites %>%
  filter(site == "shaanxi") %>%
  st_geometry() %>% plot()

# how many species occur at each site?

mam_sites %>%
  st_drop_geometry() %>%
  group_by(site) %>%
  select(site, binomial) %>%
  summarise(num_sp = length(unique(binomial)))

filter(mam_sites, site == "shaanxi")

mam_rich <- lapply(site_df$site,
                   function(i) {
                     
                     template <- raster()
                     extent(template) <- extent(raster(lc[[i]]))
                     res(template) <- res(lc[[i]])
                     
                     rast(
                       fasterize(sf = mam_sites %>%
                                   filter(site == i) %>% 
                                   st_cast("MULTIPOLYGON"), 
                                 raster = template, 
                                 fun = "sum"))})


rm(mam_rich)
plot(mam_rich[[1]])
plot(mam_rich[[1]]$sha_1)
dev.off()
```



```{r load-and-bind-cropped-ranges}

vert_list <- c("amp", "bird", "mam", "gard")

species_files <- list.files(paste0(p_derived, "species_ranges"), full.names = TRUE)

load(grep("amp", grep("RData", species_files, value = T), value = T), verbose = T)
amp_sites <- range_sites %>% 
  mutate(vert_class = "amp")

load(grep("bird", grep("RData", species_files, value = T), value = T), verbose = T)
bird_sites <- range_sites %>% 
  mutate(vert_class = "bird")

load(grep("mam", grep("RData", species_files, value = T), value = T), verbose = T)
mam_sites <- range_sites %>% 
  mutate(vert_class = "mam")

load(grep("gard", grep("RData", species_files, value = T), value = T), verbose = T)
gard_sites <- range_sites %>% 
  mutate(vert_class = "gard")



# Select and rename columns to facilitate join:

# note, mam and amp columns match perfectly
names(mam_sites) == names(amp_sites) 

amp_pre_merge <- amp_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no, presence, origin, seasonal,
         order_, family, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler, citation,
         genus, marine, terrestial, freshwater, # extras
         geometry
         )

mam_pre_merge <- mam_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no, presence, origin, seasonal,
         order_, family, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler, citation,
         genus, marine, terrestial, freshwater, # extras
         geometry
         )

bird_pre_merge <- bird_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no = SISID, presence, origin, seasonal,
         order_ = Order_, family = FamilyName, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler = COMPILER, citation = CITATION,
         family_common = Family, CommonName, # extras
         geometry = Shape
)

gard_pre_merge <- gard_sites %>% 
  select(site, vert_class, binomial, 
         category = redlistCategory, # reptiles are not comprehensively assessed, but I've added the category for those that are assessed
         # id_no = SISID, presence, origin, seasonal,
         # order_ = Order_, family = FamilyName, 
         area_km2, range_size_quantile, inverse_range_glob,
         pre_valid_reasons, post_valid_reasons,
         # compiler = COMPILER, citation = CITATION,
         Group, # extras
         geometry
)

# -------------- bind rows: ---------------- #

vert_sites <- bind_rows(amp_pre_merge, bird_pre_merge, mam_pre_merge, gard_pre_merge)
save(vert_sites, file = paste0(p_derived, "species_ranges/vert_sites.RData"))


vert_sites %>% st_drop_geometry()

vert_sites %>% st_geometry() %>% plot()


df1 <- amp_sites %>% st_drop_geometry() %>% as_tibble()
df2 <- bird_sites %>% st_drop_geometry() %>% as_tibble()
df3 <- gard_sites %>% st_drop_geometry() %>% as_tibble()



sum(df2$binomial != df2$ScientificName) # all 
identical(df2$binomial, df2$ScientificName) # all equal!

names(df1)
names(df3)
names(df2)

df3$FID_2 %>% length()
df3$FID_2 %>% unique() %>% length()

df3$binomial %>% length()


```

```{r merge-polygons}

vert_sites %>% st_drop_geometry() %>%
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  select(binomial, vert_class, #site
         ) %>%
  unique() %>%
  nrow() 
# 4253 features (4856 with reptiles)
# 2230 species total occur at one or more of my sites (2656 if including reptiles)
# 4038 unique site, species pairs exist - this is the number of runs I'll have to do. (4641 if including reptiles)

vert_sites %>% nrow()
vert_sites_merged %>% nrow()
vert_sites_merged %>% st_drop_geometry() %>%
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  select(site, binomial, vert_class, #site
         ) %>%
  unique() %>%
  nrow() 



# how many sites have multiple polygons per species?
vert_sites %>% 
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  # 4253 features
  st_drop_geometry() %>%
  group_by(site, vert_class) %>% 
  summarise(num_rows = binomial %>% length(),
            num_sp = binomial %>% unique() %>% length()) %>% 
  filter(site == "wisconsin")

sf_use_s2()
sf_use_s2(FALSE)

tic()
vert_sites_merged <- vert_sites %>% 
  group_by(site, vert_class, binomial, category, id_no, #presence, origin, seasonal
           ) %>% 
  summarise() %>% ungroup()
toc()

tcom1 <- vert_sites %>% filter(binomial == "Lithobates palustris")

tcom1 %>%
  st_geometry() %>%
  plot()

tcom1
tcom1 %>% st_combine()

names(tcom1)
tcom2 <- tcom1 %>% 
  group_by(site, vert_class, binomial, category, id_no, presence, origin, seasonal) %>% 
  summarise() %>% ungroup()

tcom3 <- tcom1 %>%
  group_by(site) %>% summarise()

plot(tcom2)
plot(tcom1[1,])
tcom1 %>% group_by(c("site", "vert_class")) %>% summarise()


```



```{r habitat-prefs}
habitat_prefs <- read_csv(file = "/Volumes/GoogleDrive-107266184156135828486/My Drive/ee/habitat_prefs.csv")

habitat_prefs
names(habitat_prefs)

habitat_prefs$specialism %>% unique()

habitat_prefs$habitat_code %>% unique() %>% sort()
habitat_prefs$habitat_importance
habitat_prefs$habitat_suitability %>% unique() %>% sort()
habitat_prefs$className %>% unique() %>% sort()

habitat_prefs$scientificName %>% unique() %>% sort()

```


```{r fasterize-site_ranges}
# fasterize
amp_sc_r <- amp_sc %>%
  st_collection_extract(., "POLYGON") %>% # extract only polygons
  fasterize(sf = ., raster = template_raster, 
            field = NULL, fun = "sum")

plot(amp_sc_r)
plot(amp_sc_r, ext = my_ext)

plot(amp_sc)


amp_china <- amp_sf[-7147, ] %>%
    st_intersection(., st_geometry(china))


plot(st_geometry(china))
amp_china

st_bbox(china)

extent(filter(site_sf, site == "shaanxi"))

template_raster <- raster::raster(ncols = 100, nrows = 100,
                    xmn = -84, xmx = -83, 
                    ymn = 42, ymx = 43)

template_raster <- raster::raster(ncols = 100, nrows = 100,
                    extent(china))

extent(filter(site_sf, site == "shaanxi"))


values(template_raster) <- 1:ncell(template_raster)
plot(template_raster)
plot(china$geometry, add = T)
#extend(mask_filled, template_raster_extent, value = 0)

amp_china_poly <- amp_china %>% st_collection_extract(., "POLYGON") # extract only polygons


amp_china_r <- 
  fasterize(sf = amp_china_poly, raster = template_raster, 
            field = NULL, fun = "sum")

plot(amp_china_r)
my_ext <- drawExtent()

plot(amp_china_r, ext = my_ext)
plot(site_sf %>% 
       filter(site == "shaanxi") %>%
       st_geometry(), 
     add = T)

act <- rast(amp_china_r)
plot(act)
plot(act, extent = my_ext)

act_crop <- crop(act, terra::ext(my_ext))
amp_s
plot(act_crop, type = "classes")
plot(amp_s$geometry)


plot(amp_s$geometry)

plot(amp_sf[1, ]$geometry)

plot(site_sf %>% filter(site == "shaanxi") %>% st_geometry())
plot(amp_sf$geometry, add = TRUE)

```



```{r filter-ranges}
names(amp_sf)

amp_sf %>% select(binomial, category)

amp_sf %>%
  filter(presence == 1) %>%   # only records with Code 1 (Extant)
  filter(origin %in% c(1, 2)) %>%     # only native species (Code 1) and reintroduced (Code 2)
  filter(seasonal %in% c(1, 2, 3)) %>%   # selecting "Resident" (1), "Breeding" (2), and "Non-breeding Season" (3) ranges. Other categories include: Non-breeding Season (3), Passage (4), and Seasonal Occurrence Uncertain (5).
  filter(marine == "False") %>%   # removing all marine species
  filter(!category %in% c("EW", "EX")) %>% # remove Extinct or Extinct in the Wild species ("EW", "EX")
  
  print(n = 40)

```



```{r RS-AOH-tester}
library(sf)
AOH <- st_read(paste0(p_dat, "bd/AOH/reptilia_AOH/reptilia.shp"))

AOH %>% st_drop_geometry() %>% as_tibble()
object_size(AOH)
names(AOH)
head(AOH)
st_crs(AOH)



# plot
AOH %>% 
  filter(binom == "Archaius_tigris") %>% 
  st_geometry() %>% 
  plot()

AOH %>% 
  st_geometry() %>% 
  plot(add = TRUE)

plot(ne_countries()) # or all sub national level bodies plot(ne_states())

crs(ne_countries())

# Create template raster by extending the input raster (mask) to the extent of the input polygons.
mask_filled <- mask
mask_filled[is.na(mask_filled)] <- 0 # replace NAs with 0s

projection <- crs(AOH) # note, seems to work better than st_crs().

# make a template raster
mask <- raster()
res(mask) <- 0.01


# values(mask) <- 0 # If you want, you can add values to the raster. You don't have to though, and it just makes the raster HUGE at this resolution (4.8 GB)
# writeRaster(mask, "mask.tif") # if you add values, you'll need to just write it to your machine, otherwise you'll quickly run out of memory, as the fasterize layer will be the same size.  


AOH_r <- fasterize(AOH, mask, fun = "sum") # field = NULL by default, which gives every polygon a value of 1

# in the event that you want to build a raster based on 
template_raster <- extend(small_mask, extent(as.Spatial(sf_file)), value = 0)




# fasterize


  
```

```{r sparse}
library(sf)
library(raster)

AOH <- st_read(paste0(p_dat, "bd/AOH/reptilia_AOH/reptilia.shp"))

# check it out
AOH %>% 
  filter(binom == "Archaius_tigris") %>% 
  st_geometry() %>% 
  plot()

AOH %>% 
  st_geometry() %>% 
  plot(add = TRUE)
# tiny lil guys, eh?



# -------------------
# First, make a template raster

mask <- raster()
res(mask) <- 0.01


# values(mask) <- 0 # If you want, you can add values to the raster. You don't have to though, and it just makes the raster HUGE at this resolution (4.8 GB)
# writeRaster(mask, "mask.tif") # if you add values, you'll need to just write it to your machine, otherwise you'll quickly run out of memory, as the fasterize layer will be the same size.  


# -------------------
#  Fasterize: 

AOH_r <- fasterize(AOH, mask, fun = "sum") # field = NULL by default, which gives every polygon a value of 1

plot(AOH_r) # again.... tiny lil guys!




# -------------------
# Notes:

# If you aren't already familiar, these are great packages for basemaps:
install.packages("rnaturalearth")
devtools::install_github("ropensci/rnaturalearthdata")
devtools::install_github("ropensci/rnaturalearthhires")
library(rnaturalearth)
library(rnaturalearthdata)
library(rnaturalearthhires)

plot(ne_countries())  # nice!
# plot(ne_states()) # or all sub national level bodies with this one 



# if you need to reproject the mask before you fasterize, I think raster works best with: 
crs(AOH) # note, seems to work better than st_crs().

# in the event that you want to build a raster based on a smaller existing one
template_raster <- extend(small_mask, extent(as.Spatial(sf_file)), value = 0)



```

## AOH dev (based on Yiwen's script)

```{r load-files-AOH}
# set up parameters:
site_index <- 11
yr_index <- 31
  
# see Yiwen's script: "scripts/ref/AOH_firstGo_whichSpecies.R"
load(file = paste0(p_derived, "species_ranges/vert_sites.RData"), verbose = TRUE)

species_ranges <- vert_sites %>%
  filter(vert_class != "gard",
         site == site_df$site[site_index]) # filter to just the site in question

# number of unique runs:
vert_sites %>%
  st_drop_geometry() %>%
  filter(vert_class != "gard") %>%
  select(site, vert_class, binomial) %>% 
  unique() %>% 
  as_tibble() %>% 
  arrange(site, vert_class, binomial)

  


### Which species to use ? ###
# ref <- read.csv("~/Dropbox/PostDoc4_Princeton/Species Traits/Mammal_base_Matched.csv", row.names=1) # just the IUCN spreadsheet, species list.

species_list <- species_ranges %>% 
  st_drop_geometry() %>%
  select(site, vert_class, binomial) %>% 
  unique() %>% 
  as_tibble() %>% 
  arrange(site, vert_class, binomial)

#### -------- load habitat map ---------- ####

### Loading suitable habitats from IUCN/IIASA #####
# iucnHabitatClass <- raster("~/Dropbox/PostDoc4_Princeton/Species Traits/iucn_habitatclassification_composite_lvl2_ver003_resampled.tif")

# jung_l2 <- rast(paste0(p_dat, "Habitats/Jung_GlobalHabitatTypes/iucn_habitatclassification_composite_lvl2_ver004.tif"))


# if Jung map:
habitat_map <- rast(paste0(p_derived, "site_jung/", site_df$site[site_index], "_jung_l2_30.tif"))

# if Yin et al. 2020 LC maps
habitat_map <- lc[[site_index]][[yr_index]]
plot(habitat_map)

# load elevation raster
elevation_t <- rast(paste0(p_derived, "elevation/", site_df$site[site_index], "_srtm_crop.tif"))

# plot(elevation_t)


# ----------------------- #
# --- pixel area (ha) --- #
# ----------------------- #
site_area_ha <- lapply(
  list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
  function(i) rast(i)
)
names(site_area_ha) <- site_df$site


# ---------------------------------------------- #
# Jung table crosswalk
# ---------------------------------------------- #
iucnHabitatTranslator <- read_csv(paste0(p_proj, "/resources/IUCNhabitatMap_translator.csv"))

IUCN_crosswalk <- read_csv(paste0(p_derived, "/IUCN_lc_crosswalk.csv")) %>%
  left_join(iucnHabitatTranslator, by = "map_code") %>% 
  arrange(map_code)
  

IUCN_crosswalk %>% arrange(lc, map_code) %>% print(n = 45)
IUCN_crosswalk %>% arrange(map_code) %>% print(n = 45)

habitat_prefs$code %>% unique() %>% sort()

```


```{r load-IUCN-files}
## translator ##
# iucnHabitat <- read.csv("~/Dropbox/PostDoc4_Princeton/Species Traits/MammalsIUCN/habitats.csv")

habitat_prefs <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/habitats.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, code, name:suitability, assessmentId, internalTaxonId)
}) %>% 
  bind_rows() %>% 
  filter(binomial %in% unique(species_list$binomial))

habitat_details <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/assessments.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, redlistCategory, rationale, habitat, threats, population)
}) %>% 
  bind_rows() %>% 
  filter(binomial %in% unique(species_list$binomial))

species_synonyms <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/synonyms.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, genusName, speciesName) %>%
    mutate(synonym = paste0(genusName, " ", speciesName))
}) %>% 
  bind_rows() %>% 
  filter(synonym %in% unique(species_list$binomial))


species_synonyms %>% filter(synonym %in% unique(non_match$binomial)) %>% arrange(synonym) %>% print(n = 30)

vert_sites %>% filter(binomial == "Antigone canadensis")


unique(non_match$binomial) %>% sort()



# check to make sure each range has habitat prefs, elevation prefs:
habitat_prefs %>% select(binomial) %>% unique() # 2205

ref %>% select(binomial) %>% unique() # 2230
vert_sites %>% st_drop_geometry() %>% filter(vert_class != "gard") %>% select(binomial) %>% unique() %>% nrow() # 2230
habitat_details %>% select(binomial) %>% unique() # 2205

unique(habitat_details$binomial) %>% length()
unique(species_list$binomial) %>% length()

non_match <- species_list %>% filter(!binomial %in% unique(habitat_details$binomial))
non_match$binomial %>% unique() # 25 species without a match. 

habitat_details %>% filter(binomial == "Capricornis sumatraensis")


species_list %>% filter(binomial == "Capricornis sumatraensis")
vert_sites %>% filter(binomial == "Capricornis sumatraensis")
vert_sites %>% filter(binomial == "Capricornis milneedwardsii") %>% st_geometry() %>% plot()


non_match %>% select(vert_class, binomial) %>% arrange(vert_class, binomial) %>% unique() %>% print(n = 25)

# column names to extract
# binomials
# habitat prefs
# elevation prefs



### Loading elevation data ####
# elevation_prefs <- read.csv("~/Dropbox/PostDoc4_Princeton/Species Traits/MammalsIUCN/ElevationOnly.csv", row.names=1)


elevation_prefs <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/all_other_fields.csv")#, n_max = 10
    ) %>%
    select(binomial = scientificName, elevation_lower = ElevationLower.limit, elevation_upper = ElevationUpper.limit)
}) %>% 
  bind_rows() %>%
  
  # extract records for only those species of interest 
  filter(binomial %in% unique(species_list$binomial)) %>%
  
  # update elevation to account for NA
  mutate(elevation_lower = ifelse(is.na(elevation_lower), 0, elevation_lower),
         elevation_upper = ifelse(is.na(elevation_upper), 9999999, elevation_upper)
         )
```


```{r aoh-dev}

# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]
species_list[, 3]
aoh_df <- tibble(species = species_list[, "binomial"],
                  IUCN_AOO = NA,
                  IUCN_AOH = NA)



i <- 1
for(i in seq_along(species_list$binomial)) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  
  # ---- extract species range polygons at the site ---- #
  
x1 <- species_ranges[species_ranges$binomial == paste0(species_list[i, "binomial"]),] # select a subset of species range polygons based on binomial
species_name <- "Lithobates palustris"

x1 <- vert_sites[vert_sites$binomial == "Lithobates palustris", ] %>% 
  st_cast() # update all features to multipolygon, for 


# ---- crop the land cover map in question to the extent of the range map ---- #
tic()
y1 <- terra::crop(#iucnHabitatClass,
  habitat_map[[11]], # site_jung_l2_30[[11]],
  x1) #%>% raster()
toc()

site_area_ha[[site_index]]



# ---- turn the species range polygons (sf) into a raster ---- #
# this involves creating a template raster to match the dimensions of the IUCN Habitat map, 
# and then using fasterize().
# if using this method, must first convert all sf objects to the same type (i.e., multipolygon)
# I can also do this using terra::rasterize(), but it's slightly slower. (~ 1 second for Wisconsin)

tic()
template_raster1 <- raster::raster(
  resolution = terra::res(site_area_ha[[site_index]]),
  ext = raster::extent(terra::ext(site_area_ha[[site_index]])[1:4]),
  ncols = terra::ncol(site_area_ha[[site_index]]),
  nrows = terra::nrow(site_area_ha[[site_index]]))


template_raster <- raster::raster(
  resolution = terra::res(y1),
  ext = raster::extent(terra::ext(y1)[1:4]),
  ncols = terra::ncol(y1),
  nrows = terra::nrow(y1))

x2 <- fasterize(x1, 
                template_raster# 
                # raster(y1)
                ) %>% rast()

x21 <- fasterize(x1,
                template_raster1# 
                # raster(y1)
                ) %>% rast()

toc()

plot(x2)
ext(x2)
ext(lc$wisconsin$y2017)

# writeRaster(x2,
            # filename = paste0(p_derived, "aoh/tmp/random_tmp.tif"), 
            # overwrite=TRUE)
# x2 <- rast(paste0(p_derived, "aoh/tmp/random_tmp.tif"))


# fasterize is faster than terra::rasterize(), but the step of writing the raster to file, then reloading as SpatRaster takes much longer.
# tic()
# x2t <- terra::rasterize(vect(x1), y1, # must convert sf to spatvector:
#                         #field="", 
#                         #fun = length#, sum = FALSE, 
#                         # filename = paste0(p_derived, "aoh/tmp/rasterize_tmp.tif"), overwrite=TRUE
#           )
# toc()
# 
# plot(x2t)


 # ---- update cell values to mask ---- #

# tic()
# x3 <- calc(x2_r, function(x) {x[!is.na(x)] <- 0; return(x)}) # passes a function setting all of the cell values that are not NAs to 0
# toc()

tic()
x3 <- subst(x2, 1, 0) # change cell value from 1 to 0.
# x3 <- x2 - 1 # can also do this, maybe just very slightly faster
toc()

# Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
# expanse() is much faster! But... it doesn't work with large rasters of the extent of some of my sites.

# aoh_df$IUCN_AOO[i] <- expanse(x2, unit = "km") # in km2

print(aoh_df, n = 30)

tic()
x2_area_test <- x3 %>%
  terra::cellSize(., unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE) %>% 
  as.numeric()

x2_area_test
toc()

tic()
x2_area_test1 <- terra::cellSize(x21, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
x2_area_test1
toc()


plot(x2)
plot(x3 + site_area_ha[[site_index]])
tic()
global(x3 + site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()
tic()
global(x2 * site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()

x2 * site_area_ha[[site_index]] %>%
  global(., fun = "sum", na.rm = TRUE)


# by calculating cellSize()
tic()
x2_area <- 
  terra::cellSize(x2, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

aoh_df$IUCN_AOO[i] <- x2_area

site_area_ha[[11]]
plot(site_area_ha[[11]])

# mask the IUCN habitat map to the range raster
y2 <- x3 + y1
# y2 <- app(c(x3, y1), sum) # the same, but slightly slower
# y2 <- terra::mask(x3, y1)

plot(y2)

# ------------------------------------------------------------------------- #
### Habitat Filter ###
# ------------------------------------------------------------------------- #
species_list[i, "binomial"]

z1 <- habitat_prefs %>% 
  filter(binomial == species_name,
         suitability == "Suitable") # extract the habitat classifications for the species in question

suitable_habitat_codes <- IUCN_crosswalk %>% 
  filter(code %in% unique(z1$code)) %>%
  # .$lc %>% 
  .$map_code %>% 
  unique() # extract the lc code from my crosswalk that correspond to the IUCN habitat codes

suitable_habitat_rcl <- IUCN_crosswalk %>% 
  filter(code %in% unique(z1$code))


# my thoughts on how to do the land cover translation
# I have decided what proportion of "forest" go into what habitat type at each site. I don't know where though, so I'll just attribute this proportionally, evenly across the whole site. So, what I should do is apply this proportionally *after* I have clipped out the suitable habitats. 

# So, I need to build a translator for the IUCN habitat prefs, and then extract by that.
# I can then, in a separate step, multiply by the proportion in question.
# I can calculate the area in each habitat type, and if a species has a subset of one habitat type that is suitable (e.g., grassland, but not savanna or shrubland), I will then adjust the habitat area down by the proportion of my lc "grassland (4)" that is considered the IUCN habitat type grassland at that site. 

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
           overwrite = TRUE)
toc()  # 1.894  seconds

# calculate area after habitat filter
tic()
y3_area <- 
  terra::cellSize(y3, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

plot(y3)
# ------------------------------------------------------------------------- #
### Elevation Filter ###
# ------------------------------------------------------------------------- #
elevation_t
elevation_t[[site_index]]

elevation_mask <- elevation_t[[site_index]] + y3
plot(elevation_mask)

y3_r <- raster(elevation_mask)

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
           overwrite = TRUE)
toc()

elevation_mask
elevation_rcl <- elevation_prefs %>% filter(binomial == species_name)

e1 <- elevation_prefs[elevation_prefs$binomial==paste0(species_list[i,1]), ]

terra::app(y3, )
ele6_t <- elevation_mask
plot(ele6_t)



tic()
ele6_rcl <- classify(elevation_mask, 
                     rcl = tibble(from = el_rcl$elevation_lower,
                                  to = el_rcl$elevation_upper, 
                                  becomes = 0),
                     include.lowest = TRUE, right = TRUE)
toc() # sweet! much faster.

plot(ele6_rcl, colNA = "pink")

# mask the range polygon by the habitat mask and the elevation mask


print(i)
write.csv(aoh_df,"~/Dropbox/PostDoc4_Princeton/Species Traits/FutureAOH.csv")
}
```

```{r aoh-trim}

# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]

aoh_df <- tibble(site = site_df$site[site_index],
                 species = species_list[, "binomial"],
                 year = yr_index + 1986,
                 IUCN_aoo_ha = NA,
                 IUCN_aoh_ha = NA)

# for a specific site, compile list of species
species_list
aoh_df

4000 * 28 /60 / 60 / 11 # hours /11

# what if I do the lc maps in batches, do I save time? 

cc_run_AOH <- function(index,
                       site_index,
                       year_index,
                       calc_lc = TRUE) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  tic(paste0("run ", index, ":", site_df$site[site_index], ", ", year_index))
  
  species_name <- species_list$binomial[index]
  # species_name <- "Lithobates palustris"
  
  # ---- extract species range polygons at the site ---- #
  range_sf <- st_cast(species_ranges[species_ranges$binomial == species_name, ]) # select a subset of species range polygons based on binomial, and update all features to multipolygon, for fasterize()
    
  # ---- turn the species range polygons (sf) into a raster ---- #
    
  range_t <- fasterize(
    range_sf, 
    raster::raster(
      resolution = terra::res(habitat_map),
      ext = raster::extent(terra::ext(habitat_map)[1:4])
      )
    ) %>% 
    rast() %>% # convert to SpatRaster 
    subst(1, 0) # update cell values from 1 to 0.
  
  # ------------------------------------------------------------------------- #
  ### Habitat Filter ###
  # ------------------------------------------------------------------------- #
  z1 <- habitat_prefs %>% 
    filter(binomial == species_name,
           suitability == "Suitable") # extract the habitat classifications for the species in question
  
  # extract the lc codes from my crosswalk that correspond to the IUCN habitat codes
  suitable_habitat_rcl <- IUCN_crosswalk %>% 
    filter(code %in% unique(z1$code))
  
  # reclassify habitat raster to 
  habitat_map_range_rcl <- 
    classify(
      habitat_map,
      rcl = select(suitable_habitat_rcl, 
                   is = ifelse(calc_lc, "lc", "map_code")
                   ) %>% unique() %>% 
               mutate(becomes = 0),
             othersNA = TRUE,
             filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
             overwrite = TRUE)
  
  plot(habitat_map_range_rcl)
  
  # ------------------------------------------------------------------------- #
  ### Elevation Filter ###
  # ------------------------------------------------------------------------- #
  elevation_rcl <- elevation_prefs %>% filter(binomial == species_name)
  
  elevation_range_rcl <- 
    classify(
      elevation_t,
      rcl = tibble(from = elevation_rcl$elevation_lower,
                   to = elevation_rcl$elevation_upper,
                   becomes = 0),
      include.lowest = TRUE, right = TRUE)
  
  plot(elevation_range_rcl, colNA = "pink")
  
  # mask the range polygon by the habitat mask and the elevation mask
  aoh <- range_t + habitat_map_range_rcl + elevation_range_rcl
  
  # ------------------------------------------------------------------------- #
  ### Calculate areas:
  # ------------------------------------------------------------------------- #
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  range_aoo_ha <- 
    terra::cellSize(range_t, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>%
    as.numeric()
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  range_aoh_ha <- 
    terra::cellSize(aoh, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>%
    as.numeric()
  
  toc(log = T)
  
  aoh_tmp <- 
    tibble(site = site_df$site[site_index],
           binomial = species_name,
           year = year_index + 1986,
           IUCN_aoo_ha = range_aoo_ha,
           IUCN_aoh_ha = range_aoh_ha)
    
  cat("calculated AOH for", species_name, "=", range_aoh_ha, "ha", fill = TRUE)
  aoh_tmp
}

aoh_test <- lapply(1:5, function(i) {
  cc_run_AOH(index = i, site_index = 11, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()



aoh_test
aoh_df[1:5,]
i <- 1
for(i in 1:5#seq_along(species_list$binomial)
    ) {

}

tic.log(format = T)

write.csv(aoh_df,"~/Dropbox/PostDoc4_Princeton/Species Traits/FutureAOH.csv")




```

