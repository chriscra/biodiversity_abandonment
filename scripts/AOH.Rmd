---
title: "AOH"
author: "Christopher L. Crawford"
output: html_document
editor_options: 
  chunk_output_type: console
---

This is part of the **Biodiversity Impacts of Abandonment** project, developed by Christopher L. Crawford, starting fall of 2021. 
See https://github.com/chriscra/biodiversity_abandonment.

```{r initialize}
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/0_start.R")
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/_util/_util_files.R")
```

```{r clean-up}
os <- get_sizes(ls())

os %>% 
  summarise(total_env_size = sum(size)) %>% 
  mutate(gb = total_env_size / 1024^3)

os
os %>% print(n = 30)

# rm(list = os$object[c(1:2)])

get(os$object[16])

# terra and raster temp files
terra::tmpFiles(current=TRUE, orphan=FALSE, old=FALSE, 
                remove=TRUE)

terra::tmpFiles(current=TRUE, orphan=TRUE, old=TRUE, 
                remove=FALSE)

terra::tmpFiles(current=TRUE, orphan=TRUE, old=TRUE, 
                remove=TRUE)

raster::rasterTmpFile()
raster::showTmpFiles()
raster::removeTmpFiles()

warnings()
```


# Development

```{r calculate-area-ha}
ifelse(
  !dir.exists(paste0(p_derived, "site_area_ha")), 
  dir.create(paste0(p_derived, "site_area_ha")), 
  "Directory already exists")


site_area_ha <- lapply(1:11, function(i) {
  terra::cellSize(age_t[[i]]$y2017, unit = "ha", mask = FALSE,
                  overwrite = TRUE,
                  names = paste0(site_df$site[i], "_area_ha"),
                  filename = paste0(p_derived, "site_area_ha/", site_df$site[i], "_area_ha.tif"))
  }
)


site_area_ha <- lapply(
  list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
  function(i) rast(i)
  )
names(site_area_ha) <- site_df$site
```

```{r crop_elevation_map}
# download SRTM 30 m elevation data from Google Earth Engine (https://developers.google.com/earth-engine/datasets/catalog/USGS_SRTMGL1_003). Multiple variables include: a. Elevation; b. Slope; c. Terrain Ruggedness Index (TRI); d. Topographic Wetness Index
p_predictors <- "/Volumes/GoogleDrive/My Drive/data/Abandonment/predictors"

elevation_l <- lapply(1:11, function(i) {
  p_predictors %>% 
    list.files(full.names = T) %>% 
    grep("srtm",., value = T) %>%
    grep(paste0(site_df$label[i], ".tif"), ., value = T) %>%
    rast()
})
names(elevation_l) <- site_df$site


elevation_l_crop <- lapply(1:11, function(i) {
  terra::crop(
  elevation_l[[i]], 
  age_t[[i]],
  filename = paste0(p_derived, "elevation/", site_df$site[i], "_srtm_crop.tif"),
  overwrite = TRUE
  )
})



terrain_l <- lapply(1:11, function(i) {
  terra::terrain(elevation_l_crop[[i]]$elevation, 
          v = c('slope', 'aspect', 'TRI', "TPI", "roughness"), 
          unit='degrees',
          filename = paste0(p_derived, "elevation/", site_df$site[i], "_terrain.tif")
          )
})
names(terrain_l) <- site_df$site



# reload

terrain <- lapply(1:11, function(i) {
  rast(
  c(paste0(p_derived, "elevation/", site_df$site[i], "_srtm_crop.tif"),
    paste0(p_derived, "elevation/", site_df$site[i], "_terrain.tif")
    ))
})

names(terrain) <- site_df$site


```

## AOH of only Abandoned croplands

```{r species-list-just-2-4}
species_list %>% filter(grepl("bird|mam", vert_class)) %>% select(binomial) %>% unique() %>% nrow()
  
habitat_prefs %>% 
  filter(suitability != "Suitable")


habitat_prefs$binomial %>% unique() %>% length() # 2312
species_ranges$binomial %>% unique() %>% length() # 2312 in species_ranges
species_list$binomial %>% unique() %>% length() # 2187 after filtering by IUCN attributes, filtering out species without suitable habitats, elevations

# 2074 species of the 2312 species unfiltered species_range layer with 2 or 4 as suitable habitat
habitat_prefs %>% 
  filter(suitability == "Suitable",
         lc %in% c(2, 4)) %>% 
  .$binomial %>% unique() %>% length() 


# 1159 of unfiltered species have 2 or 4 listed as a habitat of majorImportance
habitat_prefs %>% 
  filter(suitability == "Suitable",
         majorImportance == "Yes",
         lc %in% c(2, 4)) %>% 
  .$binomial %>% unique() %>% length() 


species_list$binomial %>% unique() %>% length() # 2187 total species in species list

# 2003 species have grassland (2) or forest (4) listed as suitable habitats
species_list %>%
  filter(binomial %in% (habitat_prefs %>% 
                          filter(suitability == "Suitable",
                                 lc %in% c(2, 4)) %>% 
                          .$binomial %>% unique())
         ) %>% 
  .$binomial %>% unique() %>% length()


habitat_prefs$code %>% unique() %>% sort()
site_habitats %>% print(n = 40)

iucn_crosswalk %>% filter(code == "5.1")

# having added map_code to habitat_prefs for more exact filtering and joining...
habitat_prefs
site_habitats
iucn_crosswalk



site_habitats
jung_hab_type_area_df %>% select(habitat_type, code, lc, Coarse_Name, IUCNLevel) %>% unique() %>%
  arrange(habitat_type)


```


## Land cover classes in abandoned croplands 

```{r create-abn-age-masks}
# ------------------------------------------------------------ #
# create a mask of the abandonment age map, excluding ages < 5
plot(age_t[[9]][[31]])

tic()
abn_mask <- lapply(1:11, function(i) {
  abn_mask_tmp <- 
    classify(
      age_t[[i]],
      rcl = tibble(from = 5,
                   to = 30,
                   becomes = 0),
      othersNA = TRUE,
      include.lowest = TRUE, right = TRUE,
      filename = paste0(p_dat_derived, "age_rasters/", run_label, "/",
                        site_df$site[i], "_abn_5_30_mask", run_label,".tif"),
      names = paste0("y", 1987:2017),
      overwrite = TRUE)
})
toc()

abn_mask <- lapply(1:11, function(i){
  rast(paste0(p_dat_derived, "age_rasters/", run_label, "/",
              site_df$site[i], "_abn_5_30_mask", run_label,".tif"))
})

names(abn_mask) <- site_df$site

freq(abn_mask[[site_index]][[31]])

plot(abn_mask$shaanxi[[31]])
plot(lc[[site_index]][[28:31]])


# ------------------------------------------------------------ #
# create a mask of the *potential* abandonment age map, excluding ages < 5
tic()
potential_abn_mask <- lapply(1:11, function(i) {
  potential_abn_mask_tmp <- 
    classify(
      potential_age_t[[i]],
      rcl = tibble(from = 5,
                   to = 30,
                   becomes = 0),
      othersNA = TRUE,
      include.lowest = TRUE, right = TRUE,
      filename = paste0(p_dat_derived, "age_rasters/", run_label, "/",
                        site_df$site[i], "_potential_abn_5_30_mask", run_label,".tif"),
      names = paste0("y", 1987:2017),
      overwrite = TRUE)
})
toc()

potential_abn_mask <- lapply(1:11, function(i){
  rast(paste0(p_dat_derived, "age_rasters/", run_label, "/",
              site_df$site[i], "_potential_abn_5_30_mask", run_label,".tif"))
})

names(potential_abn_mask) <- site_df$site


# ---------------------------------------------------------------- #
# create mask of just 5-30 max_age

tic()
max_age_mask <- lapply(1:11, function(i) {
  max_age_mask_tmp <- 
    classify(
      max_age_t[[i]],
      rcl = tibble(from = 5,
                   to = 30,
                   becomes = 0),
      othersNA = TRUE,
      include.lowest = TRUE, right = TRUE,
      filename = 
        paste0(p_dat_derived, "max_age/", run_label, "/",
              site_df$site[i], "_max_age_5_30_mask", run_label,".tif"),
      names = "max_age_5_30_mask",
      overwrite = TRUE)
})
toc()

plot(max_age_mask[[1]])


max_age_mask <- lapply(1:11, function(i){
  rast(paste0(p_dat_derived, "max_age/", run_label, "/",
              site_df$site[i], "_max_age_5_30_mask", run_label,".tif"))
})
names(max_age_mask) <- site_df$site

```


```{r land-cover-of-abn-pixels}
# write code to calculate the land cover in each pixel 5 years and older
i <- 9
print(compareGeom(abn_mask[[i]], age_t[[i]]))
print(compareGeom(abn_mask[[i]], lcc[[i]]))

# Calculate the land cover of abandoned pixels for each year

# redoing this with the cleaned version of lc: lcc
tic()
abn_lcc <- lapply(1:11, function(i) {
  # make sure to restrict lc to only 1987:2017 (Nebraska, Wisconsin)
  # i <- 9
  cat("Masking:", site_df$site[i], "...", fill = TRUE)
  tmp <- abn_mask[[i]] + lcc[[i]][[paste0("y", 1987:2017)]]
  
  cat("Writing SpatRaster to file:", site_df$site[i], "...", fill = TRUE)
  writeRaster(tmp, 
              filename = paste0(p_derived, "abn_lcc/",
                        site_df$site[i], "_abn_lcc", run_label, ".tif"), 
              overwrite = TRUE,
              names = names(tmp))
  cat(site_df$site[i], "done!", fill = TRUE)

})
toc()


# reload
abn_lcc <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "abn_lcc/",
              site_df$site[i], "_abn_lcc", run_label, ".tif"))
  })
names(abn_lcc) <- site_df$site


plot(abn_lcc[[9]][[31]])




# ---------------------------------------------------------------- #
# calculate lc of all pixels that were ever abandoned
# ---------------------------------------------------------------- #

max_age_mask

tic()
max_abn_lcc <- lapply(1:11, function(i) {
  # make sure to restrict lc to only 1987:2017 (Nebraska, Wisconsin)
  # i <- 9
  cat("Masking:", site_df$site[i], "...", fill = TRUE)
  tmp <- max_age_mask[[i]] + lcc[[i]][[paste0("y", 1987:2017)]]
  
  cat("Writing SpatRaster to file:", site_df$site[i], "...", fill = TRUE)
  writeRaster(tmp, 
              filename = paste0(p_derived, "abn_lcc/",
                        site_df$site[i], "_max_abn_lcc", run_label, ".tif"), 
              overwrite = TRUE,
              names = paste0("y", 1987:2017))
  cat(site_df$site[i], "done!", fill = TRUE)

})
toc()


# reload
max_abn_lcc <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "abn_lcc/",
              site_df$site[i], "_max_abn_lcc", run_label, ".tif"))
  })
names(max_abn_lcc) <- site_df$site


```

```{r freq-abn-lc}

plot(abn_lc$shaanxi[[1:6]])
abn_lc
tmp <- freq(abn_lc$shaanxi)
i <- 9

nlyr(abn_lc[[i]])
abn_lc[[]]

abn_lc_freq <- lapply(1:11, function(i) {
  # the first five years (1987:1991) are NA, due to abandonment definition.
  tmp <- freq(abn_lc[[i]][[paste0("y", 1992:2017)]]) %>% 
    as_tibble() %>%
    rename(year = layer, lc = value) %>%
    mutate(year = year + 1991,
           site = site_df$site[i]) %>%
    select(site, year, lc, count)
  
  tmp
}
) %>% bind_rows


abn_lcc_freq <- lapply(9, function(i) {
  # the first five years (1987:1991) are NA, due to abandonment definition.
  tmp <- freq(abn_lcc[[paste0("y", 1992:2017)]]) %>% 
    as_tibble() %>%
    rename(year = layer, lc = value) %>%
    mutate(year = year + 1991,
           site = site_df$site[i]) %>%
    select(site, year, lc, count)
  
  tmp
}
) %>% bind_rows

# write to file
write_csv(abn_lc_freq, file = paste0(p_derived, "abn_lc_freq.csv"))

abn_lc_freq

# convert to percentages and plot

abn_lc_freq %>% 
  group_by(site, year) %>%
  summarise(site, year, lc, count,
            total = sum(count)) %>%
  ungroup() %>% 
  mutate(px = count/total * 100) %>%
  # filter(lc == 3) %>%
  ggplot(mapping = aes(x = year, y = px, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Percent of all abandoned pixels", col = "Land cover class") +
  facet_wrap(vars(site), scales = "free") + theme(legend.position = "bottom")




ggplot(data = abn_lcc_freq, 
       mapping = aes(x = year, y = area_ha, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Area (ha)", col = "Land cover class") +
  # facet_wrap(vars(site), scales = "free") + 
  theme(legend.position = "bottom")

ggplot(data = abn_lcc_freq, 
       mapping = aes(x = year, y = count, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Pixels", col = "Land cover class") +
  # facet_wrap(vars(site), scales = "free") + 
  theme(legend.position = "bottom")

```



## Temporal Filtering: land cover maps
```{r explore-tmp-filter}
obj_size(dt)

dt[y1987 > 0, ]

dt <- cc_create_dt()
dt1 <- cc_create_bin() + 1
dt2 <- cc_create_bin() + 2
dt3 <- cc_create_bin() + 3

dt1
dt2
dt3

dt <- rbind(dt1, dt2, dt3)
dt <- dt[, ':='(x = 1:nrow(dt), y = 1:nrow(dt))
                           ][, c("x", "y", paste0("V", 1:15))]

dt[V1 %in% c(2, 3)]



5:(ncol(dt) - 2)
i <- 9


# new filter:

dt <- fread(input = paste0(p_dat_derived, "input_data.tables/",
                           site_df$site[9], ".csv"),
            # select = c("x", "y", "y2017"),
            # nrows = 100000
            )

freq_before <- lapply(1987:2017, function(i){
      tmp <- dt[, .N, by = c(paste0("y", i))][,"year" := i]
      names(tmp) <- c("lc", "pixels", "year")
      tmp
    }) %>% bind_rows()

# for loop
tic()
for(lc_class in 1:4) {
  for (i in 5:(ncol(dt) - 2)) {
    dt[get(names(dt)[i-2]) == lc_class &  # subset to 1-1-0-1-1
         get(names(dt)[i-1]) == lc_class & 
         get(names(dt)[i]) %in% c(1:4)[1:4 != lc_class] & 
         get(names(dt)[i+1]) == lc_class & 
         get(names(dt)[i+2]) == lc_class,
       names(dt)[i] := lc_class # update value
    ]
  }
}
toc() # 103.199 seconds for Shaanxi (4.5x to get time for )


freq_after <- lapply(1987:2017, function(i){
      tmp <- dt[, .N, by = c(paste0("y", i))][,"year" := i]
      names(tmp) <- c("lc", "pixels", "year")
      tmp
    }) %>% bind_rows()

bind_rows(
  freq_before %>% as_tibble() %>% mutate(site = "shaanxi", time = "before"),
  freq_after %>% as_tibble() %>% mutate(site = "shaanxi", time = "after")) %>%
  ggplot(mapping = aes(x = year, y = pixels, col = as_factor(lc))) +
  geom_line() + 
  facet_wrap(vars(time))




# 8-year moving window

dt <- data.table(x = "x", y = "x", rbind(
  c(1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1),
  c(1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1),
  c(2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1),
  c(2, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2, 1, 2, 1, 1, 1, 1),
  c(4, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 4),
  c(4, 1, 1, 1, 4, 3, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1))
)

dt
cc_temporal_filter_lc(dt)
dt

dt[(V1 == 1 & V2 == 1) | (V1 == 4 & V2 == 4), ]
dt[(V1 == 1 & V2 == 1 | V1 == 4 & V2 == 4), ]

i <- 7

for(lc_class in 1:4) {
  blip_values <- c(1:4)[1:4 != lc_class]
  
  for (i in 6:(ncol(dt) - 4)) {
  dt[get(names(dt)[i-3]) == lc_class &
       get(names(dt)[i-2]) == lc_class &
       get(names(dt)[i-1]) == lc_class &
       # .e.g., if lc_class is 1, then these are 
       # (V4 == 2 & V5 == 2) | (V4 == 3 & V5 == 3) | (V4 == 4 & V5 == 4)
       ((get(names(dt)[i]) == blip_values[1] & get(names(dt)[i+1]) == blip_values[1]) | 
          (get(names(dt)[i]) == blip_values[2] & get(names(dt)[i+1]) == blip_values[2]) |
          (get(names(dt)[i]) == blip_values[3] & get(names(dt)[i+1]) == blip_values[3])) &
       get(names(dt)[i+2]) == lc_class &
       get(names(dt)[i+3]) == lc_class &
       get(names(dt)[i+4]) == lc_class, 
     
     c(names(dt)[i], 
       names(dt)[i+1]) := lc_class
     ]
  }
}


```

# Load and Process AOH

```{r hab-dt-options}
aoh_type_df # see _util_files.
aoh_type_df$label
```


```{r load-all-AOH}
run_label
aoh_run_date # see _util_main.R

list.files(paste0(p_derived, "aoh"), full.names = FALSE) %>%
  grep(".csv", ., value = TRUE) %>%
  # gsub("_2022_04_01", "", .) %>%
  # gsub("_2022_04_08", "", .) %>%
  # gsub("_2022_04_12", "", .) %>%
  gsub("_c[0-9]{1,2}", "", .) %>%
  gsub(".csv", "", .) %>%
  gsub("aoh_tmp_", "", .) %>% 
  unique()
  
aoh_type_df

aoh_types <- aoh_type_df$label[c(4:11)]
aoh_type_ <- aoh_type_df$label[9]

aoh_dates <-
  tibble(aoh_types,
         date = c("_2022_04_01", "_2022_04_01", "_2022_04_08", 
                  "_2022_04_01", "_2022_04_12", 
                  "_2022_04_15|_2022_04_16", "_2022_04_15|_2022_04_16",
                  "_2022_04_23"))

i <- 1
i
for (i in 1:21) {
list.files(paste0(p_derived, "aoh"), full.names = TRUE) %>%
  grep(aoh_type_, ., value = TRUE) %>%
  grep(filter(aoh_dates, aoh_types == aoh_type_)$date, ., value = TRUE) %>%
  grep(paste0("_c", i, ".csv"), ., value = TRUE) %>%
    print()
}

filter(aoh_dates, aoh_types == aoh_type_)$date

aoh_l <- lapply(aoh_types, 
  function(aoh_type_) {
  lapply(1:21, 
         function(i) {
    read_csv(
      list.files(paste0(p_derived, "aoh"), full.names = TRUE) %>%
        grep(aoh_type_, ., value = TRUE) %>%
        grep(filter(aoh_dates, aoh_types == aoh_type_)$date, ., value = TRUE) %>%
        grep(paste0("_c", i, ".csv"), ., value = TRUE)
      )
           }
    ) %>% 
    bind_rows() %>% 
    mutate(aoh_type = aoh_type_) %>%
    left_join(iucn_status, by = "binomial") %>%
    left_join(species_list, by = c("site", "binomial")) %>%
    left_join(
      select(st_drop_geometry(species_ranges), 
             site, vert_class, binomial, # presence, origin, seasonal, 
             total_range_area, range_size_quantile) %>% unique(),
              by = c("site", "binomial", "vert_class")) %>% 
    left_join(
      habitat_age_req_coded %>% 
        select(binomial, mature_forest_obl, water_obl, coder, common_names),
      by = "binomial")
}) %>% 
  bind_rows() %>%
  
  # create a composite area, which is either area_ha or adj_area_ha, depending on whether the run was lc or IUCN
  # mutate(
  #   aoh = case_when(
  #     grepl("lc", aoh_type) ~ adj_IUCN_aoh_ha,
  #     grepl("iucn", aoh_type) ~ IUCN_aoh_ha),
  #   area = case_when(
  #     grepl("lc", aoh_type) ~ adj_area_ha,
  #     grepl("iucn", aoh_type) ~ area_ha)) %>%
  
  select(aoh_type, vert_class, site, binomial, year, map_code, 
         # lc, 
         season = seasonality, 
         area = area_ha, 
         mature_forest_obl, redlistCategory, 
         # area_ha, 
         IUCN_aoh_ha,
         # adj_IUCN_aoh_ha, adj_area_ha,
         everything())


write_parquet(aoh_l, paste0(p_derived, "aoh_l.parquet"))


aoh_l <- read_parquet(paste0(p_derived, "aoh_l.parquet"))



aoh_species_list <- 
  aoh_l %>% 
  select(#aoh_type,
    vert_class, binomial, 
    redlistCategory, mature_forest_obl,
    total_range_area, range_size_quantile, common_names) %>%
  unique()

write_parquet(aoh_species_list, paste0(p_derived, "aoh_species_list.parquet"))
aoh_species_list <- read_parquet(paste0(p_derived, "aoh_species_list.parquet"))
```


Restricting by:
1. seasonality, so that only 1, 2, 3 are considered (Codes are: "Resident" (1), "Breeding" (2), "Non-breeding Season" (3), Passage (4), and Seasonal Occurrence Uncertain (5).)

2. only those map_codes (habitats) that are marked as majorImportance for the species.

3. mature_forest_obl, so that only non-mature forest obligates are included.
4. Abandonment only vs. the entire landscape

```{r filter-AOH-suitability-by-season}
# Extract a list of species with some habitat suitabilities with season marked as NA, and some with a code.
# In these contexts, the NA season should be filtered out.
# Note that some species have been directly updated in the creation of "habitat_prefs" [Glaucidium brodiei (collared owlet) and Mustela sibirica (siberian weasel)].
# For species with *only* NA season codes, I'll leave these in, and treat them as suitable in all seasons.

habitat_prefs %>%
  filter(binomial %in% unique(species_list$binomial), 
         !is.na(map_code), suitability == "Suitable") %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  # filter(!(vert_class == "bird" & is.na(season))) %>%
  group_by(season_code, vert_class) %>%
  summarise(n_sp = n()) %>%
  print(n = 30)

# ---------- #
# extract list of species with NA season suitabilities:
sp_w_na_suitabilities <- habitat_prefs %>%
  filter(is.na(season_code), suitability == "Suitable", !is.na(map_code)) %>%
  # select(binomial, season_code) %>% unique() %>%
  .$binomial %>% unique()

# ---------- #
# Extract list of species with some habitat suitabilities with season marked as NA, and some with a code.
# i.e., with more than one habitat suitability season code, one of which is NA
# In these contexts, the NA season should be filtered out.

sp_w_na_suit_and_more <- 
  habitat_prefs %>%
  filter(binomial %in% sp_w_na_suitabilities, suitability == "Suitable", !is.na(map_code)) %>%
  select(binomial, season_code) %>% unique() %>%
  group_by(binomial) %>% summarise(n_sp = n()) %>% arrange(desc(n_sp)) %>%
  filter(n_sp > 1) %>%
  left_join(habitat_age_req_coded %>% select(binomial, common_names, vert_class)) %>%
  .$binomial

# ------------------------------------- #
# extract a list of species with NA season_codes, so that I can make sure to treat them separately.
sp_na_season <- 
  habitat_prefs %>%
  filter(
    !(binomial %in% sp_w_na_suit_and_more & is.na(season_code)), # filter out NA season_codes for species with multiple season codes, one being NA 
    binomial %in% unique(species_list$binomial),
    !is.na(map_code), suitability == "Suitable",
    
    # select those species with na season codes
    is.na(season_code)
    ) %>%
  .$binomial %>% unique()
# 607 species


# ------------------------- #
# My approach is to use a simple inner_join to filter out mismatched combinations of season and habitat, and then manually add back in the species with NA season codes associated with their suitabilities (by binding to it a filtered aoh file with just the above species with NA season codes).

aoh_filter <- 
  aoh_l %>%
  # rename(season_code = season) %>% # must update so that season_code matches
  inner_join(
    habitat_prefs %>% # extract the habitat classifications for the species in question
      filter(suitability == "Suitable", !is.na(map_code)) %>%
      select(binomial, season_code, map_code) %>%
      mutate(season = season_code) # add a new column to 1) match season in aoh, and 2) to retain season_code
    ) %>%
  bind_rows(aoh_l %>% 
              filter(binomial %in% sp_na_season) %>% # to bind back to the inner_joined df
              mutate(season_code = NA)
            )

write_parquet(aoh_filter, paste0(p_derived, "aoh_filter.parquet"))
aoh_filter <- read_parquet(paste0(p_derived, "aoh_filter.parquet"))
```

```{r calc-aoh}
# calculate AOH for multiple conditions: across all habitats and seasons, and excluding passage areas:
aoh_filter

aoh <- lapply(c("include_passage", "exclude_passage"), function(i) {
  
  aoh_filter %>%
    
    # filtering out passage areas:
    # Codes are: "Resident" (1), "Breeding" (2), "Non-breeding Season" (3),
    # Passage (4), and Seasonal Occurrence Uncertain (5).
    {if (i == "exclude_passage") filter(., season %in% c(1, 2, 3)) else .} %>%
    
    # group and sum area to calculate AOH
    group_by(aoh_type, vert_class, site, binomial, year) %>% 
    summarise(aoh = sum(area, na.rm = TRUE)) %>%
    mutate(passage_type = i)
}) %>% bind_rows() %>% ungroup()

# ------------ #
# combine with relevant columns from aoh_l
aoh <- 
  aoh %>% 
  left_join(
    aoh_l %>% 
      select(aoh_type, vert_class, site, binomial, 
             redlistCategory, mature_forest_obl, common_names) %>% 
      unique()
  )


# Add a year0 that starts with 1 for the linear models.
# However, because crop_abn starts in different years, I need to
# extract the first year for each species, join that, and use that to determine year0.

aoh_start_years <-
  aoh %>%
  group_by(aoh_type, vert_class, site, binomial, passage_type) %>%
  summarise(start_year = min(year),
            end_year = max(year)) %>%
  ungroup()


# join and create year0
aoh <-
  aoh %>% 
  left_join(aoh_start_years) %>%
  mutate(year0 = year - start_year + 1)

# previous code
  # # in this case, the full, max_abn, and max_potential_abn runs all start in 1987
  # mutate(year0 = case_when(
  #   grepl("full|max", aoh_type) ~ year - 1986,
  #   grepl("^abn_|^potential", aoh_type) ~ year - 1991
  # ))

aoh %>%
  filter(binomial == "Boana albopunctata")


# --------------------------------------------------- #
# create an index for running the linear models,
# one index for each unique species at each site, in each of the aoh runs, with and without passage areas.
run_indices <- 
  aoh %>% 
  arrange(passage_type, aoh_type, vert_class, site, binomial) %>%
  select(aoh_type, vert_class, site, binomial, passage_type,
         common_names, redlistCategory, mature_forest_obl) %>%
  unique() %>% 
  mutate(run_index = 1:n())

# add this index back to the distilled df
aoh <- aoh %>%
  left_join(run_indices)


# Add in the number of observations, number of *unique* observations (in order to filter out constant AOH species, which mess with the models)
tic()
aoh <- aoh %>% 
  group_by(run_index) %>%
  mutate(n_obs = n(), 
         n_unique_obs = length(unique(aoh))) %>% 
  ungroup()
toc()


# save file ----------------- #
run_indices
write_parquet(run_indices, paste0(p_derived, "aoh_run_indices.parquet"))
write_parquet(aoh, paste0(p_derived, "aoh.parquet"))


# load back in -------------- #
aoh <- read_parquet(paste0(p_derived, "aoh.parquet"))
run_indices <- read_parquet(paste0(p_derived, "aoh_run_indices.parquet"))
```

## Explore AOH results
```{r taking-stock}
# -------------------------------------------------------- #

# taking stock:
# lots of stuff gets filtered out, which is why these numbers are not 2x each other.
aoh_l %>% select(aoh_type, site, binomial) %>% unique() # 10,739
aoh %>% select(aoh_type, site, binomial) %>% unique() # 8642 * 2
aoh %>% select(aoh_type, site, binomial, passage_type) %>% unique() # 17,266


aoh %>% group_by(aoh_type, site, binomial, vert_class) %>% 
  summarise(n_yr = length(year)) %>%
  filter(n_yr < 62)

species_list %>% nrow() # 4001 unique species - site combinations
aoh_l %>% 
  select(aoh_type, vert_class, site, binomial, 
         redlistCategory, mature_forest_obl, common_names) %>%
  unique() %>% nrow()


aoh$year0 %>% min()

aoh$year %>% summary()
aoh %>% group_by(aoh_type) %>% summarise(min_year = min(year), max_year = max(year))

# ------ extras ------- #

# test
aoh %>% 
  pivot_wider(id_cols = c(aoh_type:year), values_from = aoh, 
              names_from = passage_type, names_prefix = "aoh_") %>%
  mutate(test = include_passage - exclude_passage) %>%
  filter(test < -0.000000001)


# if you want to add it back to aoh_l, you can do this: but don't think this is necessary
aoh_l %>%
  left_join(
    aoh %>% 
      pivot_wider(id_cols = c(aoh_type:year), values_from = aoh, 
                  names_from = passage_type, names_prefix = "aoh_")
    ) %>% 
  select(aoh_type:area, starts_with("aoh"), everything()) %>%
  mutate(aoh_exclude_passage = case_when(
    season == 4 ~ NA_real_,
    TRUE ~ aoh_exclude_passage
  ))
```




```{r expl-aoh-l}
# number of species, records, etc.
aoh_l %>%
  group_by(aoh_type, vert_class) %>%
  summarise(num_records = n(),
            sp = length(unique(binomial))) %>%
  arrange(vert_class)

# number of records at each site:
aoh_l %>% 
  group_by(aoh_type, vert_class, site) %>%
  summarise(n_sp = length(unique(binomial))) %>%
  group_by(aoh_type, vert_class) %>% summarise(n = sum(n_sp))

# number of species in each model run
aoh_l %>% group_by(aoh_type) %>% summarise(n_sp = length(unique(binomial))) # there are different numbers of species due to variance in the habitats that show up in different parts of sites. 

# the lc runs have more, because they are not restricted to the habitats only in abandoned pixels. The proportional adjustment is based on the habitats that are present in any part of the site, not just the abn.

aoh_l %>% group_by(aoh_type, site) %>% 
  summarise(n_sp = length(unique(binomial))) %>%
  ungroup() %>% group_by(aoh_type) %>% summarise(n_runs = sum(n_sp))

i <- 9

missing_sp_aoh <- lapply(1:11, function(i){
  sp_run <- aoh_l %>% 
    filter(site == site_df$site[i]) %>%
    select(aoh_type:year, aoh) %>% 
    unique() %>%
    select(site, vert_class, binomial) %>% unique()
  
  sp_not_run <- species_list %>% filter(site == site_df$site[i]) %>%
    filter(!binomial %in% sp_run$binomial)
  sp_not_run
}) %>% bind_rows()

missing_sp_aoh

plot(site_sf[3,]$geometry)
species_ranges %>% 
  filter(binomial == "Cettia major") %>%
  st_geometry() %>%
  plot(add = T, border = "red")

aoh_l %>% 
  filter(binomial == "Cettia major")
habitat_prefs  %>% filter(binomial == "Cettia major") %>%
  .$code

iucn_crosswalk %>% 
  filter(code %in% filter(habitat_prefs, binomial == "Cettia major")$code)

jung_hab_type_area_df %>%
  filter(site == "chongqing")

```

```{r species-attributes}
aoh %>% 
  filter(
    # aoh_type %in% aoh_types[c(1, 3, 6, 7)],
         aoh > 0,
         vert_class != "amp",
         passage_type == "exclude_passage"
         ) %>%
  # select(aoh_type, vert_class, binomial, passage_type) %>%
  group_by(
    aoh_type,
           vert_class, passage_type) %>%
  summarise(n_sp = length(unique(binomial))) %>% # 1688
  ungroup() %>% group_by(aoh_type, passage_type) %>%
  mutate(total_mammals_and_birds = sum(n_sp)) %>%
  ungroup() %>% group_by(aoh_type) %>% mutate(N = sum(n_sp))

species_list


names(aoh_l)


# caution - slow.
species_attributes1 <- aoh_l %>% 
  select(vert_class, binomial, mature_forest_obl, 
         redlistCategory, total_range_area, range_size_quantile) %>% 
  unique()

species_attributes <-
  aoh %>% select(vert_class, binomial, mature_forest_obl, redlistCategory) %>% unique() %>%
  left_join(species_ranges %>% 
              st_drop_geometry() %>% as_tibble() %>%
              select(vert_class, binomial, total_range_area, range_size_quantile) %>% 
              unique())

```

```{r pivot-aoh}
aoh %>%
  filter(site == site_df$site[1], binomial == sp_name) %>% #print(n = 124)
  pivot_wider(
    id_cols = c("vert_class", "site", "binomial", 
                "redlistCategory", "year", "mature_forest_obl", "passage_type"),
    names_from = aoh_type, values_from = aoh, names_pref = "aoh_") %>%
  mutate(diff_obs = aoh_full_iucn - aoh_max_abn_iucn, 
         diff_pot = aoh_full_iucn - aoh_max_potential_abn_iucn) %>%
  pivot_longer(cols = c("aoh_full_iucn", "aoh_max_abn_iucn", 
                        "aoh_max_potential_abn_iucn", 
                        "diff_obs", "diff_pot"),
               names_to = "type", values_to = "aoh")
```

```{r how-many-species?}

# we calculated AOH for this many species: 
species_list %>%
  group_by(vert_class) %>%
  summarise(n_sp = length(unique(binomial)))
528+1495 # 2023 mammals and birds with ranges that intersected with one or more of our sites.


# we found that 1688 species of mammals and birds had non-zero AOH at our sites. 
aoh %>%
# aoh_feols_trends %>%
  filter(
    aoh_type %in% aoh_types[c(1, 3, 6, 7)],
    aoh > 0,
    vert_class != "amp",
    passage_type == "exclude_passage"
    ) %>%
  # select(aoh_type, vert_class, binomial, passage_type) %>%
  group_by(aoh_type, vert_class, passage_type,# trend
           # threatened = redlistCategory %in% c("Critically Endangered", "Endangered", "Vulnerable")
           ) %>%
  summarise(n_sp = length(unique(binomial))) %>% # 1688
  ungroup() %>% group_by(aoh_type, passage_type, 
                         #threatened
                         ) %>%
  mutate(total_mammals_and_birds = sum(n_sp)) %>%
  ungroup() %>% group_by(aoh_type) %>% mutate(N = sum(n_sp))

# ===== By site ====== #
aoh %>%
  filter(
    aoh_type %in% aoh_types[c(1, 3, 6, 7)],
    aoh > 0, vert_class != "amp", passage_type == "exclude_passage") %>%
  # select(aoh_type, vert_class, binomial, passage_type) %>%
  group_by(site,
           aoh_type, vert_class, passage_type#, trend
    ) %>%
  summarise(n_sp = length(unique(binomial))) %>% # 1688
  ungroup() %>% group_by(site, aoh_type, passage_type) %>%
  mutate(total_mammals_and_birds = sum(n_sp)) %>%
  filter(site == "wisconsin")


# missing one species in the second totaling:
spl_tmp1 <- aoh %>% 
  filter(aoh_type == "full_iucn", aoh > 0,
         vert_class != "amp", passage_type == "exclude_passage") %>%
  select(binomial) %>% unique()
spl_tmp2 <- aoh_trends_by_sp %>% 
  filter(aoh_type == "full_iucn",
         vert_class != "amp", passage_type == "exclude_passage") %>%
  select(binomial) %>% unique()

spl_tmp1 %>%
  filter(!binomial %in% spl_tmp2$binomial)

aoh %>% filter(binomial == "Phoenicurus erythrogastrus")
habitat_prefs %>% filter(binomial == "Phoenicurus erythrogastrus") %>%
  select(binomial, season, IUCNLevel, map_code)
jung_hab_type_area_df %>% filter(site == "shaanxi", habitat_type %in% c(306, 404, 600))

species_ranges %>% filter(binomial == "Phoenicurus erythrogastrus") %>% st_geometry() %>%
  plot(border = "red", add = TRUE)
site_sf %>% filter(site == "shaanxi") %>% st_geometry() %>% plot()

# ------------
# mature forest obligates
# aoh_trends_by_sp %>%
  aoh_feols_trends_by_sp %>%
  filter(passage_type == "exclude_passage",
         vert_class != "amp", 
         !aoh_type %in% c("abn_iucn", "potential_abn_iucn"),
         !grepl("potential", aoh_type),
         # aoh_type == "crop_abn_iucn",
         # mature_forest_obl < 0.5
         ) %>%
  group_by(aoh_type, vert_class, passage_type, 
           mature_forest_obl = case_when(
             mature_forest_obl <= 0.5 ~ "no",
             mature_forest_obl > 0.5 ~ "yes"),
           # overall_trend, trend_direction, trend_consistency
           ) %>%
  summarise(n_sp = n()) %>% ungroup() %>% 
  group_by(aoh_type, vert_class) %>% mutate(vN = sum(n_sp)) %>% ungroup() %>% 
  group_by(aoh_type) %>% mutate(N = sum(n_sp)) %>% ungroup() %>%
  arrange(mature_forest_obl, aoh_type, vert_class)


aoh_feols_trends_by_sp %>%
  filter(aoh_type == "crop_abn_iucn", passage_type == "exclude_passage", vert_class != "amp") %>%
  group_by(vert_class, 
           mature_forest_obligates = case_when(
             mature_forest_obl <= 0.5 ~ "no",
             mature_forest_obl > 0.5 ~ "yes")
           ) %>%
  summarise(n = n())

# ------- by site ------- #
aoh_feols_trends %>%
  filter(#site == "wisconsin", 
         aoh_type == "crop_abn_iucn", 
         vert_class != "amp",
         passage_type == "exclude_passage",
         mature_forest_obl < 0.5
         ) %>%
  group_by(aoh_type, site, vert_class,
           # mature_forest_obligates = case_when(
           #   mature_forest_obl <= 0.5 ~ "no",
           #   mature_forest_obl > 0.5 ~ "yes")
           ) %>%
  summarise(n = n()) %>% ungroup() %>%
  group_by(aoh_type, site) %>%
  mutate(vert_total = sum(n)) %>% ungroup() %>% print(n = 50)

# reproducing total. 
aoh_feols_trends %>%
  filter(aoh_type == "crop_abn_iucn", 
         vert_class != "amp",
         passage_type == "exclude_passage",
         mature_forest_obl < 0.5
         ) %>%
  select(aoh_type, vert_class, binomial) %>%
  unique() %>%
  group_by(aoh_type, vert_class) %>%
  summarise(n = n()) %>% ungroup() %>%
  group_by(aoh_type) %>%
  mutate(vert_total = sum(n)) %>% ungroup()


aoh_trends_by_sp %>%
  filter(vert_class == "mam" & mature_forest_obl < 0.5)

# small-ranged species
aoh_trends_by_sp %>% 
  filter(passage_type == "exclude_passage",
         vert_class != "amp", 
         !aoh_type %in% c("abn_iucn", "potential_abn_iucn"),
         !grepl("potential", aoh_type),
         # aoh_type == "crop_abn_iucn",
         mature_forest_obl < 0.5
         ) %>%
  group_by(aoh_type, vert_class, passage_type, 
           small = case_when(
             range_size_quantile <= 0.5 ~ "Range size <=\nglobal median",
             range_size_quantile > 0.5 ~ "Range size >\nglobal median"),
           # overall_trend, trend_direction, trend_consistency
           ) %>%
  summarise(n_sp = n())

aoh_trends_by_sp %>% 
  filter(passage_type == "exclude_passage",
         vert_class != "amp", 
         !aoh_type %in% c("abn_iucn", "potential_abn_iucn"),
         !grepl("potential", aoh_type),
         # aoh_type == "crop_abn_iucn",
         mature_forest_obl < 0.5,
         range_size_quantile <= 0.5) %>%
  select(aoh_type, vert_class, binomial, redlistCategory, overall_trend) %>%
  unique()
  
aoh_species_list %>%
  filter(aoh_type %in% aoh_types[c(1, 3, 6, 7)])# %>% # full, max, crop and crop_potential
  
```

```{r generate-final-species-list}
aoh_feols_trends %>%
  filter(aoh_type == "crop_abn_iucn", 
         vert_class != "amp",
         passage_type == "exclude_passage",
         # mature_forest_obl < 0.5
         ) %>%
  select(aoh_type, vert_class, binomial) %>%
  unique() %>%
  group_by(aoh_type, vert_class) %>%
  summarise(n = n()) %>% ungroup() %>%
  group_by(aoh_type) %>%
  mutate(vert_total = sum(n)) %>% ungroup()


# generating species list:

final_species_list <- 
  aoh_feols_trends %>%
  filter(aoh_type == "crop_abn_iucn", 
         vert_class != "amp",
         passage_type == "exclude_passage",
         # mature_forest_obl < 0.5
         ) %>%
  select(aoh_type, vert_class, binomial, passage_type, 
         site, redlistCategory, obligate_type) %>%
  pivot_wider(id_cols = c(aoh_type, vert_class, binomial, 
                          passage_type, redlistCategory, obligate_type),
              names_from = site, values_from = site) %>%
  unite("sites", c(belarus:wisconsin), sep = ", ", remove = TRUE, na.rm = TRUE) %>%
  left_join(aoh_feols_trends_by_sp %>% 
              select(aoh_type:passage_type, overall_trend, 
                     range_size_quantile, common_names),
            by = c("aoh_type", "vert_class", "binomial", "passage_type")) %>%
    select(vert_class, binomial, overall_trend, sites, 
           redlistCategory, obligate_type, range_size_quantile, common_names) #%>%
  # filter(obligate_type == "not_obligate")

write_csv(final_species_list, file = paste0(p_proj, "zenodo/final_species_list.csv"))




aoh_feols_trends_by_sp %>% # one trend per species
  filter(passage_type == "exclude_passage",
         vert_class != "amp", 
         !aoh_type %in% c("abn_iucn", "potential_abn_iucn"),
         !grepl("potential", aoh_type),
         # aoh_type == "crop_abn_iucn",
         # mature_forest_obl < 0.5
         ) %>%
  group_by(aoh_type, vert_class, passage_type, 
           mature_forest_obl = case_when(
             mature_forest_obl <= 0.5 ~ "no",
             mature_forest_obl > 0.5 ~ "yes"),
           # overall_trend, trend_direction, trend_consistency
           ) %>%
  summarise(n_sp = n()) %>% ungroup() %>% 
  group_by(aoh_type, vert_class) %>% mutate(vN = sum(n_sp)) %>% ungroup() %>% 
  group_by(aoh_type) %>% mutate(N = sum(n_sp)) %>% ungroup() %>%
  arrange(mature_forest_obl, aoh_type, vert_class)
```


```{r small-area-species}

aoh %>% 
  filter(# binomial == "Myotis evotis", year %in% 1990:1999, 
         str_detect(passage_type, "exc"),
         # aoh_type == "crop_abn_iucn"
         vert_class %in% c("mam", "bird"),
    # binomial == "Myotis septentrionalis"
    binomial == "Rhinolophus marshalli"
         ) %>%
  select(aoh_type:aoh,common_names, run_index) %>%
  group_by(run_index) %>%
  mutate(max_aoh = max(aoh)) %>%
  select(-c(aoh, year)) %>% unique() %>%
  filter(
    # max_aoh < 10,
         )



```


```{r weird-species}
aoh %>% filter(binomial == "Inia geoffrensis")
aoh_trends_by_sp %>% filter(binomial == "Inia geoffrensis")
aoh_trends_by_sp %>% filter(binomial == "Myotis evotis")
aoh_trends_by_sp %>% filter(binomial == "Ondatra zibethicus")
aoh_trends_by_sp %>% filter(binomial == "Panthera pardus")
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Trachypithecus francoisi", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))
aoh_trends_by_sp %>% filter(binomial == "Rhinolophus marshalli", str_detect(passage_type, "exc"))


aoh_trends_by_sp %>% filter(binomial == "Spermophilus citellus", str_detect(passage_type, "exc"))


aoh %>% filter(binomial == "Myotis evotis", aoh_type == "crop_abn_iucn",  str_detect(passage_type, "exc"))


aoh %>%
    filter(
      binomial == "Inia geoffrensis",
      passage_type == "exclude_passage"
      ) %>%
  select(aoh_type, site) %>% unique()

aoh %>%
    filter(
      binomial == "Lontra longicaudis",
      passage_type == "exclude_passage"
      ) %>%
  select(aoh_type, site) %>% unique()

aoh %>%
    filter(
      binomial == "Myotis evotis",
      passage_type == "exclude_passage"
      ) %>%
  select(aoh_type, site) %>% unique()



aoh %>%
  filter(
    # aoh_type == "crop_abn_iucn", 
    # binomial == "Inia geoffrensis",     
    # binomial == "Lontra longicaudis",
    # binomial == "Ondatra zibethicus",
    # binomial == "Myotis evotis",
    # binomial == "Panthera pardus",
    binomial == "Pteronura brasiliensis",
    passage_type == "exclude_passage"
    ) %>%
  # filter(aoh_type == "crop_abn_iucn") %>%
    
  ggplot(mapping = aes(x = year, y = aoh/10^3, 
                       col = aoh_type, group = aoh_type,
                       # col = binomial#common_names
                       )) + 
      theme_classic() + 
  geom_point() + 
  geom_smooth(method = "lm", se = 0.95) +
  labs(x = "Year", y = expression("AOH (10"^{3}*" ha)"), 
       col = "Species"
       ) +
  # scale_x_continuous(n.breaks = 6) +

  facet_grid(
    rows = vars(aoh_type),
    cols = vars(site), scales = "free") +

    theme(legend.position = "bottom") #+
  # guides(col = guide_legend(nrow = 3))

```


### Exploratory plots

```{r prelim-plots}
sp_to_plot <- "Agamia agami"
sp_to_plot <- "Certhia familiaris"
sp_to_plot <- "Argya altirostris"

sp_to_plot <- "Sturnella magna"
sp_to_plot <- "Hylatomus pileatus"

aoh %>%
  filter(binomial == sp_to_plot, aoh_type %in% aoh_type_df$label[c(9, 10)]) %>%
  ggplot(mapping = aes(x = year, y = aoh, 
                       col = aoh_type, group = aoh_type
                       )) +
  geom_point(position = position_jitter()) + 
        geom_smooth(method = "lm", se = 0.95) +

  labs(x = "Year", y = "AOH (ha)", caption = sp_to_plot) +
  facet_wrap(vars(site), scales = "free")

aoh %>% filter(binomial == sp_to_plot)

species_ranges %>%
  filter(binomial == sp_to_plot)

species_list %>%
  filter(str_detect(binomial, "pileatus"))



```


```{r example-plots-extracting-trend-abn}

sp_name <- "Certhia familiaris"
site_index <- 11

aoh %>%
  filter(binomial == "Sturnella magna", passage_type == "exclude_passage")

cc_plot_aoh_sp_site(binomial = c("Certhia familiaris", "Poecile palustris",
                                 "Agamia agami", "Anser fabalis"), 
                    site_index = c(1:11))

cc_plot_aoh_sp_site(binomial = c("Sturnella magna", "Hylatomus pileatus"), 
                    site_index = c(1:11))
sp_name <- "Sturnella magna"
sp_name <- "Hylatomus pileatus"

cc_plot_aoh_trend_sp_site(
  binomial = c("Certhia familiaris", "Poecile palustris",
               "Agamia agami", "Anser fabalis"), 
  site_index = c(1:11))

cc_plot_aoh_trend_sp_site(
  binomial = c("Sturnella magna", "Hylatomus pileatus"), 
  site_index = c(1:11))

aoh %>% 
  filter(run_index == 3) %>%
  ggplot(mapping = aes(x = year0, y = aoh)) +
  geom_point() + 
  geom_smooth(method = "lm", se = 0.95) + 
  labs(x = "Year", y = "AOH (ha)", title = unique(filter(aoh, run_index == i)$binomial))
  
# ------ #

 habitat_prefs %>% filter(str_detect(binomial, "Poecile palustris")) %>%
  select(binomial, name, season, suitability, map_code)

habitat_age_req_coded %>%
  filter(vert_class == "bird") %>%
  group()
  

# -------------------------------------------------- #
# declining trend

aoh_max_abn_change_df %>%
  left_join(run_indices_max_abn, by = "run_index") %>%
  filter(site == "shaanxi", rel_change < 0)

sp_name2 <- "Anser fabalis"

gg_aoh_example2 <-
  aoh_distill %>%
  filter(site == site_df$site[9], binomial == sp_name2) %>% #print(n = 124)
  pivot_wider(
    id_cols = c("vert_class", "site", "binomial", "redlistCategory", "year", "mature_forest_obl"),
              names_from = aoh_type, values_from = c("aoh", "aoh_no_passage")) %>% #unique() %>% print(n = 100)
  mutate(diff_iucn = aoh_full_iucn - aoh_max_abn_iucn, diff_lc = aoh_full_lc - aoh_max_abn_lc) %>%
  pivot_longer(cols = c("aoh_full_iucn", "aoh_max_abn_iucn", "aoh_full_lc", "aoh_max_abn_lc", "diff_iucn", "diff_lc"),
               names_to = "type", values_to = "aoh") %>%
  # print(n = 80)
  # filter(type %in% c("max_abn", "lc", "diff_max")) %>%
  
  ggplot(mapping = aes(x = year, y = aoh, col = type)) + 
  geom_line(size = 1.5) + 
  labs(x = "Year", y = "AOH (ha)", 
       title = paste(sp_name2, "(Taiga bean goose)"),
       subtitle = site_df$site[9]) +
  scale_color_manual(
    name = "Type",
                     labels = c("diff_iucn" = "Difference, IUCN",
                                "diff_lc" = "Difference, lc",
                                "aoh_full_iucn" = "Landscape, IUCN",
                                "aoh_full_lc" = "Landscape, lc",
                                "aoh_max_abn_iucn" = "Abandonment, IUCN",
                                "aoh_max_abn_lc" = "Abandonment, lc"),
                     values = gg_color_hue(6)
                     )
# save plot
ggsave(plot = gg_aoh_example2,
       filename = paste0(p_output, "plots/aoh/", "aoh_example_species2", aoh_run_date, ".pdf"),
     width = 8, height = 6, units = "in")


  

# What proportion of the change in habitat resulted from abandonment?


```

```{r remove-ag-conversion-signal}
# I need to figure out some way to extract just the signal of cropland -> abandonment
# This means that I need to find an intermediary between
# non-crop > cropland > abandonment

# the current max_abn layers have the full time series for each pixel
# this means that habitat loss at the start, before cropland abandonment is picked up.

# Probably best to do this using data.table. 
# look back at the step in cc_calc_age function to see 

```


# Models

## Develop Temporal Autocorrelation Approach

```{r examine-residuals}
aoh_tmp <- aoh %>% filter(aoh_type == "crop_abn_iucn")

# run across aoh_type, site, binomial, passage_type combinations
aoh_lm_resid_tmp <- lapply(
 unique(aoh_tmp$run_index)[1:10],
 function(i) {
   aoh_tmp %>% 
     filter(run_index == i) %>%
     lm(aoh ~ year0, data = .)
             })

aoh_lm_resid_tmp

# prelim model
mod_indx <- 1

aoh_lm_resid_tmp[[mod_indx]] %>% tidy(., conf.int = TRUE, conf.level = 0.95)
glance(aoh_lm_resid_tmp[[mod_indx]])
augment(aoh_lm_resid_tmp[[mod_indx]])

dev.off()
# par(mfrow = c(4,4))
for(i in 1:10) {
  plot(aoh_lm_resid_tmp[[i]], 1)
  Sys.sleep(2)
  }
plot(aoh_lm_resid_tmp[[mod_indx]], 1)
hist(aoh_lm_resid_tmp[[mod_indx]]$residuals, main = "Residual Histogram")


```


```{r temp-autocorr-dev}
# in order to account for temporal autocorrelation, test two approaches:

# ------- approach 1 ------- #
# including term for AOH in the prior year
# -------------------------- #

# prep ----
aoh
aoh_type_

aoh_tmp <- aoh %>% filter(aoh_type == aoh_type_)
aoh_tmp

df_sp_subset <- aoh %>%
  filter(binomial == sp_to_plot, 
         site == "shaanxi",
         aoh_type %in% aoh_type_df$label[9],
         passage_type == "exclude_passage"
         )

df_sp_subset <- aoh %>% filter(run_index == 4253)
aoh_trends %>% filter(run_index == 4253)
aoh_lag_trends %>% filter(run_index == 4253)
aoh_lm_lag %>% filter(run_index == 4253)

tst <- 
  df_sp_subset %>% 
  select(binomial, aoh, contains("year"), 
         passage_type, run_index) %>% #print(n  = 100)
  group_by(run_index) %>%
  mutate(aoh_lag = lag(aoh)) %>% #na.omit() %>% 
  filter(!is.na(aoh_lag)) %>%
  head()
  # filter(year < 1994) %>%
  # print(n = 100)



# prelim model
tmp_lm <- lm(aoh ~ year0, data = df_sp_subset)
tmp_lm_lag <- lm(aoh ~ year0 + aoh_lag, 
                 data = df_sp_subset %>% 
                   group_by(run_index) %>% 
                   mutate(aoh_lag = lag(aoh)) %>% filter(!is.na(aoh_lag)))
tidy(tmp_lm)
tidy(tmp_lm_lag, conf.int = TRUE, conf.level = 0.95)
summary(tmp_lm)
summary(tmp_lm_lag)
glance(tmp_lm_lag)

AIC(tmp_lm, tmp_lm_lag)

tmp_lm %>% tidy(., conf.int = TRUE, conf.level = 0.95)
tmp_lm_lag %>% tidy(., conf.int = TRUE, conf.level = 0.95)
glance(tmp_lm)
glance(tmp_lm_lag)

ggplot(data = df_sp_subset, 
       mapping = aes(x = year0, y = aoh)) +
  geom_point() + 
  # geom_smooth(method = "lm", se = 0.95) +
  labs(x = "Year", y = "AOH (ha)") +# , title = sp_to_plot) + 
  geom_line(data = augment(tmp_lm), mapping = aes(x = year0, y = .fitted), col = "red", alpha = 1) +
  geom_line(data = augment(tmp_lm_lag), mapping = aes(x = year0, y = .fitted), col = "blue", alpha = 1) #+ 
  # geom_function(fun = function(x) { (x-4) ^ (mean(coef(lm_log2_l[[9]]), na.rm = TRUE))},
  #               mapping = aes(linetype = "Mean Decay Rate"),
  #               color = "blue", size = 1, #linetype = "dashed",
  #               inherit.aes = FALSE)

```

```{r dw-test}
# Durbin Watson test:
library(car)

durbinWatsonTest(tmp_lm)

# Durbin-Watson DW test
library(lmtest)
dwtest(formula = tmp_lm,  alternative = "two.sided")


tic()
lapply(aoh_types, 
       function(aoh_type_) {
         aoh_tmp <- aoh %>% filter(aoh_type == aoh_type_)
         
         # run across aoh_type, site, binomial, passage_type combinations
         
         aoh_lm_dw_tmp <- lapply(
           unique(aoh_tmp$run_index),
           function(i) {
             aoh_tmp %>% 
               filter(run_index == i) %>%
               lm(aoh ~ year0, data = .) %>%
               car::durbinWatsonTest(.) %>%
               tidy(.) %>% 
               mutate(aoh_type = aoh_type_,
                      run_index = i)
             }) %>% bind_rows()
         
         write_parquet(aoh_lm_dw_tmp, paste0(p_derived, "aoh_lm_dwtest_", aoh_type_,".parquet"))
         
         cat("wrote aoh_lm_dw_test_tmp for:", aoh_type_, fill = TRUE)
         })
toc()
warnings()

# ------------------------------------------------------ #
# load back in:
# ------------------------------------------------------ #
aoh_lm_dw_test <- 
  lapply(aoh_types, 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_lm_dwtest_", aoh_type_,".parquet"))
}) %>% bind_rows()

run_indices
aoh_lm_dw_test$aoh_type %>% unique()
warnings()

write_parquet(aoh_lm_dw_test, paste0(p_derived, "aoh_lm_dw_test.parquet"))

aoh_lm_dw_test <- read_parquet(paste0(p_derived, "aoh_lm_dw_test.parquet"))

hist(aoh_lm_dw_test$statistic)

aoh_lm_dw_test %>% names()
aoh_trends %>% names()

ggsave(
  aoh_lm_dw_test %>% 
  left_join(select(aoh_feols_trends, aoh_type:obligate_type), by = c("run_index", "aoh_type")) %>%
    filter(aoh_type == "crop_abn_iucn",
           # exclude all species not affected by abandonment:
           binomial %in% unique(aoh_feols_trends_by_sp %>%
                                  filter(aoh_type == "crop_abn_iucn", passage_type == "exclude_passage",
                                         vert_class != "amp", mature_forest_obl < 0.5) %>%
                                  pull(binomial)),
           passage_type == "exclude_passage", # exclude passage areas from AOH calculations
           vert_class != "amp",
           !aoh_type %in% c("abn_iucn", "potential_abn_iucn"), # exclude unused scenarios
           # !grepl("potential", aoh_type),
           mature_forest_obl < 0.5) %>%
    ggplot(aes(x = statistic, fill = trend, group = trend)) +
    geom_histogram(binwidth = 0.1) + 
    theme_classic() + 
    labs(x = "Durbin-Watson Statistic (d)", y = "Count",
         caption = "Note: d = 2 indicates no autocorrelation,\nd < 2 indicates positive autocorrelation") +
    # facet_wrap(vars(aoh_type), scales = "free_y") + 
    theme(legend.position = c(0.8, 0.78)) +
    scale_fill_manual(name = "Trend", 
                      labels = palette_labels[c(1, 3, 6)],
                      values = palette_du_jour[c(1, 3, 6)]),
  filename = paste0(p_output, "plots/aoh/", "dw_stat_crop_abn_iucn", aoh_run_date, ".pdf"),
  width = 3.5, height = 3.5, units = "in")



```


```{r AR1-full}
# implement linear regression:
tic()
lapply(aoh_types[c(6, 7, 1, 8)][c(1)], 
       function(aoh_type_) {
         aoh_lag_tmp <- aoh %>% filter(aoh_type == aoh_type_) %>%
           group_by(run_index) %>% 
           mutate(aoh_lag = lag(aoh)) %>% 
           filter(!is.na(aoh_lag))

         # run across aoh_type, site, binomial, passage_type combinations
         aoh_lm_lag_tmp <- lapply(
           unique(aoh_lag_tmp$run_index),
           function(i) {
             aoh_lag_tmp %>% 
               filter(run_index == i) %>%
               lm(aoh ~ year0 + aoh_lag, data = .) %>%
               tidy(., conf.int = TRUE, conf.level = 0.95) %>% 
               mutate(aoh_type = aoh_type_,
                      run_index = i)
             }) %>% bind_rows()
         
         write_parquet(aoh_lm_lag_tmp, paste0(p_derived, "aoh_lm_lag_", aoh_type_,".parquet"))
         
         cat("wrote aoh_lm_lag_tmp for:", aoh_type_, fill = TRUE)
         })
toc()

# load back in:
aoh_lm_lag <- 
  lapply(aoh_types[6], 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_lm_lag_", aoh_type_,".parquet"))
}) %>% bind_rows()

aoh_lag_trends <- 
  aoh_lm_lag %>% 
  left_join(run_indices) %>%
  filter(term == "year0") %>%
  mutate(trend = case_when(
    estimate > 0 & p.value < 0.05 ~ "gain", # Statistically significant gain of AOH
    estimate < 0 & p.value < 0.05 ~ "loss", # Statistically significant loss of AOH
    p.value > 0.05 ~ "no trend" # no significant trend
    )) %>%
  select(term:binomial, trend, everything()) %>%
  mutate(aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
         obligate_type = case_when(
           mature_forest_obl > 0.5 ~ "mature_forest_obligate",
           mature_forest_obl < 0.5 ~ "not_obligate"))

aoh_lag_trends$vert_class %>% unique()
aoh_lm_lag %>% 
  select(aoh_type, run_index) %>% unique() %>%
  left_join(run_indices) %>%
  select(vert_class) %>% unique()

aoh_lag_trends_by_sp <- 
  aoh_lag_trends %>%
  filter(
    #passage_type == "exclude_passage"#, mature_forest_obl < 0.5
    !is.na(trend)) %>%
  select(aoh_type, vert_class, binomial, trend, passage_type) %>% 
  unique() %>% arrange(aoh_type, binomial, trend) %>%
  group_by(aoh_type, vert_class, binomial, passage_type) %>% 
  summarise(n_trends = n(), 
            trend_types = str_c(unique(trend), collapse = "; ")) %>% 
  # arrange(desc(n_trends)) %>%
  ungroup() %>%
  mutate(overall_trend = case_when(
    n_trends == 1 ~ trend_types,
    n_trends == 2 & trend_types == "gain; no trend" ~ "weak gain",
    n_trends == 2 & trend_types == "loss; no trend" ~ "weak loss",
    n_trends == 2 & trend_types == "gain; loss" | n_trends == 3 ~ "context dependent"
  )) %>%
  left_join(aoh_species_list) %>%
  
  # update factor levels
  mutate(
    trend_direction = case_when(
      grepl("gain", overall_trend) ~ "gain",
      grepl("loss", overall_trend) ~ "loss",
      grepl("context", overall_trend) ~ "context dependent",
      grepl("no trend", overall_trend) ~ "no trend"
      ) %>% fct_relevel(c("gain", "loss", "no trend", "context dependent")),
    trend_consistency = case_when(
      n_trends == 1 ~ "consistent",
      grepl("weak", overall_trend) ~ "weak",
      grepl("context", overall_trend) ~ "opposite"
      ) %>% #as_factor() %>% 
      fct_relevel(rev(c("consistent", "weak", "opposite"))),
    
    
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    redlistCategory = fct_relevel(redlistCategory, c("Least Concern", "Near Threatened", "Vulnerable", 
                                                     "Endangered", "Critically Endangered", "Data Deficient"))
    )
```


```{r AR1-plot}
# plot:
lapply(
  # aoh_types[c(6,3,1,7,5,8)],
  "crop_abn_iucn",
  function(i) {
  gg_aoh_lag_overall_tmp <-
    aoh_lag_trends_by_sp %>%
    filter(passage_type == "exclude_passage",
         vert_class != "amp",
         mature_forest_obl < 0.5,
         aoh_type == i
         ) %>% #.$vert_class %>% unique()
    mutate(vert_class = case_when(
      vert_class == "mam" ~ "Mammals",
      vert_class == "bird" ~ "Birds"),
      aoh_type = "Overall"
    ) %>%
  group_by(aoh_type, vert_class, passage_type,
           overall_trend, trend_direction, trend_consistency) %>%
  summarise(n_sp = n()) %>%
  arrange(vert_class, aoh_type) %>%
  ggplot(mapping = aes(
         x = aoh_type, y = n_sp,
         fill = overall_trend %>% fct_relevel(names(palette_du_jour))#[c(2, 1, 3, 4, 5, 6)])
         )) +
  geom_col(position = position_stack(reverse = TRUE), color = "black", size = .25) +
  theme_classic() +
  scale_x_discrete(labels = aoh_type_labels) + 
    scale_y_continuous(breaks = seq(from = 0, to = 1000, by = 100)) +
  labs(x = NULL, y = "Number of Species") +
  scale_fill_manual(name = "Trend", 
                    labels = palette_labels,
                    values = palette_du_jour) + 
  # guides(fill = guide_legend(ncol = 2, nrow = 3)) +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  facet_grid(
    # col = vars(vert_class), rows = vars(aoh_type),
    row = vars(vert_class), col = vars(aoh_type),
    scales = "free_y", #labeller = as_labeller(c(i = "Overall","mam" = "Mammals", "bird" = "Birds"))
    )

  gg_aoh_lag_by_site_tmp <-
    aoh_lag_trends %>%
      filter(!is.na(trend),
             passage_type == "exclude_passage",
             vert_class != "amp",
             mature_forest_obl < 0.5,
             aoh_type == i
             # redlistCategory != "Data Deficient"
             ) %>%
      group_by(aoh_type, vert_class, passage_type, 
               site,
               trend) %>%
      summarise(n_sp = n()) %>% ungroup() %>%
      arrange(vert_class, aoh_type) %>%
      ggplot(mapping = aes(
               x = vert_class, y = n_sp,
               fill = trend #%>% fct_relevel(names(palette_du_jour[c(1, 3, 6)])),
         )) +
  geom_col(position = position_dodge(preserve = "single"), 
           color = "black", size = .25) +
  theme_classic() + 
  labs(x = NULL, y = NULL, 
       caption = paste0(filter(aoh_type_df, label == i)$p5)
       ) +
  scale_fill_manual(name = "Trend",
                    labels = str_wrap(palette_labels, width = 6),#[c(1, 3, 6)],
                    values = palette_du_jour#[c(1, 3, 6)]
                    ) +
  scale_x_discrete(labels = aoh_type_labels) +
    guides(fill = guide_legend(ncol = 2, nrow = 3)) +

  theme(legend.position = c(0.84, 0.1),
        legend.text = element_text(size = 7)) +
  facet_wrap(vars(site), scales = "free", nrow = 4, ncol = 3,
             labeller = as_labeller(fancy_labels))

  ggsave(plot_grid(gg_aoh_lag_overall_tmp,
                   gg_aoh_lag_by_site_tmp,
                   nrow = 1, ncol = 2, 
                   # labels = "auto",
                   align = "h", axis= "b",
                   rel_widths = c(1, 3.3)
                   ),
         filename = paste0(p_output, "plots/aoh/", 
                           "aoh_lag_AR1_overall_w_site_combo_",
                           i, aoh_run_date, 
                           # "_no_lab",
                           ".pdf"),
         width = 6, height = 6, units = "in")
})


aoh_lag_trends %>% 
  filter(str_detect(binomial, "Agropsar"),
         aoh_type == "crop_abn_iucn", site == "shaanxi"
         )
# 4233

# just shaanxi
ggplotly(
  aoh %>%
  filter(aoh_type == "crop_abn_iucn", site == "shaanxi",
         vert_class == "bird",
         mature_forest_obl < 0.5,
         passage_type == "exclude_passage"
         ) %>%
  # left_join(aoh_trends) %>%
  left_join(aoh_lag_trends) %>%
  ggplot(aes(x = year, y = aoh/10^6, col = trend,
             group = binomial
             )) +
  geom_line(alpha = 0.15) + 
  theme_classic() + 
  scale_color_manual(labels = palette_labels[c(1, 3, 6)],
                     values = palette_du_jour[c(1, 3, 6)]) +
  scale_fill_manual(labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)]) +
  labs(y = expression("AOH (10"^{6}*" ha)"),
       x = "Year", col = "Trend", fill = "Mean Trend",
       caption = paste0(filter(aoh_type_df, label == i)$p5)) +
  guides(color = guide_legend(override.aes = list(alpha = 1, size = 1.5, order = 1))) +
  facet_wrap(vars(site), scales = "free_y")
)

```




```{r dev-floating-start-for-subset}
subset_gap <- 3

# cycle through each of the potential start years and calculate the number of observations after filtering:
tt <- lapply(c(3, 5), function(j) {
  lapply(c(1987, 1988, 1989, 1990, 1991), function(i) {
  aoh %>% 
  filter(aoh_type == aoh_type_,
         passage_type == "exclude_passage",
         # run_index %in% c(2990: 3000),
         # Subset to every three or five years, depending on the subset_gap j
         year %in% sort(10:0 * j + i)) %>% 
      select(-c(start_year, end_year)) %>%
  group_by(run_index) %>%
  mutate(n_obs = n(), gap = j) %>% 
  ungroup() %>%
    select(aoh_type, vert_class, site, binomial, run_index, n_obs) %>% unique() %>%
    mutate(start_year = i, gap = j)
  }) %>% bind_rows()
}) %>% bind_rows() %>%
  filter(!(gap == 3 & start_year %in% c(1990, 1991))) %>% ungroup()

# select the highest number of observations for each run_index, and then sum up for each start year 
tt %>% arrange(run_index, gap, desc(n_obs), start_year) %>% #filter(str_detect(binomial, "Circus")) %>% 
  group_by(run_index, gap) %>%
  slice_max(n_obs, n = 1, with_ties = FALSE) %>% ungroup() %>%
  group_by(start_year, gap, n_obs) %>% 
  summarise(count = n()) %>% ungroup() %>% 
  arrange(gap, start_year)

# number of unique runs
aoh %>% filter(aoh_type == aoh_type_, passage_type == "exclude_passage") %>% .$run_index %>% unique() %>% length()
tt$run_index %>% unique() %>% length()

# my conclusion is that the vast vast majority of species have the greatest number of observations for the subset ending in 2017, for both 3 and 5 year gaps

```


```{r subsample-3-5}
aoh %>% filter(aoh_type == aoh_type_) %>% .$run_index %>% unique() %>% sort() %>% tail

# implement linear regression:
tic()
lapply(c(3, 5), function(subset_gap) {
  lapply(aoh_types[c(6, 7, 1, 8)][c(1)], 
       function(aoh_type_) {
         aoh_subset_tmp <-
           aoh %>% 
           filter(aoh_type == aoh_type_,
                  # passage_type == "exclude_passage",
                  # run_index %in% c(1:2990),
                  # Subset to every three or five years, depending on the subset_gap
                  year %in% sort(10:0 * subset_gap + 1987)) %>%
           group_by(run_index) %>%
           mutate(n_obs = n(), year_gap = subset_gap) %>% 
           ungroup()

         # run across aoh_type, site, binomial, passage_type combinations
         aoh_lm_subset_tmp <- lapply(
           unique(aoh_subset_tmp$run_index),
           function(i) {
             aoh_subset_tmp %>% 
               filter(run_index == i) %>%
               lm(aoh ~ year0, data = .) %>%
               tidy(., conf.int = TRUE, conf.level = 0.95) %>% 
               mutate(aoh_type = aoh_type_,
                      run_index = i)
             }) %>% bind_rows() %>% 
           left_join(aoh_subset_tmp %>% 
                       select(aoh_type:binomial, run_index, n_obs, year_gap,
                              redlistCategory:end_year, passage_type) %>% 
                       unique())
         
         write_parquet(aoh_lm_subset_tmp, paste0(p_derived, "aoh_lm_subset", 
                                                  subset_gap, "_", aoh_type_,".parquet"))
         
         # print(
           cat("wrote aoh_lm_subset_tmp for:", aoh_type_, ", with year gap:", subset_gap, fill = TRUE)#)
         })
})
toc()

# load back in:
aoh_lm_subset3 <- 
  lapply(aoh_types[6], 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_lm_subset3_", aoh_type_,".parquet"))
}) %>% bind_rows()

aoh_lm_subset5 <- 
  lapply(aoh_types[6], 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_lm_subset5_", aoh_type_,".parquet"))
}) %>% bind_rows()


# identify species with NA values, and visualise these species:
aoh_lm_subset3 %>% filter(if_any(!c(mature_forest_obl, common_names), is.na) | n_obs < 5) %>% arrange(desc(n_obs)) %>% print(n = 50)
aoh_lm_subset5 %>% filter(if_any(!c(mature_forest_obl, common_names), is.na) | n_obs < 5,
                          p.value < 0.05, term == "year0") %>% arrange(desc(n_obs)) %>% print(n = 50)
# just two species of bird that have statistically significant slopes, and 3 or 4 observations: Spix's Woodcreeper (Xiphorhynchus spixii) and Vinaceous Rosefinch (Carpodacus vinaceus)


aoh %>% 
  filter(aoh_type == aoh_type_, 
         str_detect(passage_type, "excl"),
         year %in% sort(10:0 * 3 + 1987),
         run_index %in% unique(filter(aoh_lm_subset3, if_any(!c(mature_forest_obl, common_names), is.na) | n_obs < 5)$run_index)) %>%
  ggplot(aes(x = year, y = aoh, group = run_index, col = as_factor(run_index))) + 
  geom_line() + geom_point() + facet_wrap(vars(run_index, binomial), scales = "free")
# there is only two 3- or 4-observation species, and both are not statistically significant.

aoh %>% 
  filter(aoh_type == aoh_type_, 
         str_detect(passage_type, "excl"),
         year %in% sort(10:0 * 5 + 1987),
         run_index %in% unique(filter(aoh_lm_subset5, if_any(!c(mature_forest_obl, common_names), is.na) | n_obs < 5)$run_index)) %>%
  ggplot(aes(x = year, y = aoh, group = run_index, col = as_factor(run_index))) + 
  geom_line() + geom_point() + facet_wrap(vars(run_index, binomial), scales = "free")
# there are 

filter(aoh_lm_subset5, if_any(!c(mature_forest_obl, common_names), is.na) | n_obs < 5)



bind_rows(aoh_lm_subset3, aoh_lm_subset5)
#  distill trends:

# ------------ #
# distilling trends for a gap of 3 years
# ------------ #
aoh_lm_subset3_trends <- 
  aoh_lm_subset3 %>%
  # aoh_lm_subset5 %>%
  # bind_rows(aoh_lm_subset3, aoh_lm_subset5) %>%
  filter(!if_any(!c(mature_forest_obl, common_names), is.na)) %>% # filter out NAs:
  left_join(run_indices) %>%
  filter(term == "year0") %>%
  mutate(trend = case_when(
    estimate > 0 & p.value < 0.05 ~ "gain", # Statistically significant gain of AOH
    estimate < 0 & p.value < 0.05 ~ "loss", # Statistically significant loss of AOH
    p.value > 0.05 ~ "no trend" # no significant trend
    )) %>%
  select(term:binomial, trend, everything()) %>%
  mutate(
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    obligate_type = case_when(
      mature_forest_obl > 0.5 ~ "mature_forest_obligate",
      mature_forest_obl < 0.5 ~ "not_obligate"))

aoh_lm_subset3_trends
aoh_lm_subset3_trends1
aoh_lm_subset3_trends$aoh_type
aoh_lm_subset3_trends1$aoh_type
identical(select(aoh_lm_subset3_trends, -aoh_type), select(aoh_lm_subset3_trends1, -aoh_type))

aoh_lm_subset3_trends$vert_class %>% unique()
aoh_lm_subset3 %>% 
  select(aoh_type, run_index) %>% unique() %>%
  left_join(run_indices) %>%
  select(vert_class) %>% unique()

aoh_lm_subset3_trends_by_sp <- 
  aoh_lm_subset3_trends %>%
  filter(
    #passage_type == "exclude_passage"#, mature_forest_obl < 0.5
    !is.na(trend)) %>%
  select(aoh_type, vert_class, binomial, trend, passage_type) %>% 
  unique() %>% arrange(aoh_type, binomial, trend) %>%
  group_by(aoh_type, vert_class, binomial, passage_type) %>% 
  summarise(n_trends = n(), 
            trend_types = str_c(unique(trend), collapse = "; ")) %>% 
  # arrange(desc(n_trends)) %>%
  ungroup() %>%
  mutate(overall_trend = case_when(
    n_trends == 1 ~ trend_types,
    n_trends == 2 & trend_types == "gain; no trend" ~ "weak gain",
    n_trends == 2 & trend_types == "loss; no trend" ~ "weak loss",
    n_trends == 2 & trend_types == "gain; loss" | n_trends == 3 ~ "context dependent"
  )) %>%
  left_join(aoh_species_list) %>%
  
  # update factor levels
  mutate(
    trend_direction = case_when(
      grepl("gain", overall_trend) ~ "gain",
      grepl("loss", overall_trend) ~ "loss",
      grepl("context", overall_trend) ~ "context dependent",
      grepl("no trend", overall_trend) ~ "no trend"
      ) %>% fct_relevel(c("gain", "loss", "no trend", "context dependent")),
    trend_consistency = case_when(
      n_trends == 1 ~ "consistent",
      grepl("weak", overall_trend) ~ "weak",
      grepl("context", overall_trend) ~ "opposite"
      ) %>% #as_factor() %>% 
      fct_relevel(rev(c("consistent", "weak", "opposite"))),
    
    
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    redlistCategory = fct_relevel(redlistCategory, c("Least Concern", "Near Threatened", "Vulnerable", 
                                                     "Endangered", "Critically Endangered", "Data Deficient"))
    )



# ------------ #
# distilling trends for a gap of 5 years
# ------------ #
aoh_lm_subset5_trends <- 
  aoh_lm_subset5 %>%
  # aoh_lm_subset5 %>%
  # bind_rows(aoh_lm_subset3, aoh_lm_subset5) %>%
  filter(!if_any(!c(mature_forest_obl, common_names), is.na)) %>% # filter out NAs:
  left_join(run_indices) %>%
  filter(term == "year0") %>%
  mutate(trend = case_when(
    estimate > 0 & p.value < 0.05 ~ "gain", # Statistically significant gain of AOH
    estimate < 0 & p.value < 0.05 ~ "loss", # Statistically significant loss of AOH
    p.value > 0.05 ~ "no trend" # no significant trend
    )) %>%
  select(term:binomial, trend, everything()) %>%
  mutate(
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    obligate_type = case_when(
      mature_forest_obl > 0.5 ~ "mature_forest_obligate",
      mature_forest_obl < 0.5 ~ "not_obligate"))


aoh_lm_subset5_trends_by_sp <- 
  aoh_lm_subset5_trends %>%
  filter(
    #passage_type == "exclude_passage"#, mature_forest_obl < 0.5
    !is.na(trend)) %>%
  select(aoh_type, vert_class, binomial, trend, passage_type) %>% 
  unique() %>% arrange(aoh_type, binomial, trend) %>%
  group_by(aoh_type, vert_class, binomial, passage_type) %>% 
  summarise(n_trends = n(), 
            trend_types = str_c(unique(trend), collapse = "; ")) %>% 
  # arrange(desc(n_trends)) %>%
  ungroup() %>%
  mutate(overall_trend = case_when(
    n_trends == 1 ~ trend_types,
    n_trends == 2 & trend_types == "gain; no trend" ~ "weak gain",
    n_trends == 2 & trend_types == "loss; no trend" ~ "weak loss",
    n_trends == 2 & trend_types == "gain; loss" | n_trends == 3 ~ "context dependent"
  )) %>%
  left_join(aoh_species_list) %>%
  
  # update factor levels
  mutate(
    trend_direction = case_when(
      grepl("gain", overall_trend) ~ "gain",
      grepl("loss", overall_trend) ~ "loss",
      grepl("context", overall_trend) ~ "context dependent",
      grepl("no trend", overall_trend) ~ "no trend"
      ) %>% fct_relevel(c("gain", "loss", "no trend", "context dependent")),
    trend_consistency = case_when(
      n_trends == 1 ~ "consistent",
      grepl("weak", overall_trend) ~ "weak",
      grepl("context", overall_trend) ~ "opposite"
      ) %>% #as_factor() %>% 
      fct_relevel(rev(c("consistent", "weak", "opposite"))),
    
    
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    redlistCategory = fct_relevel(redlistCategory, c("Least Concern", "Near Threatened", "Vulnerable", 
                                                     "Endangered", "Critically Endangered", "Data Deficient"))
    )
```

```{r subset3-5-plots}
# 3 year gap
# plot:
lapply(
  # aoh_types[c(6,3,1,7,5,8)],
  "crop_abn_iucn",
  function(i) {
  gg_aoh_subset3_overall_tmp <-
    aoh_lm_subset3_trends_by_sp %>%
    filter(passage_type == "exclude_passage",
         vert_class != "amp",
         mature_forest_obl < 0.5,
         aoh_type == i
         ) %>% #.$vert_class %>% unique()
    mutate(vert_class = case_when(
      vert_class == "mam" ~ "Mammals",
      vert_class == "bird" ~ "Birds"),
      aoh_type = "Overall"
    ) %>%
  group_by(aoh_type, vert_class, passage_type,
           overall_trend, trend_direction, trend_consistency) %>%
  summarise(n_sp = n()) %>%
  arrange(vert_class, aoh_type) %>%
  ggplot(mapping = aes(
         x = aoh_type, y = n_sp,
         fill = overall_trend %>% fct_relevel(names(palette_du_jour))#[c(2, 1, 3, 4, 5, 6)])
         )) +
  geom_col(position = position_stack(reverse = TRUE), color = "black", size = .25) +
  theme_classic() +
  scale_x_discrete(labels = aoh_type_labels) + 
    scale_y_continuous(breaks = seq(from = 0, to = 1000, by = 100)) +
  labs(x = NULL, y = "Number of Species") +
  scale_fill_manual(name = "Trend", 
                    labels = palette_labels,
                    values = palette_du_jour) + 
  # guides(fill = guide_legend(ncol = 2, nrow = 3)) +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  facet_grid(
    # col = vars(vert_class), rows = vars(aoh_type),
    row = vars(vert_class), col = vars(aoh_type),
    scales = "free_y", #labeller = as_labeller(c(i = "Overall","mam" = "Mammals", "bird" = "Birds"))
    )

  gg_aoh_subset3_by_site_tmp <-
    aoh_lm_subset3_trends %>%
      filter(!is.na(trend),
             passage_type == "exclude_passage",
             vert_class != "amp",
             mature_forest_obl < 0.5,
             aoh_type == i
             # redlistCategory != "Data Deficient"
             ) %>%
      group_by(aoh_type, vert_class, passage_type, 
               site,
               trend) %>%
      summarise(n_sp = n()) %>% ungroup() %>%
      arrange(vert_class, aoh_type) %>%
      ggplot(mapping = aes(
               x = vert_class, y = n_sp,
               fill = trend #%>% fct_relevel(names(palette_du_jour[c(1, 3, 6)])),
         )) +
  geom_col(position = position_dodge(preserve = "single"), 
           color = "black", size = .25) +
  theme_classic() + 
  labs(x = NULL, y = NULL, 
       caption = paste0(filter(aoh_type_df, label == i)$p5)
       ) +
  scale_fill_manual(name = "Trend",
                    labels = str_wrap(palette_labels, width = 6),#[c(1, 3, 6)],
                    values = palette_du_jour#[c(1, 3, 6)]
                    ) +
  scale_x_discrete(labels = aoh_type_labels) +
    guides(fill = guide_legend(ncol = 2, nrow = 3)) +

  theme(legend.position = c(0.84, 0.1),
        legend.text = element_text(size = 7)) +
  facet_wrap(vars(site), scales = "free", nrow = 4, ncol = 3,
             labeller = as_labeller(fancy_labels))

  ggsave(plot_grid(gg_aoh_subset3_overall_tmp,
                   gg_aoh_subset3_by_site_tmp,
                   nrow = 1, ncol = 2, 
                   # labels = "auto",
                   align = "h", axis= "b",
                   rel_widths = c(1, 3.3)
                   ),
         filename = paste0(p_output, "plots/aoh/", 
                           "aoh_subset3_overall_w_site_combo_",
                           i, aoh_run_date, 
                           # "_no_lab",
                           ".pdf"),
         width = 6, height = 6, units = "in")
})


# ------------------------------------------------------- #
# 5 year gap
# plot:
lapply(
  # aoh_types[c(6,3,1,7,5,8)],
  "crop_abn_iucn",
  function(i) {
  gg_aoh_subset5_overall_tmp <-
    aoh_lm_subset5_trends_by_sp %>%
    filter(passage_type == "exclude_passage",
         vert_class != "amp",
         mature_forest_obl < 0.5,
         aoh_type == i
         ) %>% #.$vert_class %>% unique()
    mutate(vert_class = case_when(
      vert_class == "mam" ~ "Mammals",
      vert_class == "bird" ~ "Birds"),
      aoh_type = "Overall"
    ) %>%
  group_by(aoh_type, vert_class, passage_type,
           overall_trend, trend_direction, trend_consistency) %>%
  summarise(n_sp = n()) %>%
  arrange(vert_class, aoh_type) %>%
  ggplot(mapping = aes(
         x = aoh_type, y = n_sp,
         fill = overall_trend %>% fct_relevel(names(palette_du_jour))#[c(2, 1, 3, 4, 5, 6)])
         )) +
  geom_col(position = position_stack(reverse = TRUE), color = "black", size = .25) +
  theme_classic() +
  scale_x_discrete(labels = aoh_type_labels) + 
    scale_y_continuous(breaks = seq(from = 0, to = 1000, by = 100)) +
  labs(x = NULL, y = "Number of Species") +
  scale_fill_manual(name = "Trend", 
                    labels = palette_labels,
                    values = palette_du_jour) + 
  # guides(fill = guide_legend(ncol = 2, nrow = 3)) +
  theme(legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  facet_grid(
    # col = vars(vert_class), rows = vars(aoh_type),
    row = vars(vert_class), col = vars(aoh_type),
    scales = "free_y", #labeller = as_labeller(c(i = "Overall","mam" = "Mammals", "bird" = "Birds"))
    )

  gg_aoh_subset5_by_site_tmp <-
    aoh_lm_subset5_trends %>%
      filter(!is.na(trend),
             passage_type == "exclude_passage",
             vert_class != "amp",
             mature_forest_obl < 0.5,
             aoh_type == i
             # redlistCategory != "Data Deficient"
             ) %>%
      group_by(aoh_type, vert_class, passage_type, 
               site,
               trend) %>%
      summarise(n_sp = n()) %>% ungroup() %>%
      arrange(vert_class, aoh_type) %>%
      ggplot(mapping = aes(
               x = vert_class, y = n_sp,
               fill = trend #%>% fct_relevel(names(palette_du_jour[c(1, 3, 6)])),
         )) +
  geom_col(position = position_dodge(preserve = "single"), 
           color = "black", size = .25) +
  theme_classic() + 
  labs(x = NULL, y = NULL, 
       caption = paste0(filter(aoh_type_df, label == i)$p5)
       ) +
  scale_fill_manual(name = "Trend",
                    labels = str_wrap(palette_labels, width = 6),#[c(1, 3, 6)],
                    values = palette_du_jour#[c(1, 3, 6)]
                    ) +
  scale_x_discrete(labels = aoh_type_labels) +
    guides(fill = guide_legend(ncol = 2, nrow = 3)) +

  theme(legend.position = c(0.84, 0.1),
        legend.text = element_text(size = 7)) +
  facet_wrap(vars(site), scales = "free", nrow = 4, ncol = 3,
             labeller = as_labeller(fancy_labels))

  ggsave(plot_grid(gg_aoh_subset5_overall_tmp,
                   gg_aoh_subset5_by_site_tmp,
                   nrow = 1, ncol = 2, 
                   # labels = "auto",
                   align = "h", axis= "b",
                   rel_widths = c(1, 3.3)
                   ),
         filename = paste0(p_output, "plots/aoh/", 
                           "aoh_subset5_overall_w_site_combo_",
                           i, aoh_run_date, 
                           # "_no_lab",
                           ".pdf"),
         width = 6, height = 6, units = "in")
})


```


```{r compare-approaches-w-summary-stats}
# aoh_trends_by_sp %>%
# aoh_lag_trends_by_sp %>%
# aoh_lm_subset3_trends_by_sp %>%
# aoh_lm_subset5_trends_by_sp %>%
comparing_tmp_auto_stats_df <-
  bind_rows(aoh_trends_by_sp %>% mutate(type = "OLS"),
            aoh_feols_trends_by_sp %>% mutate(type = "NW"),
          aoh_lm_subset3_trends_by_sp %>% mutate(type = "Subset 3"),
          aoh_lm_subset5_trends_by_sp %>% mutate(type = "Subset 5"),
          aoh_lag_trends_by_sp %>% mutate(type = "AR1")) %>%
  mutate(type = as_factor(type),
         overall_trend = fct_relevel(overall_trend, c("gain", "loss", "no trend", "weak gain", "weak loss", "context dependent"))) %>%
  filter(aoh_type == "crop_abn_iucn", 
         # type == "OLS",
         passage_type == "exclude_passage",
         vert_class != "amp", 
         mature_forest_obl < 0.5
         ) %>%
  group_by(type, aoh_type, vert_class, passage_type,
           overall_trend, trend_direction) %>%
  summarise(n_sp = n()) %>%
  arrange(
    #overall_trend, 
    type,
    vert_class, 
    # type,
    aoh_type) %>%
  ungroup() %>%
  group_by(type, aoh_type, vert_class) %>%
  mutate(total_sp = sum(n_sp),
         r = n_sp/total_sp,
         p = 100 * r,
         pr = round(p, digits = 2),
         pp = paste0(prettyNum(pr, nsmall = 2), "%")) %>% ungroup() %>%
  select(type, overall_trend, vert_class, r#, n_sp:pr
         ) %>%
  pivot_wider(id_cols = c(type, vert_class), 
              names_from = overall_trend, values_from = r) %>%
  arrange(vert_class, type)

write_csv(comparing_tmp_auto_stats_df, paste0(p_derived, "comparing_stats_df.csv"))


(200 * (2/3) + 150 * (1/3)) * 2

library(gt)

# produce a table:
gt_tauto <- comparing_tmp_auto_stats_df %>%
  gt() %>%
  tab_header(title = "Table 1. Summary statistics using various methods to address temporal autocorrelation.") %>%
  tab_options(heading.align = "left") %>%
  cols_label(
    type = "Model Type",
    vert_class = "Vert. Class",
    gain = "Gain", loss = "Loss", `no trend` = "No Trend", 
    `weak gain` = "Weak Gain", `weak loss` = "Weak Loss", `context dependent` = "Some Gains,\n Some Losses") %>%
  cols_align(align = "left", columns = everything()) %>%
  tab_source_note(source_note = md("*OLS*: simplest linear regression;   *NW*: OLS regression w/ Newey-West standard errors;")) %>%
  tab_source_note(source_note = md("*Subset*: OLS regression w/ every 3 or 5 years;   *AR1*: OLS w/ autoregressive term (AOH in prior year)")) %>%
  # tab_footnote(footnote = "Simplest OLS regression.", locations = cells_body(columns = type, rows = 1:2)) %>%
  # tab_footnote(footnote = "OLS regression w/ Newey-West standard errors.", locations = cells_body(columns = type, rows = 3:4)) %>%
  # tab_footnote(footnote = "OLS regression w/ every 3 or 5 years.", locations = cells_body(columns = type, rows = 5:8)) %>%
  # tab_footnote(footnote = "OLS w/ autoregressive term (AOH in prior year)", locations = cells_body(columns = type, rows = 9:10))

  # tab_row_group(label = "Simplest OLS regression.", rows = 1:2) %>%
  # tab_row_group(label = "OLS regression w/ Newey-West standard errors.", rows = 3:4) %>%
  # tab_row_group(label = "OLS regression w/ every 3 or 5 years.", rows = 5:8) %>%
  # tab_row_group(label = "OLS w/ autoregressive term (AOH in prior year)", rows = 9:10)
  # opt_row_striping() 
  data_color(columns = gain, colors = colorRampPalette(c("white", palette_du_jour[1]))(10)) %>%
  data_color(columns = loss, colors = colorRampPalette(c("white", palette_du_jour[6]))(10)) %>%
  data_color(columns = `no trend`, colorRampPalette(c("white", palette_du_jour[3]))(10)) %>%
  fmt_percent(columns = 3:8,  decimals = 1)


gtsave(gt_tauto, filename = paste0(p_derived, "comparing_stats_tauto_table_arranged.pdf"))
gtsave(gt_tauto, filename = paste0(p_derived, "comparing_stats_tauto_table_arranged.png"))





# ----------------------------------------------------------- #
# -- NW -- comparing observed vs. potential, across calculations
# ----------------------------------------------------------- #
aoh_feols_trends_by_sp$aoh_type %>% unique()

aoh_feols_trends_by_sp %>%
  mutate(type = as_factor("NW"),
         overall_trend = 
           fct_relevel(overall_trend, c("gain", "loss", "no trend", 
                                        "weak gain", "weak loss", "context dependent"))) %>%
  filter(str_detect(aoh_type, "crop_abn|full"), 
         passage_type == "exclude_passage",
         vert_class != "amp", 
         mature_forest_obl < 0.5
         ) %>% #.$aoh_type %>% unique()
  group_by(type, aoh_type, vert_class, passage_type,
           overall_trend, trend_direction) %>%
  summarise(n_sp = n()) %>%
  arrange(type, vert_class, aoh_type) %>%
  ungroup() %>%
  group_by(type, aoh_type, vert_class) %>%
  mutate(total_sp = sum(n_sp),
         r = n_sp/total_sp,
         p = 100 * r,
         pr = round(p, digits = 2),
         pp = paste0(prettyNum(pr, nsmall = 2), "%")) %>% ungroup() %>%
  select(type, aoh_type, overall_trend, vert_class, r) %>%
  pivot_wider(id_cols = c(type, aoh_type, vert_class), 
              names_from = overall_trend, values_from = r) %>%
  arrange(vert_class, type)

```

```{r species-specific-changes}

aoh_lag_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend_lag = trend) %>% 
  filter(str_detect(binomial, "Dryobates"))

aoh_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend) %>% 
  filter(aoh_type == "crop_abn_iucn",
         str_detect(binomial, "Dryobates"))

aoh_lm_subset5_trends %>% select(aoh_type, vert_class, site, binomial, trend) %>% 
  filter(aoh_type == "crop_abn_iucn",
         str_detect(binomial, "Dryobates"))

aoh_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend) %>% 
  filter(aoh_type == "crop_abn_iucn") %>%
  left_join(aoh_lag_trends %>% 
              select(aoh_type, vert_class, site, binomial, trend_lag = trend)) %>%
  filter(str_detect(binomial, "Sturnella magna"))


# Across the four 
gg_example_sp_trends <-
  bind_rows(aoh_trends %>% filter(aoh_type == "crop_abn_iucn") %>% mutate(type = "OLS"),
            aoh_feols_trends %>% filter(aoh_type == "crop_abn_iucn") %>% mutate(type = "NW"),
          aoh_lm_subset3_trends %>% mutate(type = "Subset 3"),
          aoh_lm_subset5_trends %>% mutate(type = "Subset 5"),
          aoh_lag_trends %>% mutate(type = "AR1")) %>%
  mutate(type = fct_relevel(type, c("OLS", "NW", "Subset 3", "Subset 5", "AR1"))) %>%
  filter(str_detect(binomial, "Dryobates|Sturnella magna|Setophaga pinus")) %>%
  select(aoh_type, vert_class, site, run_index, binomial, trend, type) %>%
  arrange(run_index, site) %>%
  # pivot_wider(id_cols = c(aoh_type, vert_class, site, run_index, binomial),
  #             names_from = type, values_from = trend) %>%
  ggplot(aes(x = type, y = as_factor(binomial), color = trend)) + 
  geom_point(size = 6) + 
    theme_classic() +
  scale_color_manual(name = "Trend", 
                     labels = palette_labels[c(1,3,6)], 
                     values = palette_du_jour[c(1,3,6)]) + 
  facet_grid(cols = vars(site), scales = "free") + 
  labs(x = "Model specification", y = "Species") + 
  theme(legend.position = "right", axis.text.x = element_text(angle = 340, vjust = 1, hjust = 0))

ggsave(gg_example_sp_trends, filename = paste0(p_plots, "aoh/ind_species/example_sp_trends.pdf"),
         width = 7, height = 2)

  

# -------- 
# species that switch
# --------

aoh_trends %>% names()
aoh_lag_trends %>% names()

aoh_trends %>% 
  filter(aoh_type == "crop_abn_iucn",
         vert_class == "bird",
         passage_type == "exclude_passage") %>%
  select()

aoh_trends_by_sp

# aoh_trends_by_sp %>%
  aoh_lag_trends_by_sp %>%
  filter(aoh_type == "crop_abn_iucn", 
         passage_type == "exclude_passage",
         vert_class != "amp", 
         !aoh_type %in% c("abn_iucn", "potential_abn_iucn"),
         mature_forest_obl < 0.5
         ) %>%
  group_by(aoh_type, vert_class, passage_type,
           overall_trend, trend_direction) %>%
  summarise(n_sp = n()) %>%
  arrange(overall_trend, vert_class, aoh_type) %>%
  ungroup() %>%
  group_by(aoh_type, vert_class) %>%
  mutate(total_sp = sum(n_sp),
         p = 100 * n_sp/total_sp,
         pr = round(p, digits = 2),
         pp = prettyNum(pr, nsmall = 2)) %>%
    select(aoh_type, overall_trend, vert_class, pp, n_sp:pr)



aoh_lag_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend_lag = trend) %>% 
  filter(str_detect(binomial, "Dryobates"))

aoh_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend) %>% 
  filter(aoh_type == "crop_abn_iucn",
         str_detect(binomial, "Dryobates"))

aoh_trends %>% 
  select(aoh_type, vert_class, site, binomial, trend) %>% 
  filter(aoh_type == "crop_abn_iucn") %>%
  left_join(aoh_lag_trends %>% 
              select(aoh_type, vert_class, site, binomial, trend_lag = trend)) %>%
  filter(str_detect(binomial, "Sturnella magna"))


# Dryobates pubescens


df_sp_subset <- aoh %>%
  filter(binomial == sp_to_plot, site == "belarus",
         aoh_type %in% aoh_type_df$label[6])


# prelim model
tmp_lm_downy <- 
  lm(aoh ~ year0, 
     data = aoh %>%
       filter(binomial == "Dryobates pubescens", site == "wisconsin",
         aoh_type == "crop_abn_iucn"))

tidy(tmp_lm_downy)
tmp_lm_downy %>% tidy(., conf.int = TRUE, conf.level = 0.95)
glance(tmp_lm_downy)
augment(tmp_lm_downy)

pdf(file = paste0(p_plots, "aoh/temp_auto/downy_example_resid_v_fitted.pdf"),
      width = 4, height = 4)
plot(tmp_lm_downy, 1)
dev.off()

pdf(file = paste0(p_plots, "aoh/temp_auto/downy_example_resid_dist.pdf"),
      width = 4, height = 4)
hist(tmp_lm_downy$residuals, main = "Residual Histogram")
dev.off()



tmp_lm_meadowlark <- 
  lm(aoh ~ year0, 
     data = aoh %>%
       filter(binomial == "Sturnella magna", site == "wisconsin",
         aoh_type == "crop_abn_iucn"))

plot(aoh ~ year0, 
     data = aoh %>%
       filter(binomial == "Sturnella magna", site == "wisconsin",
         aoh_type == "crop_abn_iucn"))

pdf(file = paste0(p_plots, "aoh/temp_auto/meadowlark_example_resid_v_fitted.pdf"),
      width = 4, height = 4)
plot(tmp_lm_meadowlark, 1)
dev.off()

pdf(file = paste0(p_plots, "aoh/temp_auto/meadowlark_example_resid_dist.pdf"),
      width = 4, height = 4)
hist(tmp_lm_meadowlark$residuals, main = "Residual Histogram")
dev.off()



# check Durbin-Watson Stat
durbinWatsonTest(tmp_lm_downy)
durbinWatsonTest(tmp_lm_meadowlark)



# check ACF plots:
aoh %>%
  filter(
    # binomial == "Dryobates pubescens", 
    binomial == "Sturnella magna",
    site == "wisconsin",
    aoh_type == "crop_abn_iucn",
    passage_type == "exclude_passage") %>% 
  as_tsibble(key = run_index, index = year) %>%
  # autoplot(aoh)
  # gg_lag(aoh)
  PACF(aoh) %>% autoplot()

# # directly compare regular and lagged models
lm(aoh ~ year0, 
   data = aoh %>% filter(binomial == "Sturnella magna", site == "wisconsin", 
                         aoh_type == "crop_abn_iucn",passage_type == "exclude_passage")
   ) %>%
  tidy(conf.int = TRUE, conf.level = 0.95)

lm(aoh ~ year0 + aoh_lag, 
   data = aoh %>% 
     filter(binomial == "Sturnella magna", site == "wisconsin", 
            aoh_type == "crop_abn_iucn",passage_type == "exclude_passage") %>% 
     group_by(run_index) %>% 
     mutate(aoh_lag = lag(aoh)) %>% filter(!is.na(aoh_lag))) %>%
  tidy(conf.int = TRUE, conf.level = 0.95)

# both significant


lm(aoh ~ year0, 
   data = aoh %>% filter(binomial == "Dryobates pubescens", site == "wisconsin", 
                         aoh_type == "crop_abn_iucn",passage_type == "exclude_passage")
   ) %>%
  tidy(conf.int = TRUE, conf.level = 0.95)

lm(aoh ~ year0 + aoh_lag, 
   data = aoh %>% 
     filter(binomial == "Dryobates pubescens", site == "wisconsin", 
            aoh_type == "crop_abn_iucn",passage_type == "exclude_passage") %>% 
     group_by(run_index) %>% 
     mutate(aoh_lag = lag(aoh)) %>% filter(!is.na(aoh_lag))) %>%
  tidy(conf.int = TRUE, conf.level = 0.95)

```


## Model trends

```{r lm-dev}
# aoh_lm
# aoh_distill %>% filter(run_index == 212)

df_sp_subset <- aoh %>%
  filter(binomial == sp_to_plot, site == "belarus",
         aoh_type %in% aoh_type_df$label[6])


# prelim model
tmp_lm <- lm(aoh ~ year0, data = df_sp_subset)
tidy(tmp_lm)
tmp_lm %>% tidy(., conf.int = TRUE, conf.level = 0.95)
glance(tmp_lm)
augment(tmp_lm)
plot(tmp_lm, 1)
hist(tmp_lm$residuals, main = "Residual Histogram")

ggplot(data = df_sp_subset, 
       mapping = aes(x = year0, y = aoh)) +
  geom_point() + 
  geom_smooth(method = "lm", se = 0.95) + 
  labs(x = "Year", y = "AOH (ha)", title = sp_to_plot) + 
  # geom_function(fun = function(x) { (x-4) ^ (mean(coef(lm_log2_l[[9]]), na.rm = TRUE))},
  #               mapping = aes(linetype = "Mean Decay Rate"),
  #               color = "blue", size = 1, #linetype = "dashed", 
  #               inherit.aes = FALSE) 
  geom_line(data = augment(tmp_lm), mapping = aes(x = year0, y = .fitted), col = "green", alpha = 0.2)


```


```{r calc-lm-OLS}
# -------------------
# run simple regression on each species' and extract AOH trend over time.
# -------------------

# ------------------------------------------------------ #
# calculate linear regression for each aoh_type, across all indices for each aoh_type
# ------------------------------------------------------ #
aoh$aoh_type %>% unique()

tic()
lapply(aoh_types, 
       function(aoh_type_) {
         aoh_tmp <- aoh %>% filter(aoh_type == aoh_type_)
         
         # run across aoh_type, site, binomial, passage_type combinations
         
         aoh_lm_tmp <- lapply(
           unique(aoh_tmp$run_index),
           function(i) {
             aoh_tmp %>% 
               filter(run_index == i) %>%
               lm(aoh ~ year0, data = .) %>%
               tidy(., conf.int = TRUE, conf.level = 0.95) %>% 
               mutate(aoh_type = aoh_type_,
                      run_index = i)
             }) %>% bind_rows()
         
         write_parquet(aoh_lm_tmp, paste0(p_derived, "aoh_lm_", aoh_type_,".parquet"))
         
         cat("wrote aoh_lm_tmp for:", aoh_type_, fill = TRUE)
         })
toc()
warnings()

# ------------------------------------------------------ #
# load back in:
# ------------------------------------------------------ #
aoh_lm <- 
  lapply(aoh_types, 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_lm_", aoh_type_,".parquet"))
}) %>% bind_rows()

run_indices
aoh_lm$aoh_type %>% unique()
warnings()

write_parquet(aoh_lm, paste0(p_derived, "aoh_lm.parquet"))

aoh_lm <- read_parquet(paste0(p_derived, "aoh_lm.parquet"))

```

Having looked at the simplest model, using just `lm()` and assuming independent observations, I now aim to test for trends in three sequential steps, or tests:
1. Estimate y = \beta year + eps, with a variance estimator for \beta that allows for autocorrelations

2. Show that this gives you (roughly) the same result as when you compare the mean values at the start and the end of the time series.

3. Take the growth rate g_t = (y_t - y_{t-1}) , and then regress that on a constant, and check if the coefficient is positive (again using the variance estimator that accounts for residual autocorrelation)

I do not intend to use the model that includes an autoregressive term. 
As Tom says, "intuitively it seems to me that controlling for the lag actually ends up controlling for some of the variation that you are interested in."



```{r feols-expl}

set.seed(1)
library(fixest)
library(tidyverse)
library(broom)


# Generate some data from a totally arbitrary Data Generating Process, just as a random example
TT <- 30
eps  <- rnorm(TT, 1:TT, sd = 5)
df <- tibble(species = 1, t = 1:TT, eps = eps, x = 0) 
for(tt in 2:TT) df$x[tt] <- 0.8*df$x[tt-1] + tt + eps[tt]

# IID standard errors (should be the same as what you get from lm)
feols(x ~ t, data = df) %>% tidy(., conf.int = TRUE, conf.level = 0.95)
lm(x ~ t, data = df) %>% tidy(., conf.int = TRUE, conf.level = 0.95)

# Newey-West standard errors, which account for autocorrelations, and are generally approved of by the time series economics people. 
feols(x ~ t, data = df, vcov = vcov_NW(time = ~t)) %>% tidy(., conf.int = TRUE, conf.level = 0.95)



# ---------------------------------------------------------------------- #
# test with my data
aoh %>%
  filter(aoh_type == "crop_abn_iucn",
         site == "wisconsin",
         passage_type == "exclude_passage",
         str_detect(binomial, "Dryobates|Sturnella magna")
         )
tmp_df <- 
  aoh %>% filter(aoh_type == "crop_abn_iucn",
                         site == "wisconsin",
                         passage_type == "exclude_passage",
                         str_detect(binomial, "Dryobates"))

# prelim model
tmp_lm <- lm(
  aoh ~ year0, 
  data = tmp_df
  )

tmp_lm_AR1 <- lm(
  aoh ~ year0 + aoh_lag, 
  data = tmp_df %>%
    group_by(run_index) %>% 
           mutate(aoh_lag = lag(aoh)) %>% 
           filter(!is.na(aoh_lag))
  )


tmp_lm_vcov <- feols(
  aoh ~ year0, 
  data = tmp_df,
  vcov = vcov_NW(time = ~year0)
  )

tidy(tmp_lm, conf.int = TRUE, conf.level = 0.95)
tidy(tmp_lm_AR1, conf.int = TRUE, conf.level = 0.95)
tidy(tmp_lm_vcov, conf.int = TRUE, conf.level = 0.95)

tmp_lm %>% tidy(., conf.int = TRUE, conf.level = 0.95)
tmp_lm_AR1 %>% tidy(., conf.int = TRUE, conf.level = 0.95)
tmp_lm_vcov %>% tidy(., conf.int = TRUE, conf.level = 0.95)
feols(aoh ~ year0, data = tmp_df, vcov = vcov_NW(time = ~year0)) %>% 
  tidy(., conf.int = TRUE, conf.level = 0.95)

feols(aoh ~ year0, data = tmp_df) %>% summary
feols(aoh ~ year0, data = tmp_df) %>% summary(vcov = vcov_NW(time = ~year0))

feols(aoh ~ year0, data = tmp_df) %>% tidy()
feols(aoh ~ year0, data = tmp_df) %>% tidy(vcov = vcov_NW(time = ~year0))
tidy(tmp_lm_vcov)


glance(tmp_lm)
augment(tmp_lm)
plot(tmp_lm, 1)
hist(tmp_lm$residuals, main = "Residual Histogram")

tmp_lm_vcov

coefplot(tmp_lm_vcov)
coef(tmp_lm_vcov)
confint(tmp_lm_vcov)
tmp_lm_vcov %>% tidy(., conf.int = TRUE, conf.level = 0.95)
hist(tmp_lm$residuals, main = "Residual Histogram")
hist(tmp_lm_vcov$residuals, main = "Residual Histogram")
etable(tmp_lm_vcov)

fitted(tmp_lm_vcov)
dd1 <- 
  tmp_lm_vcov %>%
  predict(se.fit = TRUE, interval = "confidence", vcov = vcov_NW(time = ~year0)) %>%
  mutate(year0 = 1:30)

dd
dd1

head(dd)
head(dd1)

r2(tmp_lm_vcov)
class(tmp_lm_vcov)

augment(tmp_lm)

fitted(tmp_lm_vcov)
augment.fixest(tmp_lm_vcov)
tmp_df$year0

# plot with confidence intervals:
ggplot() +
  geom_point(data = tmp_df, mapping = aes(x = year0, y = aoh)) + 
  geom_smooth(data = tmp_df, mapping = aes(x = year0, y = aoh), method = "lm", se = 0.95) +
  labs(x = "Year", y = "AOH (ha)") + 
  geom_line(data = dd1,
            mapping = aes(x = year0, y = fit),
            col = "red",# alpha = 0.2
            ) + 
  geom_ribbon(data = dd1,
              mapping = aes(x = year0,
                            ymin = ci_low, ymax = ci_high
                            ), alpha = 0.2, fill = "green"
              )

```

```{r feols}
# calculate an OLS regression using the Newey-West estimator to calculate standard errors, using the packaged {fixest}

aoh %>% 
  filter(aoh_type == "crop_abn_iucn", n_unique_obs <= 10) %>% 
  select(run_index, n_unique_obs) %>% unique() %>%
  .$n_unique_obs %>%
  
  hist(breaks = 10)

# view the species with constant AOH.
aoh %>% filter(n_unique_obs == 1) %>% select(aoh_type:binomial, run_index, n_obs, n_unique_obs) %>% unique() %>% arrange(binomial) %>% print(n = 90)


##### -------------------------------- #
# calculate feols
{
tic()
lapply(
  aoh_types,
       function(aoh_type_) {
         aoh_tmp <- aoh %>% 
           filter(aoh_type == aoh_type_,
                  n_unique_obs > 1
                  )
           
           # group_by(run_index) %>% # no longer necessary - see above, "{r calc-aoh}"
           # mutate(n_obs = n()) %>% 
           # ungroup()
           
         # run across aoh_type, site, binomial, passage_type combinations
         aoh_feols_tmp <- lapply(
           unique(aoh_tmp$run_index),

           function(i) {
             aoh_tmp %>% 
               filter(run_index == i) %>%
               feols(aoh ~ year0, data = ., vcov = vcov_NW(time = ~year0)) %>%
               tidy(., conf.int = TRUE, conf.level = 0.95) %>%
               mutate(aoh_type = aoh_type_, run_index = i)
             }) %>% 
           bind_rows() %>%
           
           # join 
           left_join(aoh_tmp %>% select(aoh_type:binomial, run_index, n_obs, n_unique_obs, redlistCategory:end_year, passage_type) %>% unique())
         
         write_parquet(aoh_feols_tmp, paste0(p_derived, "aoh_feols_", aoh_type_,".parquet"))
         
         cat("wrote aoh_feols_tmp for:", aoh_type_, fill = TRUE)
         })
toc()
}


# ------------------------------------------------------ #
# load back in:
# ------------------------------------------------------ #
aoh_feols <- 
  lapply(aoh_types, 
  function(aoh_type_) {read_parquet(paste0(p_derived, "aoh_feols_", aoh_type_,".parquet"))
}) %>% bind_rows()

aoh_feols %>% filter(aoh_type == "crop_abn_iucn")

run_indices
aoh_feols$aoh_type %>% unique()
warnings()

write_parquet(aoh_feols, paste0(p_derived, "aoh_feols.parquet"))

aoh_feols <- read_parquet(paste0(p_derived, "aoh_feols.parquet"))
```

```{r weird-sp-missing-aoh-type}
crop_abn_iucn_sp <- 
  aoh_feols_trends_by_sp %>%
  filter(aoh_type == "crop_abn_iucn", passage_type == "exclude_passage",
         vert_class != "amp", mature_forest_obl < 0.5) %>%
  pull(binomial) %>% unique()


species_list

max_sp1 <- 
  aoh_feols_trends_by_sp %>%
  filter(aoh_type == "max_abn_iucn", passage_type == "exclude_passage",
         vert_class != "amp", mature_forest_obl < 0.5) %>%
  pull(binomial) %>% unique()

full_sp1 <- 
  aoh_feols_trends_by_sp %>%
  filter(aoh_type == "full_iucn", 
         passage_type == "exclude_passage", vert_class != "amp", mature_forest_obl < 0.5) %>%
  pull(binomial) %>% unique()

crop_sp1
setdiff(sort(crop_sp1), sort(max_sp1))
setdiff(sort(max_sp1), sort(crop_sp1))
d1 <- sort(setdiff(full_sp1, max_sp1)) # species in full_sp1 that are not in max_sp1
sort(setdiff(max_sp1, full_sp1)) # species in max_sp1 that are not in full_sp1

aoh_feols_trends %>%
  filter(
    aoh_type == "max_abn_iucn",
    passage_type == "exclude_passage",
    vert_class != "amp", 
    mature_forest_obl < 0.5, 
    !(binomial %in% crop_sp1)) %>%
  select(vert_class, binomial) %>%
  left_join(common_names)

aoh_feols_trends_by_sp %>%
  filter(
    aoh_type == "max_abn_iucn",
    passage_type == "exclude_passage",
    vert_class != "amp", 
    mature_forest_obl < 0.5, 
    !(binomial %in% crop_sp1)) %>%
  select(vert_class, binomial) %>%
  left_join(common_names)


aoh_feols_trends_by_sp %>%
  filter(
    aoh_type == "crop_abn_iucn",
    passage_type == "exclude_passage",
    vert_class != "amp", 
    mature_forest_obl < 0.5, 
    !(binomial %in% max_sp1)) %>%
  select(vert_class, binomial) %>% pull(binomial) # %>%
  left_join(common_names)


  
aoh_feols_trends %>% #_by_sp %>%
  filter(
    # aoh_type == "crop_abn_iucn",
    passage_type == "exclude_passage",
    vert_class != "amp", 
    mature_forest_obl < 0.5) %>%
  group_by(aoh_type, vert_class) %>% 
  summarise(n = n(), 
            nn = length(unique(binomial))) %>%
  arrange(vert_class, aoh_type)

# plot weird species:
aoh %>%
  filter(binomial %in% c(
    # "Sus scrofa"
    "Phoenicurus erythrogastrus"
    # "Proechimys goeldii" # in max_abn, not crop_abn
    # "Pyrrhula pyrrhula" # in crop_abn, not max_abn
    # "Odocoileus hemionus" # in crop_abn, not max_abn
    # "Plecotus austriacus" # in crop_abn, not max_abn
    ),
    passage_type == "exclude_passage",
    # aoh_type == "max_abn_iucn", 
    ) %>%
  ggplot(aes(y = aoh, x = year, col = site)) +
  geom_line() +
  facet_wrap(vars(aoh_type), scales = "free")

# These species were removed from the different aoh types because they had zero change over the course of the time series.
# They only had one unique observation and were therefore removed from the datasest prior to having their trend calculated. I think this is because the FEOLS call throws an error in this case.
aoh %>% 
  # filter(binomial == "Proechimys goeldii", aoh_type == "crop_abn_iucn", passage_type == "exclude_passage") %>% pull(run_index) %>% unique() %>%
  
  filter(run_index == 
           5054
         ) %>%
  feols(aoh ~ year0, data = ., vcov = vcov_NW(time = ~year0)) %>%
  tidy(., conf.int = TRUE, conf.level = 0.95)


aoh %>% 
  filter(n_unique_obs == 1) %>%
  select(
    aoh_type,
    vert_class,
    # site,
    binomial,
    aoh) %>% 
  unique() %>%
  arrange(vert_class, binomial, aoh_type) %>%
  print(n = 50)


aoh %>%
  filter(binomial == "Sus scrofa") %>%
  select(aoh_type:binomial, run_index) %>% unique()


aoh_feols

aoh_lm

setdiff(sort(unique(aoh_lm$run_index)),
        sort(unique(aoh_feols_trends$run_index))
        ) %>%
  length()


aoh %>% 
  filter(n_unique_obs == 1) %>%
  select(aoh_type, vert_class, binomial, aoh, passage_type) %>% 
  unique() %>%
  arrange(vert_class, binomial, aoh_type) %>%
  nrow()


aoh %>% 
  filter(n_unique_obs == 1) %>%
  select(
    aoh_type,
    vert_class,
    site,
    binomial,
    aoh) %>% 
  unique() %>%
  arrange(vert_class, binomial, aoh_type) %>%
  print(n = 50)

aoh_feols %>% 
  filter(binomial == "Sus scrofa", 
         aoh_type == "max_abn_iucn",
         passage_type == "exclude_passage")

# ------------------------------------------------------ #
# add species with 0 slope:
# ------------------------------------------------------ #
aoh %>% 
  filter(n_unique_obs == 1) %>%
  select(-c(year, year0, aoh)) %>% unique() 
  # select(aoh_type, vert_class, binomial, aoh, passage_type) %>% 
  # unique() %>%
  # arrange(vert_class, binomial, aoh_type) %>%
  # nrow()

aoh %>% 
  filter(n_unique_obs == 1) %>%
  select(-c(year, year0, aoh)) %>% unique() %>%
  mutate(term = "year0", estimate = 0, trend = "no trend")

names(aoh)
names(aoh_feols_trends)

head(aoh_feols_trends) %>%
  bind_rows(
    aoh %>% 
      filter(n_unique_obs == 1) %>%
      select(-c(year, year0, aoh)) %>% unique() %>%
      head() %>%
      mutate(term = "year0", estimate = 0, trend = "no trend")
    ) %>%
  select(trend:obligate_type)


aoh_trends
aoh_feols_trends
nrow(aoh_trends) - nrow(aoh_feols_trends)
nrow(aoh_trends_by_sp) - nrow(aoh_feols_trends_by_sp)

aoh_trends_by_sp %>%
  select(aoh_type:passage_type) %>%
  mutate(model_type == "lm")

aoh_feols_trends_by_sp %>%
  select(aoh_type:passage_type)

aoh_feols_trends_by_sp %>%
  select(aoh_type:passage_type) %>%
  mutate(model2 = "feols") %>%
  unique() %>% nrow()

aoh_trends_by_sp %>%
  select(aoh_type:passage_type) %>%
  mutate(model1 = "lm") %>%
  unique() %>% nrow()


left_join(
  aoh_feols_trends_by_sp %>%
    select(aoh_type:passage_type) %>%
    mutate(model2 = "feols"),
  aoh_trends_by_sp %>%
    select(aoh_type:passage_type) %>%
    mutate(model1 = "lm"),
  by = c("aoh_type", "vert_class", "binomial", "passage_type")
  ) %>% 
  filter(is.na(model1))


```

```{r feols-trends}
# mature_forest_obl < 0.5,
#          # !(vert_class == "bird" & mature_forest_obl > 0.5),
# ------------------------------------------------------ #
# distill trends
# ------------------------------------------------------ #
aoh_feols_trends <-
  aoh_feols %>%
  # left_join(run_indices) %>%
  filter(!if_any(!c(mature_forest_obl, common_names), is.na)) %>% # filter out NAs:
  left_join(run_indices) %>%
  filter(term == "year0") %>%
  mutate(trend = case_when(
    estimate > 0 & p.value < 0.05 ~ "gain", # Statistically significant gain of AOH
    estimate < 0 & p.value < 0.05 ~ "loss", # Statistically significant loss of AOH
    p.value >= 0.05 ~ "no trend" # no significant trend
    )) %>%
  select(term:binomial, trend, everything()) %>%
  
  # add species with 0 slope (n_unique_obs == 1):
  bind_rows(
    aoh %>% 
      filter(n_unique_obs == 1) %>%
      select(-c(year, year0, aoh)) %>% unique() %>%
      mutate(term = "year0", estimate = 0, trend = "no trend")
    ) %>%

  mutate(
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    obligate_type = case_when(
      mature_forest_obl > 0.5 ~ "mature_forest_obligate",
      mature_forest_obl < 0.5 ~ "not_obligate"))

write_parquet(aoh_feols_trends, paste0(p_derived, "aoh_feols_trends.parquet"))

aoh_feols_trends <- read_parquet(paste0(p_derived, "aoh_feols_trends.parquet"))


# ------------------------------------------------------ #
# ------- trends by species ------- #
# ------------------------------------------------------ #

aoh_feols_trends_by_sp <- 
  aoh_feols_trends %>%
  filter(
    #passage_type == "exclude_passage"#, mature_forest_obl < 0.5
    !is.na(trend)) %>%
  select(aoh_type, vert_class, binomial, trend, passage_type) %>% 
  unique() %>% arrange(aoh_type, binomial, trend) %>%
  group_by(aoh_type, vert_class, binomial, passage_type) %>% 
  summarise(n_trends = n(), 
            trend_types = str_c(unique(trend), collapse = "; ")) %>% 
  # arrange(desc(n_trends)) %>%
  ungroup() %>%
  mutate(overall_trend = case_when(
    n_trends == 1 ~ trend_types,
    n_trends == 2 & trend_types == "gain; no trend" ~ "weak gain",
    n_trends == 2 & trend_types == "loss; no trend" ~ "weak loss",
    n_trends == 2 & trend_types == "gain; loss" | n_trends == 3 ~ "context dependent"
  )) %>%
  left_join(aoh_species_list) %>%
  
  # update factor levels
  mutate(
    trend_direction = case_when(
      grepl("gain", overall_trend) ~ "gain",
      grepl("loss", overall_trend) ~ "loss",
      grepl("context", overall_trend) ~ "context dependent",
      grepl("no trend", overall_trend) ~ "no trend"
      ) %>% fct_relevel(c("gain", "loss", "no trend", "context dependent")),
    trend_consistency = case_when(
      n_trends == 1 ~ "consistent",
      grepl("weak", overall_trend) ~ "weak",
      grepl("context", overall_trend) ~ "opposite"
      ) %>% #as_factor() %>% 
      fct_relevel(rev(c("consistent", "weak", "opposite"))),
    
    
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    redlistCategory = fct_relevel(redlistCategory, c("Least Concern", "Near Threatened", "Vulnerable", 
                                                     "Endangered", "Critically Endangered", "Data Deficient"))
    )

write_parquet(aoh_feols_trends_by_sp, paste0(p_derived, "aoh_feols_trends_by_sp.parquet"))

aoh_feols_trends_by_sp <- read_parquet(paste0(p_derived, "aoh_feols_trends_by_sp.parquet"))

# ------------------------------------------------------ #
# load relevant files
# ------------------------------------------------------ #
aoh_feols <- read_parquet(paste0(p_derived, "aoh_feols.parquet"))
aoh_feols_trends <- read_parquet(paste0(p_derived, "aoh_feols_trends.parquet"))
aoh_feols_trends_by_sp <- read_parquet(paste0(p_derived, "aoh_feols_trends_by_sp.parquet"))

```

```{r aoh-ols-trends}
# ------------------------------------------------------ #
# distill trends
# ------------------------------------------------------ #

# determine the direction of trend for each species-site combination
aoh_trends <- 
  aoh_lm %>% 
  left_join(run_indices) %>%
  filter(term == "year0") %>%

  mutate(trend = case_when(
    estimate > 0 & p.value < 0.05 ~ "gain", # Statistically significant gain of AOH
    estimate < 0 & p.value < 0.05 ~ "loss", # Statistically significant loss of AOH
    p.value > 0.05 ~ "no trend" # no significant trend
    )) %>%
  # mutate(trend0 = if_else(estimate > 0, "gain", "loss")) %>%
  # mutate(trend_from_ci = case_when(
  #   sign(conf.low) + sign(conf.high) == -2 ~ "loss",
  #   sign(conf.low) + sign(conf.high) == 2 ~ "gain",
  #   sign(conf.low) + sign(conf.high) < 2 & 
  #     sign(conf.low) + sign(conf.high) > -2 ~ "no trend")
  #   ) %>% 
  # mutate(test = trend == trend_from_ci) %>%
  # select(term, estimate, p.value, conf.low, conf.high, run_index:binomial, contains("trend"), everything()) %>%
  # filter(
  #   p.value > 0.05,
  #   is.na(test)
  #   ) %>% .$trend %>% unique()
  
  select(term:binomial, trend, everything()) %>%
  mutate(aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
         obligate_type = case_when(
           mature_forest_obl > 0.5 ~ "mature_forest_obligate",
           mature_forest_obl < 0.5 ~ "not_obligate"))


write_parquet(aoh_trends, paste0(p_derived, "aoh_trends.parquet"))
aoh_trends <- read_parquet(paste0(p_derived, "aoh_trends.parquet"))



# ------------------------------------------------------ #
# ------- trends by species ------- #
# ------------------------------------------------------ #

# Create data.frame with a single row for each species in each aoh type, with the number of trends and the specific trend types they experience (overall_trend).
# Extract the number of species with multiple trends per aoh_type:

# Add a column for overall_trend:
# 1. Always winners
# 2. Always losers
# 3. Context dependent

aoh_trends_by_sp <-
  aoh_trends %>%
  filter(
    #passage_type == "exclude_passage"#, mature_forest_obl < 0.5
    !is.na(trend)) %>%
  select(aoh_type, vert_class, binomial, trend, passage_type) %>% 
  unique() %>% arrange(aoh_type, binomial, trend) %>%
  group_by(aoh_type, vert_class, binomial, passage_type) %>% 
  summarise(n_trends = n(), 
            trend_types = str_c(unique(trend), collapse = "; ")) %>% 
  # arrange(desc(n_trends)) %>%
  ungroup() %>%
  mutate(overall_trend = case_when(
    n_trends == 1 ~ trend_types,
    n_trends == 2 & trend_types == "gain; no trend" ~ "weak gain",
    n_trends == 2 & trend_types == "loss; no trend" ~ "weak loss",
    n_trends == 2 & trend_types == "gain; loss" | n_trends == 3 ~ "context dependent"
  )) %>%
  left_join(aoh_species_list) %>%
  
  # update factor levels
  mutate(
    trend_direction = case_when(
      grepl("gain", overall_trend) ~ "gain",
      grepl("loss", overall_trend) ~ "loss",
      grepl("context", overall_trend) ~ "context dependent",
      grepl("no trend", overall_trend) ~ "no trend"
      ) %>% fct_relevel(c("gain", "loss", "no trend", "context dependent")),
    trend_consistency = case_when(
      n_trends == 1 ~ "consistent",
      grepl("weak", overall_trend) ~ "weak",
      grepl("context", overall_trend) ~ "opposite"
      ) %>% #as_factor() %>% 
      fct_relevel(rev(c("consistent", "weak", "opposite"))),
    
    
    aoh_type = fct_relevel(aoh_type, aoh_types[c(6, 7, 3, 5, 1, 2, 4)]),
    redlistCategory = fct_relevel(redlistCategory, c("Least Concern", "Near Threatened", "Vulnerable", 
                                                     "Endangered", "Critically Endangered", "Data Deficient"))
    )

write_parquet(aoh_trends_by_sp, paste0(p_derived, "aoh_trends_by_sp.parquet"))
aoh_trends_by_sp <- read_parquet(paste0(p_derived, "aoh_trends_by_sp.parquet"))



# ------------------------------------------------------ #
# ------- trends changes ------- #
# ------------------------------------------------------ #

# ----------------------------------------- #
# Q. How many species have no trend or a negative trend at the landscape scale,
# but a positive trend in abandonment?
# ----------------------------------------- #
aoh_trends_by_sp



# ----------------------------------------- #
# Q. How many species have no trend or a negative trend for observed abandonment,
# but a positive trend in potential abandonment?
# ----------------------------------------- #
trend_changes <- 
  aoh_feols_trends %>%
  filter(vert_class != "amp",
         str_detect(aoh_type, "crop"),
         passage_type == "exclude_passage",
         mature_forest_obl < 0.5
         ) %>%
  pivot_wider(id_cols = c(vert_class, site, binomial),
              values_from = trend,
              names_from = aoh_type) %>%
  # select(contains("crop")) %>% unique()
  mutate(overall_change = case_when(
    crop_abn_iucn == "gain" & crop_abn_potential_iucn == "gain" ~ "no change (gain)",
    crop_abn_iucn == "loss" & crop_abn_potential_iucn == "loss" ~ "no change (loss)",
    crop_abn_iucn == "gain" & crop_abn_potential_iucn == "loss" ~ "gain to loss",
    crop_abn_iucn == "loss" & crop_abn_potential_iucn == "gain" ~ "loss to gain",
    crop_abn_iucn == "loss" & crop_abn_potential_iucn == "no trend" ~ "loss to no trend",
    crop_abn_iucn == "gain" & crop_abn_potential_iucn == "no trend" ~ "gain to no trend",
    crop_abn_iucn == "no trend" & crop_abn_potential_iucn == "no trend" ~ "no change (no trend)",
    crop_abn_iucn == "no trend" & crop_abn_potential_iucn == "loss" ~ "no trend to loss",
    crop_abn_iucn == "no trend" & crop_abn_potential_iucn == "gain" ~ "no trend to gain"
  ) %>% fct_relevel(),
  change_direction = case_when(
    grepl("^no change", overall_change) ~ "no change",
    grepl("to loss$", overall_change) ~ "loss",
    grepl("to gain$", overall_change) ~ "gain",
    grepl("no trend", overall_change) ~ "indeterminate"
  ) %>% fct_relevel("gain", "no change", "indeterminate", "loss")) %>%
  group_by(vert_class, site, 
           # overall_change, 
           change_direction
           ) %>%
  summarise(n_sp = n()) %>% 
  arrange(vert_class, change_direction)
  # .$overall_change %>% as_factor() %>% levels()


trend_changes %>%
  ggplot(mapping = aes(
         x = change_direction,
         y = n_sp,
         fill = vert_class,
         group = vert_class
         )) +
  geom_col(position = position_dodge(preserve = "total"),
           color = "black", size = .25) +
  theme_classic() + 
  labs(x = "Trend Change Direction", y = "Number of Species") +
  # scale_fill_manual(name = "", labels = palette_labels, values = palette_du_jour) + 
  theme(legend.position = "right",
        axis.text.x = element_text(angle = 340, vjust = 1, hjust = 0)) +
  facet_wrap(vars(site), scales = "free_y", labeller = as_labeller(fancy_labels))



trend_changes %>%
  ggplot(mapping = aes(
         y = change_direction,
         x = n_sp,
         fill = vert_class,
         group = vert_class
         )) +
  geom_col(position = position_dodge(preserve = "total"),
           color = "black", size = .25) +
  theme_classic() + 
  # labs(x = "Trend Change Direction", y = "Number of Species") +
  # scale_fill_manual(name = "", labels = palette_labels, values = palette_du_jour) + 
  theme(legend.position = "right") +
    theme(strip.text.y.right = element_text(angle = 0)) +
  facet_grid(rows = vars(site), scales = "free")#, labeller = as_labeller(fancy_labels))

```

## Effect sizes

Three ways to report this:
a. absolute area gain.
b. % of the site area
c. proportional gain

Why plot the observed change in AOH instead of the estimated change in AOH, derived from model results?
Some of the modeled trends produce negative estimates of the starting AOH, which produces truly wonky results for ratios and proportions.
Essentially, this makes it so that ratios for winner species that start from a negative are consequently negative.
These observed values are calculated

```{r estimated-changes-aoh-change-df}
# ------------------
# determine the relative trend (percent change in AOH start to end)
# based on the model trends
# ------------------
aoh_lm <- read_parquet(paste0(p_derived, "aoh_lm.parquet"))
aoh_feols <- read_parquet(paste0(p_derived, "aoh_feols.parquet"))

# calculate percent changes

aoh_change_df <-
  # aoh_lm %>%
  aoh_feols %>% 
  select(run_index, 
         term, estimate,
         conf.low, conf.high) %>%
  mutate(term = ifelse(term == "(Intercept)", "intercept", "slope")) %>%
  pivot_longer(cols = c(estimate, contains("conf")), names_to = "est_type") %>%
  pivot_wider(id_cols = c(run_index, est_type), 
              values_from = value,#c(estimate, conf.low, conf.high),
              names_from = term, #names_prefix = "",
              ) %>%
  
  # add species with 0 slopes, i.e., n_unique_obs == 1
  bind_rows(
    aoh %>%
      filter(n_unique_obs == 1) %>%
      select(-c(year, year0)) %>% unique() %>%
      select(run_index, intercept = aoh) %>%
      mutate(est_type = "estimate", slope = 0)
    ) %>%
  
  left_join(aoh_start_end_l %>% select(run_index, contains("year")) %>% unique(), by = "run_index") %>%
  left_join(run_indices) %>%
  select(run_index, est_type, vert_class, site, contains("year"), slope, intercept, 
         aoh_type, passage_type, vert_class, binomial, mature_forest_obl) %>%
  left_join(select(area_summary_df, site, total_site_area_ha_2017, area_ever_abn_ha), by = "site") %>% 
  left_join(aoh_feols_trends %>% select(run_index, trend), by = "run_index") %>%
  left_join(aoh_feols_trends_by_sp %>% select(aoh_type:overall_trend, trend_direction, trend_consistency), by = c("aoh_type", "vert_class", "binomial", "passage_type")) %>%
  mutate(time_range = end_year - start_year,
         aoh_start_est = slope*1 + intercept,
         aoh_end_est = slope*(time_range) + intercept,
         abs_change = aoh_end_est - aoh_start_est,
         abs_change_per_yr = abs_change / time_range,
         abs_change_as_prop_site_area = abs_change / total_site_area_ha_2017,
         ratio_change = aoh_end_est / aoh_start_est,
         prop_change = abs_change / aoh_start_est, 
         factor_change = case_when(prop_change < 0 ~ 1/prop_change, TRUE ~ prop_change),
         percent_change = paste0(prettyNum(round(100 * prop_change, digits = 2), nsmall = 2), "%")) # %>%
    
    # select(abs_change:percent_change) %>%
    # print(n = 100)


# save file
write_parquet(aoh_change_df, paste0(p_derived, "aoh_change_df.parquet"))

names(aoh_change_df)

# minor exploration

aoh_change_df %>%
  filter(est_type == "estimate", aoh_type == "crop_abn_iucn", str_detect(passage_type, "excl"),
         vert_class != "amp", mature_forest_obl < 0.5)


# estimated (^) vs. the observed change directly from aoh_start_end_l
aoh_start_end_l %>% 
  filter(window_size == 1,
         aoh_type == "crop_abn_iucn", str_detect(passage_type, "excl"),
         vert_class != "amp", mature_forest_obl < 0.5)
```

```{r observed-change-in-AOH-by-window-size}

tmp_df

# ------------------------------------------------------- #
# calculate average aoh at start and end of time period
# ------------------------------------------------------- #
n_ <- 5

aoh_start_end <- left_join(
  aoh %>% filter(aoh_type == "crop_abn_iucn") %>% group_by(run_index) %>% slice_min(year, n = n_) %>% 
    summarise(start = mean(aoh), start_year = min(year)) %>% ungroup(),
  aoh %>% filter(aoh_type == "crop_abn_iucn") %>% group_by(run_index) %>% slice_max(year, n = n_) %>% 
    summarise(end = mean(aoh), end_year = max(year)) %>% ungroup()) %>%
  mutate(window_size = n_)

# ------------- cycle through various window lengths ------------- #
aoh %>% select(run_index) %>% unique()
aoh %>% select(aoh_type) %>% unique()

aoh_start_end_l <- 
  lapply(aoh_types, function(j) {
    lapply(c(1, seq(from = 5, to = 15, by = 5)),
           function(i) {
             left_join(
               aoh %>% 
                 filter(aoh_type == j) %>% 
                 group_by(run_index) %>% slice_min(year, n = i) %>% 
                 summarise(start = mean(aoh), start_year = min(year)) %>% ungroup(),
               aoh %>% 
                 filter(aoh_type == j) %>% 
                 group_by(run_index) %>% slice_max(year, n = i) %>% 
                 summarise(end = mean(aoh), end_year = max(year)) %>% ungroup()) %>%
               mutate(window_size = i)
             }) %>% bind_rows()
    }) %>% bind_rows() %>%
  left_join(run_indices, by = "run_index") %>%
  left_join(select(area_summary_df, site, total_site_area_ha_2017, area_ever_abn_ha), by = "site") %>%
  left_join(aoh_feols_trends %>% select(run_index, trend)) %>%
  mutate(abs_change = end - start, 
         ratio = end/start, 
         ratio_mod = case_when(ratio < 1 ~ 1/ratio * -1, TRUE ~ ratio),
         prop_change = abs_change/start, 
         factor_change = case_when(prop_change < 0 ~ 1/prop_change, TRUE ~ prop_change),
         percent_change = paste0(prettyNum(round(100 * prop_change, digits = 2), nsmall = 2), "%"),
         abs_change_as_prop_site_area = abs_change / total_site_area_ha_2017) %>%
  select(c("run_index", "start", "start_year", "end", "end_year", "window_size", "abs_change", "prop_change", "percent_change", "ratio", "ratio_mod", "abs_change_as_prop_site_area"), everything())

names(aoh_start_end_l)

write_parquet(aoh_start_end_l, paste0(p_derived, "aoh_start_end_l.parquet"))

# add species with 0 slopes, i.e., n_unique_obs == 1
aoh %>%
  filter(n_unique_obs == 1) %>%
  select(-c(year, year0)) %>% unique() %>%
  select(run_index, intercept = aoh) %>%
  mutate(est_type = "estimate", slope = 0)

aoh_start_end_trends_l %>% 
  filter(run_index == 24712)

aoh_start_end_trends_l %>%
  filter(run_index %in% unique(pull(filter(aoh, n_unique_obs == 1), run_index))) %>%
  select(site:trend_threshold) %>% pull(trend) %>% length()

aoh_start_end_l %>%
  filter(!(start_year == 1987 & end_year == 2017)) %>%
  select(start_year, end_year) %>%
  unique()

# ------------------------------------------------------- #
# calculate trends, cycling through various thresholds for "significance"
# ------------------------------------------------------- #

# cycle through various thresholds
aoh_start_end_trends_l <- 
  lapply(seq(from = 0.05, to = 0.5, by = 0.05), 
         function(i) {
           aoh_start_end_l %>%
             mutate(trend = case_when(
                      prop_change >= i ~ "gain", 
                      prop_change <= -i ~ "loss",
                      abs(prop_change) < i ~ "no trend"
                      ),
                    trend_threshold = i)
}) %>% bind_rows()

write_parquet(aoh_start_end_trends_l, paste0(p_derived, "aoh_start_end_trends_l.parquet"))

aoh_start_end_trends_l %>% filter(trend_threshold == 0.1)
aoh_start_end_trends


aoh_start_end_trends %>%
  filter(abs(prop_change) < 0.05)

aoh_start_end_trends %>%
  filter(abs(prop_change) < 0.5)

# ---------- plot ----------- #

gg_aoh_start_end_trends_l <- 
  aoh_start_end_trends_l %>%
  # left_join(run_indices, by = "run_index") %>%
  filter(aoh_type == "crop_abn_iucn", 
         passage_type == "exclude_passage",
         vert_class != "amp",
         mature_forest_obl < 0.5,
         # aoh_type == i
         ) %>% #.$vert_class %>% unique()
    mutate(vert_class = case_when(
      vert_class == "mam" ~ "Mammals",
      vert_class == "bird" ~ "Birds"),
      # aoh_type = "Overall"
    ) %>%
  group_by(aoh_type, vert_class, passage_type, trend, trend_threshold, window_size) %>%
  summarise(n_sp = n()) %>%
  arrange(vert_class, aoh_type) %>%
  ggplot(mapping = aes(
         x = trend, y = n_sp,
         fill = trend %>% fct_relevel(c("gain", "loss", "no trend"))
         )) +
  geom_col(position = position_stack(reverse = TRUE), color = "black", size = .25) +
  theme_classic() +
  scale_x_discrete(labels = aoh_type_labels) + 
  scale_y_continuous(breaks = seq(from = 0, to = 1200, by = 200)) +
  labs(x = NULL, y = "Number of Species") +
  scale_fill_manual(name = "Trend", 
                    labels = palette_labels[c(1,3,6)],
                    values = palette_du_jour[c(1,3,6)]) + 
  # guides(fill = guide_legend(ncol = 2, nrow = 3)) +
  theme(
    # legend.position = "none",
        axis.text.x = element_blank(),
        axis.ticks.x = element_blank()) +
  facet_grid(
    vert_class + window_size ~ trend_threshold,
    # row = vars(interaction(vert_class, window_size)), col = vars(trend_threshold),
    scales = "free_y", #labeller = as_labeller(c(i = "Overall","mam" = "Mammals", "bird" = "Birds"))
    )

aoh_start_end_trends_l
gg_aoh_start_end_trends_l

ggsave(gg_aoh_start_end_trends_l,
       filename = paste0(p_output, "plots/aoh/", 
                           "aoh_start_end_threshold_v_window_panel",
                           ".pdf"),
         width = 8, height = 6, units = "in"
       )
```


```{r compare-obs-change-to-mod-trends-feols}
# ---------------------------------------------------------------------- #
# compare trends with feols
# ---------------------------------------------------------------------- 
aoh_start_end_trends_l %>%
  left_join(aoh_feols_trends %>% select(run_index, trend_feols = trend), by = "run_index") %>% 
  filter(is.na(trend_feols)) %>% print(n = 150)

aoh_feols_trends
names(run_indices)

df_agree <-
  aoh_start_end_trends_l %>%
  left_join(aoh_feols_trends %>% select(run_index, trend_feols = trend), by = "run_index") %>%
  filter(!is.na(trend_feols)) %>%
  # names() %>%
  mutate(agree = trend == trend_feols) %>%
  filter(!is.na(agree),
         # agree == "FALSE"
         ) %>%
  filter(
    # window_size == 5, trend_threshold == 0.1,
    passage_type == "exclude_passage",
    vert_class != "amp",
    mature_forest_obl < 0.5,
    # aoh_type == i
    )  %>% #.$vert_class %>% unique()
  group_by(aoh_type, vert_class, passage_type, trend, trend_threshold, window_size, agree) %>%
  summarise(n_sp = n()) %>%
  arrange(vert_class, aoh_type) %>%
  ungroup() %>%
  pivot_wider(id_cols = c(aoh_type, vert_class, passage_type, trend, trend_threshold, window_size),
              names_from = agree, values_from = n_sp) %>%
    rename("n_agree" = `TRUE`, "n_disagree" = `FALSE`) %>% 
    # filter(is.na(n_disagree)) %>%
    mutate(n_disagree = replace_na(n_disagree, 0)) %>%
    mutate(p_dis = n_disagree/n_agree)


df_agree$p_dis

# plotting the proportion of disagreements to agreements for all trends
gg_total_p_disagree <-
  df_agree %>%
  group_by(aoh_type, vert_class, passage_type, trend_threshold, window_size) %>% 
  arrange(aoh_type, vert_class, passage_type, trend_threshold, window_size) %>%
  summarise(n_agree = sum(n_agree), n_disagree = sum(n_disagree)) %>% ungroup() %>% 
  mutate(p_dis = n_disagree/n_agree) %>%
    # filter(aoh_type == "crop_abn_iucn") %>%
  # filter(window_size == 5, trend_threshold == 0.1)
  ggplot(mapping = aes(x = trend_threshold, y = p_dis, color = vert_class)) +
  geom_point() +
  theme_classic() +
  facet_grid(aoh_type ~ window_size, labeller = label_both, scales = "free")

ggsave(gg_total_p_disagree,
       filename = paste0(p_output, "plots/aoh/", 
                           "aoh_start_end_v_feols_p_disagree",
                           ".pdf"),
         width = 7, height = 5, units = "in"
       )

gg_p_disagree_by_trend <- df_agree %>% 
  # filter(p_dis >1)
    # filter(window_size == 5, trend_threshold == 0.1)
  ggplot(mapping = aes(x = trend_threshold, y = p_dis, color = trend, alpha = n_agree)) +
  geom_point() + 
  theme_classic() +
  scale_color_manual(name = "Trend", 
                    labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)]) +
  
  #scale_alpha_manual(values = c(0.5, 1)) +
  facet_grid(vert_class ~ window_size)


ggsave(gg_p_disagree_by_trend,
       filename = paste0(p_output, "plots/aoh/", 
                           "aoh_start_end_v_feols_p_disagree_by_trend",
                           ".pdf"),
         width = 6.5, height = 5, units = "in"
       )

df_agree %>% filter(is.na(n_disagree))
# ---------------------------------------------------------------------- #
# condensing this information into a single number
# ---------------------------------------------------------------------- #

df_agree %>%
  group_by(aoh_type, vert_class, passage_type, trend_threshold, window_size) %>% 
  arrange(aoh_type, vert_class, passage_type, trend_threshold, window_size) %>%
  summarise(n_agree = sum(n_agree), n_disagree = sum(n_disagree)) %>% ungroup() %>% 
  mutate(p_dis = n_disagree/n_agree) %>%
  filter(trend_threshold < 0.26) %>%
  arrange(window_size) %>% print(n = 30)

# When using a threshold of 10-20% to indicate inscreases or decreases, trends match for about 95% of species.

```

```{r eff-size-stats}
# ----------------------------------------------------------------- #
# a. mean absolute change, by trend, by taxonomic group
# b. mean absolute change, by trend, by taxonomic group, by site
# c. mean absolute change, by trend, by site
# ----------------------------------------------------------------- #

# --------- a ----------- #
aoh_est_change_tmp %>%
  filter(site != "mato_grosso") %>%
  group_by(vert_class, trend) %>%
  summarise(n = n(), mean = mean(abs_change) / 10^6, median = median(abs_change) / 10^6) %>%
  arrange(trend, vert_class)
  # pivot_longer(cols = c("mean", "median"), names_to = "Statistic") %>% #arrange(Statistic)

  ggplot() + 
  geom_point(aes(x = mean, y = vert_class, col = trend, group = vert_class), size = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)])


aoh_est_change_tmp %>%
    filter(site != "mato_grosso") %>%

      ggplot() +
      # geom_vline(xintercept = 0, linetype = "dashed", col = "gray50") +
      geom_histogram(aes(x = abs(abs_change)/10^6, fill = trend, group = trend), bins = 50, col = "black", size = 0.5) +
  geom_vline(data = aoh_est_change_tmp %>% 
                 filter(site != "mato_grosso") %>%

               group_by(trend, vert_class) %>%
               summarise(n = n(), mean = mean(abs_change), median = median(abs_change)) %>% 
               pivot_longer(cols = c("mean", "median"), names_to = "Statistic") %>% ungroup(), 
               mapping = aes(xintercept = abs(value)/10^6, linetype = Statistic), size = 0.75
               ) + 
      facet_grid(rows = vars(trend), cols = vars(vert_class),
                 scales = "free",
                 labeller = as_labeller(aoh_type_labels)) +
      theme_classic() +
    scale_x_continuous(guide = "axis_minor", minor_breaks = seq(from = 0.1, to = 1.2, by = 0.1)) +
            
      scale_fill_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)], values = palette_du_jour2[c(1, 3, 6)]) +
      labs(x = expression("Absolute change in AOH (10"^{6}*" ha)"), y = "Count") + 
      theme(legend.position = "right", ggh4x.axis.ticks.length.minor = rel(2/3))


# --------- b ----------- #
aoh_est_change_tmp %>%
  group_by(site, vert_class, trend) %>%
  summarise(n = n(), mean = mean(abs_change), median = median(abs_change)) %>%
  ggplot() + 
  geom_point(aes(x = mean, y = site, col = trend, group = vert_class), size = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)]) +
  facet_grid(. ~ vert_class, scales = "free")


# --------- c ----------- #
aoh_est_change_tmp %>%
  group_by(site, trend) %>%
  summarise(n = n(), mean = mean(abs_change), median = median(abs_change)) %>%
  ggplot() + 
  geom_point(aes(x = mean, y = site, col = trend), size = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)])


aoh_est_change_tmp %>% 
  group_by(site, vert_class, trend) %>%
  summary()


# ----------------------------------------------------------------- #
# d. mean factor change, by trend, by taxonomic group
# e. mean factor change, by trend, by taxonomic group, by site
# f. mean factor change, by trend, by site
# ----------------------------------------------------------------- #

# --------- d ----------- #
aoh_start_end_l_tmp_plots %>% 
  filter(window_size == 5, !is.na(trend)) %>%
  group_by(trend, vert_class) %>%
  summarise(n = n(), mean = mean(abs(ratio_mod)), median = median(abs(ratio_mod))) %>% 
  # pivot_longer(cols = c("mean", "median"), names_to = "Statistic") %>% 
  ungroup() # %>%
  ggplot() + 
  geom_point(aes(x = mean, y = vert_class, col = trend, group = vert_class), size = 2) +
  geom_point(aes(x = median, y = vert_class, col = trend, group = vert_class), size = 2, shape = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)])

# --------- e ----------- #
aoh_start_end_l_tmp_plots %>% 
  filter(window_size == 5, # abs(ratio_mod) < 15,
         !is.na(trend)) %>%
  group_by(trend, vert_class, site) %>%
  summarise(n = n(), mean = mean(abs(ratio_mod)), median = median(abs(ratio_mod))) %>%
  ggplot() + 
  geom_point(aes(x = mean, y = site, col = trend, group = vert_class), size = 2) +
  geom_point(aes(x = median, y = site, col = trend, group = vert_class), size = 2, shape = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)]) +
  facet_grid(. ~ vert_class, scales = "free")


# --------- f ----------- #
aoh_start_end_l_tmp_plots %>% 
  filter(window_size == 5, # abs(ratio_mod) < 15,
         !is.na(trend)) %>%
  group_by(trend, site) %>%
  summarise(n = n(), mean = mean(abs(ratio_mod)), median = median(abs(ratio_mod))) %>%
  ggplot() + 
  geom_point(aes(x = mean, y = site, col = trend), size = 2) +
  theme_classic() +
  scale_color_manual(name = "Trend", labels = palette_labels[c(1, 3, 6)],
                    values = palette_du_jour[c(1, 3, 6)])



```

# Extras



```{r seff}
# extract run codes:
list.files("scripts/cluster/slurm_out") %>% 
  grep("aoh_hab*", ., value = TRUE) %>% grep("aoh_hab11_*", ., value = TRUE) %>%
  str_extract(., "[0-9]{6,10}_[0-9]{1,2}") %>% #unique()
  paste0("seff ", .) %>%
  paste(., collapse = "; ") %>%
  cat()

1202/60 # 20 minutes for shaanxi


cat(
  paste("seff", paste0("39004952_", 1:27), collapse = "; "),
  "> text2.txt"
    )
# Use the above to make seff calls to get the full times and memory usage for the full array run
# then copy and paste this output into a 

paste("seff", paste0("39537809_", c(1, 7, 8, 10)), collapse = "; ")


txt <- read_csv("scripts/ref/seff_out_5_potential_age.csv")
txt <- read_csv("scripts/ref/seff_out_aoh.csv")
txt <- read_csv("scripts/ref/seff_out_run_1_2.2.csv")

txt %>% print(n = 15)


seff <- tibble(
  # core_index = 1:11,
  job_id = str_subset(txt$out, "^Job ID:"),
  array_id = str_subset(txt$out, "Array Job ID:"),
  time = str_subset(txt$out, "CPU Utilized"), 
  mem_used = str_subset(txt$out, "Memory Utilized"),
  mem_given = str_subset(txt$out, "Memory Efficiency"),
  state = str_subset(txt$out, "State: ")
  ) %>%
  mutate(
    job_id = str_extract(job_id, "[0-9]{6,10}") %>% as.numeric(),
    array_id = str_extract(array_id, "[0-9]{6,10}_[0-9]{1,2}"),
    id = str_extract(array_id, "[0-9]{6,10}_") %>% gsub("_", "", .) %>% as.numeric(),
    array = str_extract(array_id, "_[0-9]{1,2}") %>% gsub("_", "", .) %>% as.numeric(),
    time = str_extract(time, "[0-9][0-9]:[0-9][0-9]:[0-9][0-9]"),
    mem_used = str_extract(mem_used, "[0-9]{2,3}.[0-9][0-9]..."),# %>% as.numeric(),
    mem_used_p = str_extract(mem_given, "[0-9]{1,2}.[0-9][0-9]%"),
    mem_given = str_extract(mem_given, "[0-9]{2,3}.[0-9][0-9] GB") %>% 
      gsub(" GB", "", .) %>% as.numeric(),
    
    file =
      list.files("scripts/cluster/slurm_out") %>%
      grep("aoh_hab*", ., value = TRUE) %>%
      str_subset(array_id),
    label = str_replace(file,
                        paste0("_", array_id, ".txt"), "")
    ) %>%
  select(
    # label,
    everything()
    )

seff %>% arrange(array) %>% print(n = 30)
seff %>% filter(grepl("COMPLETED", state)) %>% arrange(array) %>% print(n = 30)

seff %>% select(state) %>% unique()
seff %>% select(label) %>% unique()

seff %>% mutate(
  file =
    list.files("scripts/cluster/slurm_out") %>%
    grep("aoh_hab*", ., value = TRUE), #%>%
    # str_subset(array_id),
  label = str_replace(file,
                      paste0("_", array_id, ".txt"), ""))

seff %>%
  filter(label == "aoh_hab10",
         # !str_detect(state, "CANCELLED")
         ) %>%
  filter(!str_detect(state, "COMPLETED")) %>%
  arrange(array) %>% print(n = 30)

list.files("scripts/cluster/slurm_out") %>% 
      grep("aoh_hab*", ., value = TRUE)

species_list %>% 
  filter(core_index == 1) %>%
  tail( n = 30)

species_list %>% 
  filter(core_index == 1) %>%
  .$binomial %>% grep("Emberiza", .)

seff %>% 
  filter(job_id == "40322150_1")

seff %>% filter(id == "40402581") %>% print(n =30)

seff %>% arrange(desc(time))

seff
seff %>%
  filter(grepl("fail", state, ignore.case = TRUE)) %>% arrange(array) %>% print(n = 30)

seff %>%
  select(id) %>% unique()

```


```{r AOH-suitability-by-season}
# Do species have seasonal suitabilities?
habitat_prefs$binomial %>% unique() %>% length() # 2312
habitat_prefs %>%
  filter(binomial %in% unique(species_list$binomial), 
         !is.na(map_code), suitability == "Suitable") %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  # filter(!(vert_class == "bird" & is.na(season))) %>%
  group_by(season_code, vert_class) %>%
  summarise(n_sp = n()) %>%
  print(n = 30)

# ok, once I filter this to just suitable habitats, the unknown seasonality and na birds disappear
# 4 season == NA bird entries
# 20 seasonal unknown entries (17 mammals, 3 birds), totaling 6 species.
# unk_sp <-
  habitat_prefs %>%
  filter(binomial %in% unique(species_list$binomial), 
         !is.na(map_code), suitability == "Suitable") %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  left_join(habitat_age_req_coded %>% select(binomial, common_names)) %>%
  filter(
    #!(vert_class == "bird" & is.na(season)),
    is.na(season)
    # grepl("unknown", season, ignore.case = TRUE)
    ) %>%
  select(vert_class, binomial, common_names, name, map_code, season_code) #%>%
  # .$binomial %>% unique()

habitat_prefs %>% 
  filter(binomial %in% unk_sp, !is.na(map_code)) %>% 
  left_join(habitat_age_req_coded %>% select(binomial, common_names)) %>%

  select(binomial, common_names, name, map_code, season) %>%
  print(n = 100)

# what are their habitat descriptions?
habitat_age_req_coded %>% filter(binomial %in% unk_sp) %>%
  select(vert_class, binomial, common_names, habitat)
  

habitat_prefs %>%
  filter(binomial %in% unique(species_list$binomial), !is.na(map_code)) %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>% nrow()
  filter(!(vert_class == "bird" & is.na(season)))

habitat_prefs %>%
  filter(binomial %in% c("Recurvirostra americana", "Glaucidium brodiei"),
         !is.na(map_code))

species_ranges %>% st_drop_geometry() %>% as_tibble() %>%
  filter(binomial %in% c("Recurvirostra americana", "Glaucidium brodiei"))

species_ranges %>% filter(binomial == "Glaucidium brodiei") %>% select(seasonal) %>% plot()

jung_hab_type_area_df %>%
  filter(site == "nebraska") %>%
  arrange(habitat_type)

jung_hab_type_area_df %>%
  filter(site == "chongqing") %>%
  arrange(habitat_type)


species_list %>% nrow() # 4001 (old: 4038)
species_list$binomial %>% unique %>% length # 2187 # number of unique species (after filtering by habitat, elevation)


# number of species in each class at each site
species_list %>% 
  group_by(site, vert_class) %>% 
  summarise(num_sp = n()) 


# If they don't have suitabilities, should I drop them?



# Drop passage areas

species_ranges %>% 
  # st_drop_geometry() %>% 
  filter(binomial %in% unique(species_list$binomial),
         vert_class == "bird",
         binomial == "Catharus swainsoni", 
         site == site_df$site[11]) %>%
  # as_tibble() %>%
  select(
    # site, binomial,
         seasonal) %>%
  plot()


species_list %>% filter(str_detect(binomial, "Catharus swainsoni"))



# testing with the Swainson's Thrush
habitat_prefs %>% 
  filter(str_detect(binomial, "Catharus swainsoni")) %>%
  select(binomial, majorImportance:season, map_code, IUCNLevel) %>%
  arrange(season)



species_ranges$seasonal %>% unique() %>% sort()
habitat_prefs$season %>% unique() %>% sort()
habitat_prefs %>%
  filter(
    # season %in% c("Seasonal Occurrence Unknown","unknown")
    is.na(season), vert_class == "bird"
    )
  

habitat_prefs %>%
  select(binomial, majorImportance:season, map_code, IUCNLevel) %>%
  
  # update season_code:
  # --- Codes are: "Resident" (1), "Breeding" (2), "Non-breeding Season" (3), Passage (4), and Seasonal Occurrence Uncertain (5).
  mutate(season_code = case_when(
    grepl("resident", season, ignore.case = TRUE) ~ 1,
    season %in% c("breeding", "Breeding Season") ~ 2,
    season %in% c("non-breeding", "Non-Breeding Season") ~ 3,
    grepl("passage", season, ignore.case = TRUE) ~ 4,
    grepl("unknown", season, ignore.case = TRUE) ~ 5
    )) %>%
  # filter(season_code == 1) %>%
  select(season_code,season) %>% arrange(season_code) %>% unique()


habitat_prefs

habitat_prefs %>%
  left_join(unique(select(species_list, binomial, vert_class)), by = "binomial") %>%
  filter(vert_class == "bird") %>%
  select(season, suitability) %>% unique() %>% arrange(suitability)

habitat


species_ranges %>%
  filter(vert_class == "bird", binomial == sp_name2)
```


```{r inner-join-suitability-by-season}
aoh_l$aoh_type %>% unique()

tmp_aoh <- aoh_l %>% 
  filter(aoh_type == "max_abn_iucn", #binomial == sp_name, 
         # site == site_df$site[site_index],
         year %in% 2011:2015) %>% 
  select(binomial, year, map_code, season, area) #%>% print(n=200)

# filter to just the combinations of map_code and season_code that are suitable
habitat_combos <- z1 %>% select(binomial, season_code, map_code, IUCNLevel) %>% arrange(season_code, map_code)
habitat_prefs %>% # extract the habitat classifications for the species in question
  filter(suitability == "Suitable", !is.na(map_code)) %>%
  select(binomial, season_code, map_code, IUCNLevel)
  

tmp_aoh %>%
  rename(season_code = season) %>%
  inner_join(z1 %>% select(binomial, season_code, map_code, IUCNLevel))


# ok, now I need to figure out how to get the combo of NA seasons to not drop those AOH areas.

# here's a way to update the NA season_codes to 99
habitat_prefs %>% # extract the habitat classifications for the species in question
  filter(suitability == "Suitable", !is.na(map_code),
         binomial == "Acris crepitans") %>%
  select(binomial, season_code, map_code, IUCNLevel) %>%
  mutate(season_code = case_when(
    is.na(season_code) ~ 99,
    TRUE ~ season_code
  ))

# create a new column showing whether the species has NA season suitabilities
habitat_prefs %>% # extract the habitat classifications for the species in question
  filter(suitability == "Suitable", !is.na(map_code),
         binomial == "Acris crepitans") %>%
  select(binomial, season_code, map_code, IUCNLevel) %>%
  mutate(season_na = is.na(season_code))
```


```{r deal-w-multiple-season-NA}
tmp1 <- habitat_prefs %>% # extract the habitat classifications for the species in question
  filter(suitability == "Suitable", !is.na(map_code),
         binomial == "Acris crepitans")

tmp1 <- rbind(tmp1, tmp1[4,])
tmp1[5, "season_code"] <- 1

sp_w_na_suitabilities <- habitat_prefs %>%
  filter(is.na(season_code)) %>%
  # select(binomial, season_code) %>% unique() %>%
  .$binomial %>% unique()

sp_w_na_suitabilities_gt_1 <- habitat_prefs %>%
  filter(binomial %in% sp_w_na_suitabilities, suitability == "Suitable", !is.na(map_code)) %>%
  select(binomial, season_code) %>% unique() %>%
  group_by(binomial) %>% summarise(n_sp = n()) %>% arrange(desc(n_sp)) %>%
  filter(n_sp > 1) %>%
  left_join(habitat_age_req_coded %>% select(binomial, common_names, vert_class)) %>%
  .$binomial

sp_w_na_suitabilities_gt_1
# "Arctonyx albogularis" # hog badger, exclude NA season (grassland)
# "Canis latrans" # coyote - exclude NA season (urban areas - these are probably suitable, but not large enough to matter for abandonment context)
# "Glaucidium brodiei" # These were shrubland high altitude, but this should be updated to 1
# "Monodelphis americana" # Northern Three-striped Opossum, removed from species_list for lack of habitat in Goias.
# "Mustela sibirica" # Siberian weasel, NA seas is 109 forest, but this should be updated to 1
# "Myotis daubentonii" # Daubenton's Myotis (bat) - this just has two different seasons. No update necessary
habitat_prefs %>% 
  filter(binomial %in% sp_w_na_suitabilities_gt_1, suitability == "Suitable", !is.na(map_code)) %>%
  select(binomial, season_code, map_code, IUCNLevel) %>%
  arrange(binomial, season_code) %>%
  print(n = 40)

habitat_age_req_coded %>% filter(binomial == "Monodelphis americana") # not in the habitat_coded
species_ranges %>% filter(binomial == "Monodelphis americana") %>%
  select(seasonal) %>% plot()
habitat_prefs %>% filter(binomial == "Monodelphis americana")
species_list %>% filter(binomial == "Monodelphis americana") # not in the species list - removed for lack of habitat at Goias
jung_hab_type_area_df %>%
  filter(site == "goias") 
elevation_prefs %>% filter(binomial == "Monodelphis americana")

# five species have habitat preferences that include NA and other codes.


# for these species, I'll fix these codes so that they are changed if they should be included (Glaucidium brodiei (collared owlet) and Mustela sibirica (siberian weasel)) or left alone if they should be excluded with NA season codes.
```


```{r dev-inner-join}
# for these species, I'll fix these codes so that they are changed if they should be included (Glaucidium brodiei (collared owlet) and Mustela sibirica (siberian weasel)) or left alone if they should be excluded with NA season codes.

# Extract list of species with some habitat suitabilities with season marked as NA, and some with a code.
# In these contexts, the NA season should be filtered out.
# Note that some species have been directly updated in the creation of "habitat_prefs" [Glaucidium brodiei (collared owlet) and Mustela sibirica (siberian weasel)].
# For species with *only* NA season codes, I'll leave these in, and treat them as suitable in all seasons.

habitat_prefs %>%
  filter(binomial %in% unique(species_list$binomial), 
         !is.na(map_code), suitability == "Suitable") %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  # filter(!(vert_class == "bird" & is.na(season))) %>%
  group_by(season_code, vert_class) %>%
  summarise(n_sp = n()) %>%
  print(n = 30)

# ---------- #
# extract list of species with NA season suitabilities:
sp_w_na_suitabilities <- habitat_prefs %>%
  filter(is.na(season_code)) %>%
  # select(binomial, season_code) %>% unique() %>%
  .$binomial %>% unique()

# ---------- #
# Extract list of species with some habitat suitabilities with season marked as NA, and some with a code.
# i.e., with more than one habitat suitability season code, one of which is NA
# In these contexts, the NA season should be filtered out.

sp_w_na_suit_and_more <- habitat_prefs %>%
  filter(binomial %in% sp_w_na_suitabilities, suitability == "Suitable", !is.na(map_code)) %>%
  select(binomial, season_code) %>% unique() %>%
  group_by(binomial) %>% summarise(n_sp = n()) %>% arrange(desc(n_sp)) %>%
  filter(n_sp > 1) %>%
  left_join(habitat_age_req_coded %>% select(binomial, common_names, vert_class)) %>%
  .$binomial


# ------------------------------------ #
# now, filter the NA season habitats out for these species.
# exclude na seasons for just these species:

habitat_prefs %>%
  filter(
    !(binomial %in% sp_w_na_suit_and_more & is.na(season_code))) %>% # filter out NA season_codes for species with multiple season codes, one being NA

  filter(binomial %in% unique(species_list$binomial),
         !is.na(map_code), suitability == "Suitable"
         ) %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  # filter(!(vert_class == "bird" & is.na(season))) %>%
  group_by(season_code, vert_class) %>%
  summarise(n_sp = n()) %>%
  print(n = 30)

# above is the number of habitat entries (multiple per species) - below is the number of species with each season_code
habitat_prefs %>%
  filter(
    !(binomial %in% sp_w_na_suit_and_more & is.na(season_code))) %>% # filter out NA season_codes for species with multiple season codes, one being NA
  
  filter(binomial %in% unique(species_list$binomial),
         !is.na(map_code), suitability == "Suitable"
         ) %>%
  left_join(select(species_list, vert_class, binomial) %>% unique()) %>%
  select(binomial, vert_class, season_code) %>% unique() %>%
  # filter(!(vert_class == "bird" & is.na(season))) %>%
  group_by(season_code, vert_class) %>%
  summarise(n_sp = n()) %>%
  print(n = 30)

# ------------------------------------- #
# extract a list of species with NA season_codes, so that I can make sure to treat them separately.
sp_na_season <- 
  habitat_prefs %>%
  filter(
    !(binomial %in% sp_w_na_suit_and_more & is.na(season_code)), # filter out NA season_codes for species with multiple season codes, one being NA 
    binomial %in% unique(species_list$binomial),
    !is.na(map_code), suitability == "Suitable",
    
    # select those species with na season codes
    is.na(season_code)
    ) %>%
  .$binomial %>% unique()
# 607 species

# check that these species *only* have NA season codes
habitat_prefs %>% filter(binomial %in% sp_na_season) %>% select(season_code) %>% unique() # check



# ------------------------- #
# Default approach is to use a simple inner_join, then bind to it a filtered aoh file with just the above species (with NA season codes)

tmp_aoh %>% filter(binomial %in% sp_na_season) # to bind back to the inner_joined df

aoh_l$binomial %>% unique() %>% length() # 2181 species:
aoh_l %>% group_by(aoh_type) %>% summarise(n_sp = length(unique(binomial))) # there are different numbers of species due to variance in the habitats that show up in different parts of sites. 
# the lc runs have more, because they are not restricted to the habitats only in abandoned pixels. The proportional adjustment is based on the habitats that are present in any part of the site, not just the abn.

aoh_l %>% filter(aoh_type == "max_abn_lc") %>% 
  filter(!binomial %in% unique(filter(aoh_l, aoh_type == "max_abn_iucn")$binomial)) %>%
  select(aoh_type:binomial) %>% unique()
  #1939 species:

species_ranges %>%
  filter(binomial == "Acrocephalus scirpaceus", site == "belarus") %>%
  select(seasonal) %>% plot()



tmp_aoh$binomial %>% unique() %>% length() # 1933 species:
tmp_aoh_filter$binomial %>% unique() %>% length() # 1664 species:
aoh_l %>%
  filter(aoh_type == "max_abn_lc")

aoh_filter %>% 
  select(aoh_type) %>%
unique()

aoh_filter <- 
  aoh_l %>%
  # rename(season_code = season) %>% # must update so that season_code matches
  inner_join(
    habitat_prefs %>% # extract the habitat classifications for the species in question
      filter(suitability == "Suitable", !is.na(map_code)) %>%
      select(binomial, season_code, map_code) %>%
      mutate(season = season_code) # add a new column to 1) match season in aoh, and 2) to retain season_code
    ) #%>%
  bind_rows(aoh_l %>% 
              filter(binomial %in% sp_na_season) %>% # to bind back to the inner_joined df
              mutate(season_code = NA)
            )

tmp_aoh_filter$binomial %>% unique() %>% length()



# ******* 

# ok - next steps: 
# add this as a filtering step right after loading the aoh_l layers
# build from this aoh_filter df going forward
# only load in the specific aoh types I'm actually going to use (i.e., IUCN ones)
```


```{r unresolved-hab-during-passage}
# one option is to have habitats for breeding or non-breeding count as suitable during passage
# assuming that passage habitat requirements are the most permissive

# how does this apply to shorebirds?
habitat_age_req_coded %>% filter(water_obl > 0.5, grepl("wisc", site_presence))
habitat_prefs %>% filter(str_detect(binomial, "Actitis macularius"))

habitat_prefs %>% filter(season_code == 4) %>%
  left_join(habitat_age_req_coded %>% select(binomial, water_obl, common_names, site_presence)) %>%
  filter(water_obl > 0.5) %>%
  # select(binomial, common_names, site_presence) %>% unique()
  filter(binomial == "Xenus cinereus") %>%
  select(season_code, map_code, IUCNLevel) %>% arrange(season_code, map_code)

# Not sure.. might be more complicated, but at least it won't apply for now, since I'm excluding passage areas.
```




