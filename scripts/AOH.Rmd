---
title: "AOH"
author: "Christopher L. Crawford"
date: "11/16/2021"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r initialize}
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/0_start.R")
# install.packages("terra")
# packageVersion("terra")
# library(terra)

# load files:
source("/Users/christophercrawford/work/projects/biodiversity_abn/scripts/util/_util_files.R")
```


# AOH


```{r load-raw-species-data}
# location of prepped range map data (from Zambia project)
p_range <- "/Volumes/GoogleDrive/My Drive/Zambia/agroEcoTradeoff/external/data_new/1_IUCN_dev/"
list.files(p_range) %>% grep("prep", .,  value = TRUE)



# Amphibians
load(paste0(p_range, "amp_valid_prepped.RData"), verbose = TRUE)
assign("amp_sf", amp_valid)
rm(amp_valid)
st_crs(amp_sf) <- st_crs(amp_sf)


# Birds
load(paste0(p_range, "bird_valid_prepped.RData"), verbose = TRUE)
assign("bird_sf", bird_valid)
rm(bird_valid)
st_crs(bird_sf) <- st_crs(bird_sf)


# Mammals
load(paste0(p_range, "mam_valid_prepped.RData"), verbose = TRUE)
assign("mam_sf", mam_valid)
rm(mam_valid)
st_crs(mam_sf) <- st_crs(mam_sf)


# Reptiles (GARD)
load(paste0(p_range, "gard_prep.RData"), verbose = TRUE)
gard_prep
assign("rep_sf", gard_prep)
rm(gard_prep)
st_crs(rep_sf) <- st_crs(rep_sf)


```

```{r validate}
# Amphibians

amp_sf <- amp_sf %>% sf::st_make_valid()

amp_valid_reasons <- st_is_valid(amp_sf, reason = TRUE)
length(amp_valid_reasons)
unique(amp_valid_reasons)
grep("Loop 0: Edge 9032 crosses edge 9034", amp_valid_reasons) 
# 7147:
# Vaillant's Frog
# Lithobates vaillanti

amp_sf[7147, ]


# Birds
bird_sf <- bird_sf %>% sf::st_make_valid()

bird_sf_valid_reasons <- st_is_valid(bird_sf, reason = TRUE)

length(amp_valid_reasons)
unique(amp_valid_reasons)
grep("Valid Geometry", bird_sf_valid_reasons, invert = TRUE) 



amp_sf[7147, ]

# Mammals


# Reptiles (GARD)

```

```{r crop-ranges-to-sites}
# Amphibians

names(amp_sf)
amp_s <- amp_sf[-7147, ] %>%
    st_intersection(., site_sf %>% filter(site == "shaanxi"))

amp_sc <- amp_sf[-7147, ] %>%
    st_intersection(., site_sf %>% 
                      filter(site %in% site_df$site[c(3,9)])
                    )

tic()
amp_sites <- amp_sf[-7147, ] %>% st_intersection(., site_sf)
toc() # 1402 sec

names(amp_sites)
amp_sites %>% st_drop_geometry() %>% select(binomial, category, site)

write_csv(amp_sites %>% st_drop_geometry(), 
          file = paste0(p_derived, "amp_sites.csv"))
st_write(amp_sites, paste0(p_derived, "amp_sites.shp")) # 
save(amp_sites, file = paste0(p_derived, "amp_sites.RData"))
# load(file = paste0(p_derived, "amp_sites.RData"), verbose = TRUE)



# Birds
bird_s <- bird_sf %>%
    st_intersection(., site_sf %>% filter(site == "shaanxi"))

```

```{r mam-sites}
mam_sites %>%
  filter(site == "shaanxi") %>%
  st_geometry() %>% plot()

# how many species occur at each site?

mam_sites %>%
  st_drop_geometry() %>%
  group_by(site) %>%
  select(site, binomial) %>%
  summarise(num_sp = length(unique(binomial)))

filter(mam_sites, site == "shaanxi")

mam_rich <- lapply(site_df$site,
                   function(i) {
                     
                     template <- raster()
                     extent(template) <- extent(raster(lc[[i]]))
                     res(template) <- res(lc[[i]])
                     
                     rast(
                       fasterize(sf = mam_sites %>%
                                   filter(site == i) %>% 
                                   st_cast("MULTIPOLYGON"), 
                                 raster = template, 
                                 fun = "sum"))})


rm(mam_rich)
plot(mam_rich[[1]])
plot(mam_rich[[1]]$sha_1)
dev.off()
```



```{r load-and-bind-cropped-ranges}

vert_list <- c("amp", "bird", "mam", "gard")

species_files <- list.files(paste0(p_derived, "species_ranges"), full.names = TRUE)

load(grep("amp", grep("RData", species_files, value = T), value = T), verbose = T)
amp_sites <- range_sites %>% 
  mutate(vert_class = "amp")

load(grep("bird", grep("RData", species_files, value = T), value = T), verbose = T)
bird_sites <- range_sites %>% 
  mutate(vert_class = "bird")

load(grep("mam", grep("RData", species_files, value = T), value = T), verbose = T)
mam_sites <- range_sites %>% 
  mutate(vert_class = "mam")

load(grep("gard", grep("RData", species_files, value = T), value = T), verbose = T)
gard_sites <- range_sites %>% 
  mutate(vert_class = "gard")



# Select and rename columns to facilitate join:

# note, mam and amp columns match perfectly
names(mam_sites) == names(amp_sites) 

amp_pre_merge <- amp_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no, presence, origin, seasonal,
         order_, family, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler, citation,
         genus, marine, terrestial, freshwater, # extras
         geometry
         )

mam_pre_merge <- mam_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no, presence, origin, seasonal,
         order_, family, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler, citation,
         genus, marine, terrestial, freshwater, # extras
         geometry
         )

bird_pre_merge <- bird_sites %>% 
  select(site, vert_class, binomial, category, 
         id_no = SISID, presence, origin, seasonal,
         order_ = Order_, family = FamilyName, 
         area_km2:threat_weight,
         pre_valid_reasons, post_valid_reasons,
         compiler = COMPILER, citation = CITATION,
         family_common = Family, CommonName, # extras
         geometry = Shape
)

gard_pre_merge <- gard_sites %>% 
  select(site, vert_class, binomial, 
         category = redlistCategory, # reptiles are not comprehensively assessed, but I've added the category for those that are assessed
         # id_no = SISID, presence, origin, seasonal,
         # order_ = Order_, family = FamilyName, 
         area_km2, range_size_quantile, inverse_range_glob,
         pre_valid_reasons, post_valid_reasons,
         # compiler = COMPILER, citation = CITATION,
         Group, # extras
         geometry
)

# -------------- bind rows: ---------------- #

vert_sites <- bind_rows(amp_pre_merge, bird_pre_merge, mam_pre_merge, gard_pre_merge)
save(vert_sites, file = paste0(p_derived, "species_ranges/vert_sites.RData"))


vert_sites %>% st_drop_geometry()

vert_sites %>% st_geometry() %>% plot()


df1 <- amp_sites %>% st_drop_geometry() %>% as_tibble()
df2 <- bird_sites %>% st_drop_geometry() %>% as_tibble()
df3 <- gard_sites %>% st_drop_geometry() %>% as_tibble()



sum(df2$binomial != df2$ScientificName) # all 
identical(df2$binomial, df2$ScientificName) # all equal!

names(df1)
names(df3)
names(df2)

df3$FID_2 %>% length()
df3$FID_2 %>% unique() %>% length()

df3$binomial %>% length()


```

```{r merge-polygons}

vert_sites %>% st_drop_geometry() %>%
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  select(binomial, vert_class, #site
         ) %>%
  unique() %>%
  nrow() 
# 4253 features (4856 with reptiles)
# 2230 species total occur at one or more of my sites (2656 if including reptiles)
# 4038 unique site, species pairs exist - this is the number of runs I'll have to do. (4641 if including reptiles)

vert_sites %>% nrow()
vert_sites_merged %>% nrow()
vert_sites_merged %>% st_drop_geometry() %>%
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  select(site, binomial, vert_class, #site
         ) %>%
  unique() %>%
  nrow() 



# how many sites have multiple polygons per species?
vert_sites %>% 
  filter(vert_class != "gard") %>% # I can't use reptile species because they do not all have habitat assessments from IUCN
  # 4253 features
  st_drop_geometry() %>%
  group_by(site, vert_class) %>% 
  summarise(num_rows = binomial %>% length(),
            num_sp = binomial %>% unique() %>% length()) %>% 
  filter(site == "wisconsin")

sf_use_s2()
sf_use_s2(FALSE)

tic()
vert_sites_merged <- vert_sites %>% 
  group_by(site, vert_class, binomial, category, id_no, #presence, origin, seasonal
           ) %>% 
  summarise() %>% ungroup()
toc()

tcom1 <- vert_sites %>% filter(binomial == "Lithobates palustris")

tcom1 %>%
  st_geometry() %>%
  plot()

tcom1
tcom1 %>% st_combine()

names(tcom1)
tcom2 <- tcom1 %>% 
  group_by(site, vert_class, binomial, category, id_no, presence, origin, seasonal) %>% 
  summarise() %>% ungroup()

tcom3 <- tcom1 %>%
  group_by(site) %>% summarise()

plot(tcom2)
plot(tcom1[1,])
tcom1 %>% group_by(c("site", "vert_class")) %>% summarise()


```



```{r habitat-prefs}
habitat_prefs <- read_csv(file = "/Volumes/GoogleDrive-107266184156135828486/My Drive/ee/habitat_prefs.csv")

habitat_prefs
names(habitat_prefs)

habitat_prefs$specialism %>% unique()

habitat_prefs$habitat_code %>% unique() %>% sort()
habitat_prefs$habitat_importance
habitat_prefs$habitat_suitability %>% unique() %>% sort()
habitat_prefs$className %>% unique() %>% sort()

habitat_prefs$scientificName %>% unique() %>% sort()

```


```{r fasterize-site_ranges}
# fasterize
amp_sc_r <- amp_sc %>%
  st_collection_extract(., "POLYGON") %>% # extract only polygons
  fasterize(sf = ., raster = template_raster, 
            field = NULL, fun = "sum")

plot(amp_sc_r)
plot(amp_sc_r, ext = my_ext)

plot(amp_sc)


amp_china <- amp_sf[-7147, ] %>%
    st_intersection(., st_geometry(china))


plot(st_geometry(china))
amp_china

st_bbox(china)

extent(filter(site_sf, site == "shaanxi"))

template_raster <- raster::raster(ncols = 100, nrows = 100,
                    xmn = -84, xmx = -83, 
                    ymn = 42, ymx = 43)

template_raster <- raster::raster(ncols = 100, nrows = 100,
                    extent(china))

extent(filter(site_sf, site == "shaanxi"))


values(template_raster) <- 1:ncell(template_raster)
plot(template_raster)
plot(china$geometry, add = T)
#extend(mask_filled, template_raster_extent, value = 0)

amp_china_poly <- amp_china %>% st_collection_extract(., "POLYGON") # extract only polygons


amp_china_r <- 
  fasterize(sf = amp_china_poly, raster = template_raster, 
            field = NULL, fun = "sum")

plot(amp_china_r)
my_ext <- drawExtent()

plot(amp_china_r, ext = my_ext)
plot(site_sf %>% 
       filter(site == "shaanxi") %>%
       st_geometry(), 
     add = T)

act <- rast(amp_china_r)
plot(act)
plot(act, extent = my_ext)

act_crop <- crop(act, terra::ext(my_ext))
amp_s
plot(act_crop, type = "classes")
plot(amp_s$geometry)


plot(amp_s$geometry)

plot(amp_sf[1, ]$geometry)

plot(site_sf %>% filter(site == "shaanxi") %>% st_geometry())
plot(amp_sf$geometry, add = TRUE)

```



```{r filter-ranges}
names(amp_sf)

amp_sf %>% select(binomial, category)

amp_sf %>%
  filter(presence == 1) %>%   # only records with Code 1 (Extant)
  filter(origin %in% c(1, 2)) %>%     # only native species (Code 1) and reintroduced (Code 2)
  filter(seasonal %in% c(1, 2, 3)) %>%   # selecting "Resident" (1), "Breeding" (2), and "Non-breeding Season" (3) ranges. Other categories include: Non-breeding Season (3), Passage (4), and Seasonal Occurrence Uncertain (5).
  filter(marine == "False") %>%   # removing all marine species
  filter(!category %in% c("EW", "EX")) %>% # remove Extinct or Extinct in the Wild species ("EW", "EX")
  
  print(n = 40)

```



```{r RS-AOH-tester}
library(sf)
AOH <- st_read(paste0(p_dat, "bd/AOH/reptilia_AOH/reptilia.shp"))

AOH %>% st_drop_geometry() %>% as_tibble()
object_size(AOH)
names(AOH)
head(AOH)
st_crs(AOH)



# plot
AOH %>% 
  filter(binom == "Archaius_tigris") %>% 
  st_geometry() %>% 
  plot()

AOH %>% 
  st_geometry() %>% 
  plot(add = TRUE)

plot(ne_countries()) # or all sub national level bodies plot(ne_states())

crs(ne_countries())

# Create template raster by extending the input raster (mask) to the extent of the input polygons.
mask_filled <- mask
mask_filled[is.na(mask_filled)] <- 0 # replace NAs with 0s

projection <- crs(AOH) # note, seems to work better than st_crs().

# make a template raster
mask <- raster()
res(mask) <- 0.01


# values(mask) <- 0 # If you want, you can add values to the raster. You don't have to though, and it just makes the raster HUGE at this resolution (4.8 GB)
# writeRaster(mask, "mask.tif") # if you add values, you'll need to just write it to your machine, otherwise you'll quickly run out of memory, as the fasterize layer will be the same size.  


AOH_r <- fasterize(AOH, mask, fun = "sum") # field = NULL by default, which gives every polygon a value of 1

# in the event that you want to build a raster based on 
template_raster <- extend(small_mask, extent(as.Spatial(sf_file)), value = 0)




# fasterize


  
```

```{r sparse}
library(sf)
library(raster)

AOH <- st_read(paste0(p_dat, "bd/AOH/reptilia_AOH/reptilia.shp"))

# check it out
AOH %>% 
  filter(binom == "Archaius_tigris") %>% 
  st_geometry() %>% 
  plot()

AOH %>% 
  st_geometry() %>% 
  plot(add = TRUE)
# tiny lil guys, eh?



# -------------------
# First, make a template raster

mask <- raster()
res(mask) <- 0.01


# values(mask) <- 0 # If you want, you can add values to the raster. You don't have to though, and it just makes the raster HUGE at this resolution (4.8 GB)
# writeRaster(mask, "mask.tif") # if you add values, you'll need to just write it to your machine, otherwise you'll quickly run out of memory, as the fasterize layer will be the same size.  


# -------------------
#  Fasterize: 

AOH_r <- fasterize(AOH, mask, fun = "sum") # field = NULL by default, which gives every polygon a value of 1

plot(AOH_r) # again.... tiny lil guys!




# -------------------
# Notes:

# If you aren't already familiar, these are great packages for basemaps:
install.packages("rnaturalearth")
devtools::install_github("ropensci/rnaturalearthdata")
devtools::install_github("ropensci/rnaturalearthhires")
library(rnaturalearth)
library(rnaturalearthdata)
library(rnaturalearthhires)

plot(ne_countries())  # nice!
# plot(ne_states()) # or all sub national level bodies with this one 



# if you need to reproject the mask before you fasterize, I think raster works best with: 
crs(AOH) # note, seems to work better than st_crs().

# in the event that you want to build a raster based on a smaller existing one
template_raster <- extend(small_mask, extent(as.Spatial(sf_file)), value = 0)



```


## Misc

```{r create-blank-template-rasters}
site_index


lapply(1:11, function(i) {
  template_r <- terra::rast(
    resolution = res(lc[[i]]),
    extent = ext(lc[[i]])
  )
  
  

  terra::writeRaster(template_r, 
                     filename = paste0(p_derived, "templates/", site_df$site[i], "_template.tif"),
                     overwrite = TRUE,
                     names = paste0(site_df$site[i], "_template"))
  })


rasterOptions()
rasterOptions(tmpdir = "/scratch/gpfs/clc6/biodiversity_abn/derived/tmp/")
tmp_r <- raster(ncols = 10, 
                nrows = 10, 
                resolution = 50)

values(tmp_r) <- 1:ncell(tmp_r)

plot(tmp_r)
plot(template_r)

```


# IUCN Data

```{r load-ranges}
# cropped range maps
load(file = paste0(p_derived, "species_ranges/vert_sites.RData"), verbose = TRUE)


vert_sites %>%
  st_drop_geometry() %>%
  filter(vert_class != "gard") %>%
  select(site, vert_class, binomial) %>% 
  unique() %>% 
  as_tibble() %>% 
  arrange(site, vert_class, binomial)
```


```{r IUCN-synonyms}
species_synonyms <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/synonyms.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, genusName, speciesName) %>%
    mutate(synonym = paste0(genusName, " ", speciesName))
}) %>% 
  bind_rows() 

species_synonyms_sub <- species_synonyms %>% 
  filter(synonym %in% unique(species_list$binomial) | 
           binomial %in% unique(species_list$binomial))

# write to file:
write_csv(species_synonyms, file = paste0(p_derived, "iucn_species_synonyms_subset.csv"))

# 25 species with names that do not match:

vert_sites %>% st_drop_geometry() %>% 
  filter(vert_class != "gard") %>% 
  select(binomial) %>% unique() %>% nrow() # 2230

habitat_prefs$binomial %>% unique() %>% length()
species_ranges$binomial %>% unique() %>% length()

# remove reptiles


habitat_prefs_all

# list of unique species-site combinations at my sites
non_match <-
  vert_sites %>% 
  st_drop_geometry() %>% as_tibble() %>%
  filter(vert_class != "gard") %>%
  select(site, vert_class, binomial) %>% 
  unique() %>% 
  filter(!binomial %in% unique(habitat_prefs$binomial))

non_match$binomial %>% unique() # 25 species in vert_sites are without a match.

# play with synonyms:
species_synonyms

species_synonyms %>% filter(synonym %in% unique(non_match$binomial)) %>% arrange(synonym) %>% print(n = 30) # only 24 species have synonyms...

species_w_syn <- 
  species_synonyms %>% 
  filter(synonym %in% unique(non_match$binomial)) %>% 
  arrange(synonym)# %>% .$synonym

# what species does not have a synonym?
non_match %>% filter(!binomial %in% species_w_syn$synonym) %>% .$binomial %>% unique

habitat_prefs %>% filter(binomial == "Naemorhedus griseus")
habitat_prefs_all %>% filter(binomial == "Naemorhedus griseus")
elevation_prefs %>% filter(binomial == "Naemorhedus griseus")
grep("Naemorhedus", habitat_prefs$binomial)

# all species in the genus
habitat_prefs_all[grep("Naemorhedus", habitat_prefs_all$binomial), c(1:3, 6)]


filter(species_synonyms, synonym %in% unique(species_list$binomial))

species_list %>% filter(binomial == "Capricornis sumatraensis")
vert_sites %>% filter(binomial == "Capricornis sumatraensis")
vert_sites %>% filter(binomial == "Capricornis milneedwardsii") %>% st_geometry() %>% plot()

```

```{r species-ranges}
# --------------------------------------------------- #
# create species_ranges, a subset of vert_sites
# --------------------------------------------------- #
# make sure to update species_ranges with synonyms

species_ranges <-
  vert_sites %>% 
  #st_drop_geometry() %>% as_tibble() %>%  # for testing only
  filter(vert_class != "gard") %>%
  
  # filter(binomial %in% species_w_syn$synonym) %>% # for testing only
  left_join(select(species_w_syn, new_binomial = binomial, synonym), by = c("binomial" = "synonym")) %>%
  mutate(binomial = ifelse(!is.na(new_binomial), new_binomial, binomial)) %>%
  left_join(select(species_w_syn, binomial, synonym), by = "binomial") %>%
  select(site:binomial, synonym, everything(), -new_binomial)
  
save(species_ranges, file = paste0(p_derived, "species_ranges/species_ranges.RData"))


species_ranges %>% 
  st_drop_geometry() %>% as_tibble() %>% 
  select(site:synonym) #%>% filter(!is.na(synonym))


species_list$binomial %>% unique() %>% length() # 2188 species
species_list %>% nrow() # 3979 unique runs
species_ranges$binomial %>% unique %>% length # 2230 # no species were removed
```

```{r habitat_prefs}
# make sure this loads with the most recent species_list (i.e., with fixed synonyms)
habitat_prefs <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/habitats.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, code, name:suitability, assessmentId, internalTaxonId)
}) %>% 
  bind_rows() %>% 
  filter(binomial %in% unique(species_ranges$binomial))

# update: add map_code to habitat_prefs for more exact filtering and joining.
habitat_prefs <- habitat_prefs %>% #select(code, name) %>% unique() %>% 
  # arrange(code) %>%
  left_join(iucn_crosswalk %>% filter(code != 5.1), by = "code") %>%
  mutate(map_code = ifelse(code == 5.1, 
                           ifelse(str_detect(name, "Tundra Wetlands"), 510, 501), 
                           map_code)) %>%
  select(-Coarse_Name, -lc, -IUCNLevel) %>%
  left_join(select(iucn_crosswalk, -code), by = "map_code") #%>% print(n = 110)

# all species:
habitat_prefs_all <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/habitats.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, code, 
           name:suitability, assessmentId, internalTaxonId)
}) %>% bind_rows()


habitat_details <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/assessments.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, redlistCategory, rationale, habitat, threats, population)
}) %>% 
  bind_rows() %>% 
  filter(binomial %in% unique(species_ranges$binomial))

# ----------------
# save updated file
# ----------------
write_csv(habitat_prefs, file = paste0(p_derived, "iucn_habitat_prefs_subset.csv"))
write_csv(habitat_details, file = paste0(p_derived, "iucn_habitat_details_subset.csv"))
```


```{r elevation_prefs}
# ---------------------------------------------------------- #
### Loading elevation data ####

elevation_prefs <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/all_other_fields.csv")#, n_max = 10
    ) %>%
    select(binomial = scientificName, 
           elevation_lower = ElevationLower.limit,
           elevation_upper = ElevationUpper.limit)
}) %>% 
  bind_rows() %>%
  
  # extract records for only those species of interest 
  filter(binomial %in% unique(species_ranges$binomial)) %>%
  
  # update elevation to account for NA
  mutate(elevation_lower = ifelse(is.na(elevation_lower), 0, elevation_lower),
         elevation_upper = ifelse(is.na(elevation_upper), 9999, elevation_upper)
         )

#
elevation_prefs %>%
  filter(elevation_upper == 0)

# Rana temporaria has its upper and lower elevations mixed up.
# Fix.
elevation_prefs <- elevation_prefs %>%
  mutate(elevation_lower = ifelse(binomial == "Rana temporaria",
                                  0, elevation_lower),
         elevation_upper = ifelse(binomial == "Rana temporaria",
                                  2700, elevation_upper)
  ) #%>% filter(binomial == "Rana temporaria")



elevation_prefs %>% 
  mutate(check = elevation_upper - elevation_lower) %>%
  filter(check < 0)


# ----------------
# save updated file
# ----------------

write_csv(elevation_prefs, file = paste0(p_derived, "iucn_elevation_prefs_subset.csv"))
```



```{r species_list}
# --------------------------------------------------- #
# create species_list, a list of unique species-site combinations at my sites
# --------------------------------------------------- #

# ------------------------------------------------------------- #
# Step. 1
# extract species list from vert_sites, and update species with different names now.
# ------------------------------------------------------------- #

species_list <- vert_sites %>%
  st_drop_geometry() %>%
  filter(vert_class != "gard") %>% 
  select(site, vert_class, binomial) %>% unique() %>%
  arrange(site, vert_class, binomial) %>% as_tibble() %>% 
  
  # update list species synonyms:
  # filter(binomial %in% species_w_syn$synonym) %>% # for testing only
  left_join(select(species_w_syn, new_binomial = binomial, synonym), by = c("binomial" = "synonym")) %>%
  mutate(binomial = ifelse(!is.na(new_binomial), new_binomial, binomial)) %>%
  left_join(select(species_w_syn, binomial, synonym), by = "binomial") %>% 
  select(-new_binomial)

# at this stage:
# number of unique runs:
species_list %>% nrow() # 4038

# number of unique species (pre filtering by habitat, elevation)
species_list$binomial %>% unique() %>% length # 2230

# number of species in each class at each site
species_list %>% 
  group_by(site, vert_class) %>% 
  summarise(num_sp = n()) 

# update based on habitat suitability

# ----------------
# fix and filter based on habitat suitability and presence (must load habitat_prefs - see below)
# ----------------
species_list$binomial %>% unique() %>% length # 2230
habitat_prefs$binomial %>% unique() %>% length() # 2229, now having reloaded this habitat_prefs with the , the only species that still doesn't have a match is the Chinese goral (Naemorhedus griseus)


suitable_sp <- habitat_prefs %>%  # having loaded habitat_prefs for all 2229 species
  filter(binomial %in% species_list$binomial,  # note, this is uncessary, if habitat_prefs has already been subset by species_list
         suitability == "Suitable") %>%
  .$binomial %>% unique()

length(suitable_sp) # 2226

tmp_sp <- species_list %>%
  filter(!binomial %in% suitable_sp) %>% 
  .$binomial %>% unique()

# three of these four excluded species have unknown suitabilities
# the fourth is "Naemorhedus griseus" which has been removed from the redlist for some reason
habitat_prefs %>% filter(binomial %in% tmp_sp[-1])
habitat_prefs %>% filter(binomial %in% suitable_sp) # extract the habitat classifications for the species in question


# filter to just those species with a) suitable habitat that b) occurs at one of the sites.
# this excludes about 40 species
species_w_habitat <- 
  habitat_prefs %>% 
  filter(suitability == "Suitable",
         code %in% jung_hab_type_area_df$code)

species_w_habitat %>% .$binomial %>% unique() %>% length() # 2188 (including all habitat_prefs)

# which species get removed?
species_without_habitat <- species_list %>% 
  filter(!binomial %in% unique(filter(species_list, 
                                      binomial %in% species_w_habitat$binomial)$binomial)
) 

species_without_habitat %>% .$binomial %>% unique() %>% sort()

# ------------------------------------------------------------- #
# Step. 2
# Further filter species_list to exclude those site-species combinations where that species does not have any habitat
# ------------------------------------------------------------- #

# this initial version leaves species at sites that don't have habitat, as long as some other site has habitat for that species
# species_list <- species_list %>%
#   # filter(binomial %in% species_w_habitat$binomial) # also works
#   filter(binomial %in% 
#            unique(filter(habitat_prefs, 
#                          suitability == "Suitable",
#                          code %in% jung_hab_type_area_df$code)$binomial))

# Sequentially figure out which species have habitat at each specific site, and filter to those

species_to_remove <- lapply(1:11, function(i){
  site_habitats_tmp <- sort(filter(jung_hab_type_area_df, site == site_df$site[i])$code)
  site_species <- sort(filter(species_list, site == site_df$site[i])$binomial)
  
  # a list of species at a given site, with habitat at that site
  species_with_habitat_at_site <- habitat_prefs %>% 
    filter(binomial %in% site_species,
           suitability == "Suitable",
           code %in% site_habitats_tmp) %>% 
    .$binomial %>% unique()
  
  species_list %>% 
  filter(site == site_df$site[[i]],
         !binomial %in% species_with_habitat_at_site)
}) %>% bind_rows()


# ------ update species_list again -------- #
species_list <- lapply(1:11, function(i){
  site_habitats_tmp <- sort(filter(jung_hab_type_area_df, site == site_df$site[i])$code)
  site_species <- sort(filter(species_list, site == site_df$site[i])$binomial)
  
  # a list of species at a given site, with habitat at that site
  species_with_habitat_at_site <- 
    habitat_prefs %>%
    filter(binomial %in% site_species,
           suitability == "Suitable",
           code %in% site_habitats_tmp) %>% 
    .$binomial %>% unique()
  
  species_list %>% 
  filter(site == site_df$site[[i]],
         binomial %in% species_with_habitat_at_site)
}) %>% bind_rows()



# ------------------------------------------------------------- #
# Step. 3
# Further filter species_list to exclude those species appropriate elevations at each site
# ------------------------------------------------------------- #

site_elevation_range <- tibble(
  site = site_df$site,
  min = sapply(1:11, function(i) {minmax(elevation_map[[i]])[, 1]})[1,],
  max = sapply(1:11, function(i) {minmax(elevation_map[[i]])[, 1]})[2,],
  )

# manually check to make sure the elevation filtering works right:
for (i in 1:11) {
  cat("species outside the elevational limit at:", site_df$site[i], fill = TRUE)
  print(site_elevation_range[i, ])
  print(
    elevation_prefs %>% 
      filter(binomial %in% filter(species_list, site == site_df$site[i])$binomial,
             !(elevation_lower > site_elevation_range[i,]$max |
                elevation_upper < site_elevation_range[i,]$min)))
  }


# ---------------------- filter species_list --------------------- #
species_list <- lapply(1:11, function(i) {
  sp_within_elevational_range <- 
    elevation_prefs %>% 
      filter(binomial %in% filter(species_list, site == site_df$site[i])$binomial,
             !(elevation_lower > site_elevation_range[i,]$max |
                elevation_upper < site_elevation_range[i,]$min))
  
  species_list %>% 
    filter(site == site_df$site[[i]],
           binomial %in% sp_within_elevational_range$binomial
           )
}) %>% bind_rows()


species_ranges$binomial %>% unique %>% length # 2230 species

# final counts
species_list$binomial %>% unique %>% length # 2104 species
species_list %>% nrow() # 3744 unique runs



```

```{r parallelize-aoh}

# ------------------------------------------------------------- #
# Step. 4
# Parallelize species_list, with core index assignments
# ------------------------------------------------------------- #

species_list


aoh_dt_11_test
aoh_31_df %>% select(site, binomial, time) %>% unique()

aoh_dt_11_test %>% 
  select(site, binomial, time) %>% unique() %>% print(n = 200)

comparing_times0
# comparing_times0 <- aoh_dt_11_test %>% 
comparing_times <- aoh_31_df %>%
  select(site, binomial, time) %>% unique() %>%
    group_by(site) %>%
    summarise(max_time = max(time),
              mean_time = mean(time)) %>% 
  mutate(time_rel_max_mx = max_time / max(max_time),
         time_rel_max_mn = mean_time / max(mean_time),
         ncell = sapply(1:11, function(i) {ncell(lc[[i]])}),
         ncell_rel_max = ncell / max(ncell),
         factor_mx = pmax(time_rel_max_mx, ncell_rel_max),
         record_multiplier_mx = max(factor_mx)/factor_mx,
         record_multiplier_mn = max(time_rel_max_mn)/time_rel_max_mn,
         )

comparing_times
# time scales straightforwardly with the number of cells (linearly)
# so, I can run about X times as many records at smaller sites.

vert_sites %>%
  st_drop_geometry() %>%
  filter(vert_class != "gard") %>%
  select(site, vert_class, binomial) %>%
  unique() %>% as_tibble() %>% nrow()

# 4038 unique site-vert records, before filtering

species_list %>% nrow() # 3744 unique runs, after filtering

records_by_site <- species_list %>%
  group_by(site) %>% summarise(runs = length(unique(binomial)))

comparing_times0
comparing_times

# calculate the number of cores, across a range of batch sizes
core_tests <- lapply(50:150, function(i) {
    tmp <- comparing_times %>% 
  select(site, max_time, mean_time, record_multiplier = record_multiplier_mn) %>%
  left_join(records_by_site, by = "site") %>%
  mutate(sp_per_core = i * record_multiplier,
         cores_needed = runs/sp_per_core,
         cores_rounded = ceiling(cores_needed),
         runs_per_core = ceiling(runs/cores_rounded),
         hr_if_max = runs_per_core * max_time / 60 / 60,
         hr_if_mean = runs_per_core * mean_time / 60 / 60,         
         diff = cores_rounded - cores_needed)
    
    tibble(block_size = i,
           num_cores = sum(tmp$cores_rounded),
           diff = sum(tmp$diff),
           mean_time_needed_mn = mean(tmp$hr_if_mean),
           mean_time_needed_mx = mean(tmp$hr_if_max)
           )
}) %>% bind_rows

core_tests %>% arrange(diff) %>% print(n= 20)


# looks like 101 is the best mix of size and time, while minimizing the "unused" cores
# with 101 runs per core
calc_cores0

calc_cores <-
  comparing_times %>% 
  select(site, max_time, mean_time, record_multiplier = record_multiplier_mn) %>%
  left_join(records_by_site, by = "site") %>%
  mutate(sp_per_core = 137 * record_multiplier, # 137... previously 92 or 138
         cores_needed = runs/sp_per_core,
         cores_rounded = ceiling(cores_needed),
         runs_per_core = ceiling(runs/cores_rounded),
         hr_if_max = runs_per_core * max_time / 60 / 60,
         hr_if_mean = runs_per_core * mean_time / 60 / 60,
         diff = cores_rounded - cores_needed)

calc_cores

sum(calc_cores$cores_rounded)
sum(calc_cores$diff)


# construct a vector of index numbers based on the number of cores, the species per core, etc.

della_index <- lapply(1:11, function(i) {
  tmp <- calc_cores %>% filter(site == site_df$site[i])
  index <- rep(1:tmp$cores_rounded, each = tmp$runs_per_core)
  index <- index[1:tmp$runs]
  
  if(i>1) {index <- index + sum(calc_cores$cores_rounded[1:(i-1)])}
  
  index
}) %>% unlist()

della_index[1:1000 + 2*1000]
length(della_index)

# add index to the species_list
# species_list <- species_list %>% select(-index)
species_list <- species_list %>%
  mutate(core_index = della_index)

unique(species_list$core_index)

species_list %>% filter(site %in% c("shaanxi", "chongqing")) %>% .$core_index %>% unique()
calc_cores
```

```{r write-final-species-list}
# ------------------------------------------------------------- #
# Step. 5
# Write out the final, filtered species_list
# ------------------------------------------------------------- #
write_csv(species_list, file = paste0(p_derived, "species_list.csv"))
```


```{r load-IUCN-assessment-data}
# ---------------------------------------------- #
# Jung IUCN habitat types map crosswalk
# ---------------------------------------------- #
# iucnHabitatTranslator <- read_csv(paste0(p_proj, "/resources/IUCNhabitatMap_translator.csv"))
# 
# iucn_crosswalk <- read_csv(paste0(p_derived, "iucn_lc_crosswalk.csv")) %>%
#   left_join(iucnHabitatTranslator, by = "map_code") %>% 
#   arrange(map_code)
# 
# iucn_crosswalk %>% write_csv(paste0(p_derived, "iucn_lc_crosswalk.csv"))
iucn_crosswalk %>% print(n = 50)

iucn_crosswalk <- read_csv(paste0(p_derived, "iucn_lc_crosswalk.csv"))
```

```{r common-names}

common_names <- lapply(c("LC", "nonLC"), function(i) {
  read_csv(
    file = paste0(p_dat, "bd/IUCN/redlist_2021_11_17_", i, "/common_names.csv")#, n_max = 10
  ) %>% 
    select(binomial = scientificName, common_name = name 
           # , redlistCategory, rationale, habitat, threats, population
           )
}) %>% 
  bind_rows() %>% 
  filter(binomial %in% unique(species_ranges$binomial))


write_csv(common_names, file = paste0(p_derived, "iucn_common_names_subset.csv"))


common_names %>%
  group_by(binomial) %>%
  summarise(common_names = str_c(common_name, collapse = "; "))
  

species_list %>%
  group_by(binomial, vert_class) %>%
  summarise(site_presence = str_c(site, collapse = "; ")) %>% ungroup()


common_names$binomial %>% unique %>% length
species_ranges$binomial %>% unique %>% length
species_list$binomial %>% unique %>% length

```


# AOH 

## {terra} AOH dev (based on Yiwen's script)

```{r load-map-files-AOH}
#### -------- load habitat map ---------- ####

### Loading suitable habitats from IUCN/IIASA #####
# iucnHabitatClass <- raster("~/Dropbox/PostDoc4_Princeton/Species Traits/iucn_habitatclassification_composite_lvl2_ver003_resampled.tif")

# jung_l2 <- rast(paste0(p_dat, "Habitats/Jung_GlobalHabitatTypes/iucn_habitatclassification_composite_lvl2_ver004.tif"))


# if Jung map:
habitat_map <- rast(paste0(p_derived, "site_jung/", site_df$site[site_index], "_jung_l2_30.tif"))

# if Yin et al. 2020 LC maps
habitat_map <- lc[[site_index]][[yr_index]]
plot(habitat_map)

# load elevation raster list

elevation_map <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "elevation/", 
              site_df$site[i], "_srtm_crop.tif")
       )
  })

site_area_ha <- lapply(
  list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
  function(i) rast(i)
)
names(site_area_ha) <- site_df$site

```

```{r aoh-dev}
# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]
species_list[, 3]
aoh_df <- tibble(species = species_list[, "binomial"],
                  IUCN_AOO = NA,
                  IUCN_AOH = NA)



i <- 1
for(i in seq_along(species_list$binomial)) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  
  # ---- extract species range polygons at the site ---- #
  
x1 <- species_ranges[species_ranges$binomial == paste0(species_list[i, "binomial"]),] # select a subset of species range polygons based on binomial
species_name <- "Lithobates palustris"

x1 <- vert_sites[vert_sites$binomial == "Lithobates palustris", ] %>% 
  st_cast() # update all features to multipolygon, for 


# ---- crop the land cover map in question to the extent of the range map ---- #
tic()
y1 <- terra::crop(#iucnHabitatClass,
  habitat_map[[11]], # site_jung_l2_30[[11]],
  x1) #%>% raster()
toc()

site_area_ha[[site_index]]



# ---- turn the species range polygons (sf) into a raster ---- #
# this involves creating a template raster to match the dimensions of the IUCN Habitat map, 
# and then using fasterize().
# if using this method, must first convert all sf objects to the same type (i.e., multipolygon)
# I can also do this using terra::rasterize(), but it's slightly slower. (~ 1 second for Wisconsin)

tic()
template_raster1 <- raster::raster(
  resolution = terra::res(site_area_ha[[site_index]]),
  ext = raster::extent(terra::ext(site_area_ha[[site_index]])[1:4]),
  ncols = terra::ncol(site_area_ha[[site_index]]),
  nrows = terra::nrow(site_area_ha[[site_index]]))


template_raster <- raster::raster(
  resolution = terra::res(y1),
  ext = raster::extent(terra::ext(y1)[1:4]),
  ncols = terra::ncol(y1),
  nrows = terra::nrow(y1))

x2 <- fasterize(x1, 
                template_raster# 
                # raster(y1)
                ) %>% rast()

x21 <- fasterize(x1,
                template_raster1# 
                # raster(y1)
                ) %>% rast()

toc()

plot(x2)
ext(x2)
ext(lc$wisconsin$y2017)

# writeRaster(x2,
            # filename = paste0(p_derived, "aoh/tmp/random_tmp.tif"), 
            # overwrite=TRUE)
# x2 <- rast(paste0(p_derived, "aoh/tmp/random_tmp.tif"))


# fasterize is faster than terra::rasterize(), but the step of writing the raster to file, then reloading as SpatRaster takes much longer.
# tic()
# x2t <- terra::rasterize(vect(x1), y1, # must convert sf to spatvector:
#                         #field="", 
#                         #fun = length#, sum = FALSE, 
#                         # filename = paste0(p_derived, "aoh/tmp/rasterize_tmp.tif"), overwrite=TRUE
#           )
# toc()
# 
# plot(x2t)


 # ---- update cell values to mask ---- #

# tic()
# x3 <- calc(x2_r, function(x) {x[!is.na(x)] <- 0; return(x)}) # passes a function setting all of the cell values that are not NAs to 0
# toc()

tic()
x3 <- subst(x2, 1, 0) # change cell value from 1 to 0.
# x3 <- x2 - 1 # can also do this, maybe just very slightly faster
toc()

# Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
# expanse() is much faster! But... it doesn't work with large rasters of the extent of some of my sites.

# aoh_df$IUCN_AOO[i] <- expanse(x2, unit = "km") # in km2

print(aoh_df, n = 30)

tic()
x2_area_test <- x3 %>%
  terra::cellSize(., unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE) %>% 
  as.numeric()

x2_area_test
toc()

tic()
x2_area_test1 <- terra::cellSize(x21, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
x2_area_test1
toc()


plot(x2)
plot(x3 + site_area_ha[[site_index]])
tic()
global(x3 + site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()
tic()
global(x2 * site_area_ha[[site_index]], fun = "sum", na.rm = TRUE)
toc()

x2 * site_area_ha[[site_index]] %>%
  global(., fun = "sum", na.rm = TRUE)


# by calculating cellSize()
tic()
x2_area <- 
  terra::cellSize(x2, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

aoh_df$IUCN_AOO[i] <- x2_area

site_area_ha[[11]]
plot(site_area_ha[[11]])

# mask the IUCN habitat map to the range raster
y2 <- x3 + y1
# y2 <- app(c(x3, y1), sum) # the same, but slightly slower
# y2 <- terra::mask(x3, y1)

plot(y2)

# ------------------------------------------------------------------------- #
### Habitat Filter ###
# ------------------------------------------------------------------------- #
species_list[i, "binomial"]

z1 <- habitat_prefs %>% 
  filter(binomial == species_name,
         suitability == "Suitable") # extract the habitat classifications for the species in question

suitable_habitat_codes <- iucn_crosswalk %>% 
  filter(code %in% unique(z1$code)) %>%
  # .$lc %>% 
  .$map_code %>% 
  unique() # extract the lc code from my crosswalk that correspond to the IUCN habitat codes

suitable_habitat_rcl <- iucn_crosswalk %>% 
  filter(code %in% unique(z1$code))


# my thoughts on how to do the land cover translation
# I have decided what proportion of "forest" go into what habitat type at each site. I don't know where though, so I'll just attribute this proportionally, evenly across the whole site. So, what I should do is apply this proportionally *after* I have clipped out the suitable habitats. 

# So, I need to build a translator for the IUCN habitat prefs, and then extract by that.
# I can then, in a separate step, multiply by the proportion in question.
# I can calculate the area in each habitat type, and if a species has a subset of one habitat type that is suitable (e.g., grassland, but not savanna or shrubland), I will then adjust the habitat area down by the proportion of my lc "grassland (4)" that is considered the IUCN habitat type grassland at that site. 

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
           overwrite = TRUE)
toc()  # 1.894  seconds

# calculate area after habitat filter
tic()
y3_area <- 
  terra::cellSize(y3, unit = "ha", mask = TRUE) %>% 
  global(fun = "sum", na.rm = TRUE)
toc()

plot(y3)
# ------------------------------------------------------------------------- #
### Elevation Filter ###
# ------------------------------------------------------------------------- #
elevation_map
elevation_map[[site_index]]

elevation_mask <- elevation_map[[site_index]] + y3
plot(elevation_mask)

y3_r <- raster(elevation_mask)

tic()
y3 <- 
  classify(y2,
           rcl = select(suitable_habitat_rcl, is = map_code) %>% mutate(becomes = 0),
           othersNA = TRUE,
           filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
           overwrite = TRUE)
toc()

elevation_mask
elevation_rcl <- elevation_prefs %>% filter(binomial == species_name)

e1 <- elevation_prefs[elevation_prefs$binomial==paste0(species_list[i,1]), ]

terra::app(y3, )
ele6_t <- elevation_mask
plot(ele6_t)



tic()
ele6_rcl <- classify(elevation_mask, 
                     rcl = tibble(from = el_rcl$elevation_lower,
                                  to = el_rcl$elevation_upper, 
                                  becomes = 0),
                     include.lowest = TRUE, right = TRUE)
toc() # sweet! much faster.

plot(ele6_rcl, colNA = "pink")

# mask the range polygon by the habitat mask and the elevation mask


print(i)
write.csv(aoh_df,"~/Dropbox/PostDoc4_Princeton/Species Traits/FutureAOH.csv")
}
```

```{r aoc-direct-testing}

# cc_AOH_terra <- function(index,
#                        site_index,
#                        year_index,
#                        calc_lc = TRUE) {
  # ------------------------------------------------------------------------- #
  ### starts here ###
  # ------------------------------------------------------------------------- #
  tic.clearlog()
  tic(paste0("run ", index, ":", site_df$site[site_index], ", ", year_index))
  aoh_test_mg
  aoh_test_s
  index <- 3
  site_index <- 9 # 6 = mato_grosso
  year_index <- 2010:2017
  calc_lc <- TRUE
  calc_AOO <- TRUE
  
  species_ranges <- vert_sites %>%
  filter(vert_class != "gard",
         site == site_df$site[site_index]) # filter to just the site in question
  
  species_list <- species_ranges %>% st_drop_geometry() %>%
    select(site, vert_class, binomial) %>% unique() %>%
    arrange(site, vert_class, binomial)

  species_name <- species_list$binomial[index]
  # species_name <- "Lithobates palustris"
  
  habitat_map <- if (calc_lc) {
    lc[[site_index]][[paste0("y", year_index)]]
  } else {
    rast(paste0(p_derived, "site_jung/", site_df$site[site_index], "_jung_l2_30.tif"))
  }
  
  elevation_map <- rast(paste0(p_derived, "elevation/", site_df$site[site_index], "_srtm_crop.tif"))
  
  # ---- extract species range polygons at the site ---- #
  range_sf <- st_cast(species_ranges[species_ranges$binomial == species_name, ]) # select a subset of species range polygons based on binomial, and update all features to multipolygon, for fasterize()
  plot(range_sf$geometry)
  
  # plot(lc[[site_index]][[year_index]])
  plot(habitat_map)
  plot(range_sf$geometry, border = "red", add = TRUE)

  # ---- turn the species range polygons (sf) into a raster ---- #
    
  range_t <- 
    fasterize(range_sf,
              raster::raster(resolution = terra::res(habitat_map),
                             ext = raster::extent(terra::ext(habitat_map)[1:4]))
              ) %>% 
    rast() %>% # convert to SpatRaster 
    subst(1, 0) # update cell values from 1 to 0.
  
  plot(range_t)
  # ------------------------------------------------------------------------- #
  ### Habitat Filter ###
  # ------------------------------------------------------------------------- #
  z1 <- habitat_prefs %>% 
    filter(binomial == species_name,
           suitability == "Suitable") # extract the habitat classifications for the species in question
  
  habitat_prefs %>% 
    filter(binomial == species_name) %>%
    arrange(suitability) %>% print(n = 25)
  
  habitat_details %>% filter(binomial == species_name) %>% .$habitat
  
  # extract the lc codes from my crosswalk that correspond to the IUCN habitat codes
  suitable_habitat_rcl <- iucn_crosswalk %>% 
    filter(code %in% unique(z1$code))
  
  freq(habitat_map)
  iucn_crosswalk %>% print(n = 42)
  plot(site_jung_l2$mato_grosso, breaks = c(105.9,106.1))
  plot(site_jung_l2_30$mato_grosso, breaks = c(105.9,106.1))
  plot(site_jung_l2_30$mato_grosso, breaks = c(506.9,507.1))
  plot(site_jung_l2$mato_grosso, breaks = c(405.9,406.1))
  freq(site_jung_l2_30$mato_grosso)
  
  # reclassify habitat raster to 
  habitat_map1 <- lc[[site_index]][["y2017"]]
  habitat_map <- lc[[8]]#[[paste0("y", 2010:2017)]]
  
  tic()
  habitat_map_rcl <- 
    classify(
      # habitat_map1,
      habitat_map,
      rcl = select(suitable_habitat_rcl, 
                   is = ifelse(calc_lc, "lc", "map_code")
                   ) %>% unique() %>% 
               mutate(becomes = 0),
             othersNA = TRUE,
             # filename = paste0(p_derived, "aoh/tmp/aoh_tmp.tif"),
             overwrite = TRUE)
  toc() # 5 seconds for 1, 8.178 s for 3, 11 s for 8, 28 seconds s for all 31
  
  31*5
  28
  plot(habitat_map_rcl[[1:4]])
  
  plot(habitat_map_rcl)
  # ------------------------------------------------------------------------- #
  ### Elevation Filter ###
  # ------------------------------------------------------------------------- #
  elevation_prefs_rcl <- elevation_prefs %>% filter(binomial == species_name)
  
  elevation_map_rcl <- 
    classify(
      elevation_map,
      rcl = tibble(from = elevation_prefs_rcl$elevation_lower,
                   to = elevation_prefs_rcl$elevation_upper,
                   becomes = 0),
      include.lowest = TRUE, right = TRUE)
  
  plot(elevation_map_rcl, colNA = "pink")
  
  # mask the range polygon by the habitat mask and the elevation mask
  plot(range_t)
  tic()
  aoh <- range_t + elevation_map_rcl
  aoh <- aoh + habitat_map_rcl
  toc() # 26 seconds for all 31, # 1.4 for 1 layer 
  

  # ------------------------------------------------------------------------- #
  ### Calculate areas:
  # ------------------------------------------------------------------------- #
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  if (calc_AOO) {
    range_aoo_ha <- 
    terra::cellSize(range_t, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>% .$sum
    }
  
  # Calculate the Area Of Occurrence (AOO), before filtering by habitat and elevation
  tic()
  range_aoh_ha <- 
    terra::cellSize(aoh, unit = "ha", mask = TRUE) %>% 
    global(fun = "sum", na.rm = TRUE) %>% .$sum
  toc() # 1.8 seconds for 1, 8 seconds for 5 layers, 40 s for all 31
  
  toc(log = T)
  
  aoh_tmp <- 
    tibble(site = site_df$site[site_index],
           binomial = species_name,
           year = year_index,
           # IUCN_aoo_ha = range_aoo_ha,
           IUCN_aoh_ha = range_aoh_ha)
  
  if (calc_AOO) {
    aoh_tmp <- aoh_tmp %>%
      mutate(IUCN_aoo_ha = range_aoo_ha)
  }
  
  if (include_time) {
    aoh_tmp <- aoh_tmp %>%
      mutate(time = 
               tic.log(format = F) %>% bind_rows() %>%
               mutate(time = toc - tic) %>% .$time)
  }
  
  # Note: the slight difference between areas before and after habitat filtering is
  # the result of a small amount of 0s added to the Yin et al. 2020 land cover maps. 
  
  cat("calculated AOH for", species_name, "=", range_aoh_ha, "ha", fill = TRUE)
  aoh_tmp

```

```{r aoh-function-testing}

# create an empty data.frame to store results from the for loop:
species_list[, "binomial"]

aoh_df <- tibble(site = site_df$site[site_index],
                 species = species_list[, "binomial"],
                 year = yr_index + 1986,
                 IUCN_aoo_ha = NA,
                 IUCN_aoh_ha = NA)


# things to load:
load(file = paste0(p_derived, "species_ranges/vert_sites.RData"), verbose = TRUE)

# for a specific site, compile list of species
species_list
aoh_df

4000 * 28 /60 / 60 / 11 # hours /11

# what if I do the lc maps in batches, do I save time? 



tic("test1")
toc(log=T)
tic("test2")
toc(log=T)

tic.clearlog()
tic.log(format = T) %>% unlist() 
tic.log(format = F) %>% bind_rows() %>%
  mutate(time = toc - tic) %>% .$time


aoh_test <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()

seq_along(species_list$binomial)

aoh_test2 <- lapply(1:2, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()

aoh_test_mg <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 6, year_index = 31, calc_lc = FALSE)
}) %>% bind_rows()


aoh_test_s2 <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2017, calc_lc = FALSE)
}) %>% bind_rows()

aoh_test_s[1:5,]
aoh_test_s2


aoh_test_lc_s <- lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2017, calc_lc = TRUE)
}) %>% bind_rows()
aoh_test_lc_s
aoh_tmp

vert_sites %>% filter(binomial == "Rana chensinensis", 
                      site == "shaanxi" ) %>% 
  st_geometry() %>% 
  plot(add = T, col = "red")

site_sf %>% filter(site == "shaanxi" ) %>% st_geometry() %>% plot()

aoh_test_s1

aoh_test_mg
habitat_details %>% filter(binomial == "Adenomera andreae") %>% .$habitat
habitat_prefs %>% filter(binomial == "Adenomera andreae") %>% .$habitat

synonyms 
species_synonyms %>% filter(binomial == "Adenomera andreae")

aoh_test4 <- 
  lapply(1:11, function(site_index) {
    tmp <- lapply(1, function(i) {
      cc_AOH_terra(index = i, site_index = site_index, year_index = 31, calc_lc = FALSE)
      }) %>% bind_rows()
  }) %>% bind_rows()
  

aoh_test_mult_s <- 
  lapply(3, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 2015:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()

aoh_test_mult_s %>% tail

aoh_test_mult_s




aoh_tmp
aoh_test_mult_s

aoh_test_s


aoh_test3
aoh_test4

# between 24-32 seconds

# run 1:wisconsin, 31: 29.43 sec elapsed
# calculated AOH for Acris crepitans = 630173.7 ha
# run 2:wisconsin, 31: 32.413 sec elapsed
# calculated AOH for Ambystoma laterale = 1962498 ha
# run 3:wisconsin, 31: 26.02 sec elapsed
# calculated AOH for Ambystoma maculatum = 1260343 ha
# run 4:wisconsin, 31: 24.47 sec elapsed
# calculated AOH for Ambystoma tigrinum = 905840.2 ha
# run 5:wisconsin, 31: 25.846 sec elapsed
# calculated AOH for Anaxyrus americanus = 2938938 ha
# > aoh_test

aoh_test
aoh_df[1:5,]

aoh_test4

write_csv(aoh_test,
          file = paste0(p_derived, "aoh/aoh_df.csv"))

```



```{r remove-0s-from-lc}

# this doesn't really matter! I'm just comparing the AOH anyways...

tic()
lc_clean <- subst(lc[[8]][[1:4]], from = 0, to = NA_real_)
toc()
# 63 seconds for just four layers of the biggest site. 

compareGeom(lc_clean, lc[[9]])

df1 <- freq(lc_clean)
df2 <- freq(lc[[9]][[1:4]])

df1 %>% as_tibble() %>% arrange(value)
df2 %>% as_tibble() %>% arrange(value)

lc_clean <- classify(
      lc[[9]][[1:4]],
      rcl = tibble(from = elevation_rcl$elevation_lower,
                   to = elevation_rcl$elevation_upper,
                   becomes = 0),
      include.lowest = TRUE, right = TRUE)

plot(lc[[9]][[1]], breaks = c(-0.1, 0.1), maxcell = 1e8)



terra::trim()

plot(lc_clean)

tic()
lc_clean2 <- trim(lc[[9]][[1:4]], value = 0)
toc()


df3 <- freq(lc_clean2)

df3 %>% as_tibble() %>% arrange(value)

```

# {data.table} AOH

```{r load-files-for-dt-AOH}
# set parameters:

index <- 3
site_df
site_index <- 3
year_index <- 2011:2017
calc_lc <- TRUE
include_time <- TRUE
range_maps <- species_ranges

# ------------------------------------------------------------------------- #
### load in required elements prior to running the data.table function
# ------------------------------------------------------------------------- # 
# all the loading of the habitat maps before:
tic("load layers")

  hab_dt <- fread(input = paste0(p_dat_derived, "input_data.tables/",
                                 site_df$site[site_index], ".csv"))

  elevation_map <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "elevation/", 
              site_df$site[i], "_srtm_crop.tif")
       )
  })
  
  site_area_ha <- lapply(
    list.files(paste0(p_derived, "site_area_ha"), full.names = TRUE), 
    function(i) rast(i)
    )

  el_area_dt <- spatraster_to_dt(
    spt = c(site_area_ha[[site_index]],
            elevation_map)#, xy_switch = FALSE
    )

  setnames(el_area_dt, 
           old = grep("area", names(el_area_dt), value = T), 
           new = "area_ha")
  
  stopifnot(
    all.equal(hab_dt$x, el_area_dt$x),
    all.equal(hab_dt$y, el_area_dt$y)
    )
  
  # combine hab_dt and el_area_dt into a single data.table
  hab_dt[, ':='(area_ha = el_area_dt$area_ha,
                elevation = el_area_dt$elevation)]
  
  rm(el_area_dt) # to save memory on my machine.

  toc() #


```



```{r compare-results-dt-AOH}
tic("terra method")
aoh_terra_test_mult_s <- 
  lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 9, year_index = 1987:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()
toc()

# tic()
# one_sp <- cc_AOH_terra(index = 3, site_index = 9, year_index = 2017, 
#              calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
# toc()

tic("data.table method")
aoh_dt_test_mult_s <- lapply(1:5, function(i) {
  cc_AOH_data.table(index = i, site_index = 9, year_index = 1987:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()

# times: 
# terra: 555.635 s
# data.table: 262.04
aoh_terra_test_mult_s$time %>% unique %>% sum /
  aoh_dt_test_mult_s$time %>% unique %>% sum
# 2.11 x faster to do it with data.table

# compare results
aoh_terra_test_mult_s
aoh_dt_test_mult_s %>% 
  select(site, binomial, year, IUCN_aoh_ha, time) %>% unique

# they match
identical(aoh_terra_test_mult_s$IUCN_aoh_ha, aoh_dt_test_mult_s %>% 
  select(site, binomial, year, IUCN_aoh_ha, time) %>% unique %>%
  .$IUCN_aoh_ha)


# 3 three heavy lifts: hab rcl, elevation rcl, and the final masking

# time comparison 124 for terra function vs. 159 for data.table method
# now, having switched the order of the data.table filtering, the data.table method takes closer to 50 seconds.
```

```{r adjust-by-lc-prop}

# what proportion of the area in each of my four land cover codes is in 
# so, if a species 
z1

adj_df <- jung_hab_type_area_df %>%
  filter(site == site_df$site[site_index],
         code %in% unique(z1$code)) %>%
  group_by(lc) %>%
  summarise(adjustment = sum(prop_lc))

jung_hab_type_area_df %>% select(-IUCNLevel) %>%
  filter(site == site_df$site[9])


aoh_dt_test_mult_s
aoh_dt_test_mult_s

aoh_dt_test_mult_s <- aoh_dt_test_mult_s %>% 
  as_tibble() %>% 
  left_join(adj_df, by = "lc") %>% 
  mutate(adj_area_ha = area_ha * adjustment)

aoh_dt_test_mult_s %>% 
  select(-IUCN_aoh_ha) %>%
  left_join(aoh_dt_test_mult_s %>% 
              group_by(site, binomial, year) %>%
              summarise(IUCN_aoh_ha = sum(area_ha),
                        adj_IUCN_aoh_ha = sum(adj_area_ha)),
            by = c("site", "binomial", "year")
  )

df_tmp

```

```{r test-wisc}
# testing with Wisconsin data.table
# FYI it takes about 45 seconds to load all the data required at the start.
hab_dt

# too memory intensive.

tic("terra method")
aoh_terra_test_mult_w <- 
  lapply(1:5, function(i) {
  cc_AOH_terra(index = i, site_index = 11, year_index = 1987:2017, 
             calc_lc = TRUE, calc_AOO = FALSE, include_time = TRUE)
}) %>% bind_rows()
toc()

tic("data.table method")
aoh_dt_test_mult_w <- lapply(1:5, function(i) {
  cc_AOH_data.table(index = i, site_index = 11, year_index = 1987:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()

aoh_dt_test_mult_w %>% select(site, binomial, time) %>% unique() %>%
  mutate(time_p_run = time/31)


```


## Melting data.tables

Can I gain speed by melting the data.table in order to get the area by year and land cover code in one single data.table call? 
Ultimately, no. 
This method seems to be slower by a factor of 1.3. 
Good to have learned how to melt data.tables, but table this method for now.

```{r melt-dt}
# in order to use the by function correctly, I need to melt the data.table from wide to long format, and have a column for year. 
hab_dt

# add a new index, drop x and y
hab_dt[, key := 1:nrow(.SD)]
hab_dt[, c("x", "y", paste0("y", 1987:2000)) := NULL]

tdt <- hab_dt[1:200, .(key, y2001, y2002, y2003)]

tdt

# reshape

melt_dt <- melt(tdt, id.vars = c("key"), measure.vars = paste0("y", 2001:2003))

obj_size(tdt)
obj_size(melt_dt)


# test with big one:
hab_dt

tic()
hab_dt_melt <- data.table::melt(hab_dt, id.vars = c("key"), measure.vars = paste0("y", 2001:2017))
toc()

obj_size(hab_dt)
obj_size(hab_dt_melt) # three times as big.

# how would I summarize now?
hab_dt_melt


hab_dt

# first, filter by range, elevation, etc.:
hab_dt

hab_filtered_range_el

obj_size(hab_filtered_range_el)

# --------------------- #
# add a key
rm(hab_dt)
hab_filtered_range_el[, key := 1:nrow(.SD)]

# adding a key added this much space:
(3702098608 - 3792393688) / 10^6 # 90 MB!
(3792393688 - 3070033520) / 10^6 # deleting X, Y, elevation, and range saves 722 MB 
obj_size(hab_filtered_range_el) / 10^9 # 3.792 GB

hab_filtered_range_el[, c("x", "y") := NULL]
obj_size(hab_filtered_range_el) # 3.431 GB


hab_filtered_range_el[, c("elevation", "range") := NULL]
obj_size(hab_filtered_range_el) # 3.070 GB


# subset:
obj_size(hab_filtered_range_el)

names(hab_filtered_range_el)
hab_filtered_range_el[, c(paste0("y", 1987:2010)) := NULL]


obj_size(hab_filtered_range_el)

tic()
hab_dt_melt <- data.table::melt(hab_filtered_range_el, 
                                id.vars = c("key", "area_ha"), 
                                measure.vars = paste0("y", 2011:2017))

hab_dt_melt[value %in% habitat_prefs_rcl, 
            sum(area_ha), 
            by = c("variable", "value")]

toc()


tic()
aoh_dt_test_melt_comp_s <- lapply(3, function(i) {
  cc_AOH_data.table(index = i, site_index = 9, year_index = 2011:2017, 
             calc_lc = TRUE, include_time = TRUE)
}) %>% bind_rows()
toc()
aoh_dt_test_melt_comp_s

# 
#     variable value       V1
#  1:    y2011     1 147962.5
#  2:    y2011     2 123306.9
#  3:    y2012     1 150692.8
#  4:    y2012     2 135720.2
#  5:    y2013     1 156040.7
#  6:    y2013     2 135630.5
#  7:    y2014     1 154844.5
#  8:    y2014     2 132604.9
#  9:    y2015     1 156117.8
# 10:    y2015     2 140025.3
# 11:    y2016     1 155746.2
# 12:    y2016     2 145278.5
# 13:    y2017     1 154090.6
# 14:    y2017     2 151717.8

```

```{r time-melt}
hab_dt

# having loaded hab_dt before
tic("full melt time")
species_ranges <- vert_sites %>%
  filter(vert_class != "gard",
         site == site_df$site[site_index]) # filter to just the site in question

species_list <- species_ranges %>% st_drop_geometry() %>%
  select(site, vert_class, binomial) %>% unique() %>%
  arrange(site, vert_class, binomial)

species_name <- species_list$binomial[index]
# species_name <- "Lithobates palustris"
cat("Species name:", species_name, fill = TRUE)

# ---- extract species range polygons at the site ---- #
# select a subset of species range polygons based on binomial, and 
# update all features to multipolygon, for fasterize()
range_sf <- st_cast(species_ranges[species_ranges$binomial == species_name, ]) 

# ---- turn the species range polygons (sf) into a raster ---- #
range_t <- 
  fasterize(range_sf,
            raster::raster(resolution = terra::res(elevation_map),
                           ext = raster::extent(terra::ext(elevation_map)[1:4]))
  ) %>% 
  rast() #%>% # convert to SpatRaster 
# subst(1, 0,
#       filename = paste0(tmp_location, "range_t_tmp.tif"),
#       overwrite = T) # update cell values from 1 to 0.

# plot(range_t)

range_dt <- spatraster_to_dt(spt = range_t)

# a quick test to make sure the x and y columns match, to circumvent the need
# to round x and y to get the data.table::merge() to work correctly.
stopifnot(
  all.equal(hab_dt$x, range_dt$x),
  all.equal(hab_dt$y, range_dt$y)
)

# add range to the data.table as a column
hab_dt[, range := range_dt$layer]

# ------------------------------------------------------------------------- #
### Habitat Filter ###
# ------------------------------------------------------------------------- #
z1 <- habitat_prefs %>% 
  filter(binomial == species_name,
         suitability == "Suitable") # extract the habitat classifications for the species in question

# extract the lc codes from my crosswalk that correspond to the IUCN habitat codes
habitat_prefs_rcl <- 
  iucn_crosswalk %>% 
  filter(code %in% unique(z1$code)) %>%
  select(codes = ifelse(calc_lc, "lc", "map_code")) %>% # select lc class codes, or IUCN habitat map codes, depending on the "calc_lc" switch
  unique() %>% .$codes

# ------------------------------------------------------------------------- #
### Elevation Filter ###
# ------------------------------------------------------------------------- #
elevation_prefs_rcl <- elevation_prefs %>% filter(binomial == species_name)

# ------------------------------------------------------------------------- #
### Calculate AOH, broken down by habitat type ###
# ------------------------------------------------------------------------- #

# subset data.table to only pixels within both species range and elevation range, first:
hab_filtered_range_el <- hab_dt[!is.na(range) &
                                  elevation <= elevation_prefs_rcl$elevation_upper &
                                  elevation >= elevation_prefs_rcl$elevation_lower]



# begin melt chunk:
rm(hab_dt)
hab_filtered_range_el[, key := 1:nrow(.SD)]
hab_filtered_range_el[, c("x", "y", "elevation", "range",
                          paste0("y", 1987:2010)) := NULL]

hab_dt_melt <- data.table::melt(hab_filtered_range_el, 
                                id.vars = c("key", "area_ha"), 
                                measure.vars = paste0("y", 2011:2017))

hab_dt_melt[value %in% habitat_prefs_rcl, 
            sum(area_ha), 
            by = c("variable", "value")]

toc() # 22.604 seconds for just 7 layers, which is less than the original data.table code, which runs through each column individually. Just stick with that code.
```




# Cluster results
```{r 11-test}
aoh_dt_11_test <- read_csv(paste0(p_derived, "aoh/aoh_dt_11_test.csv"))

species_list %>% 
  group_by(site)
```


```{r missing-sp}

# how many did it actually run?
aoh_dt_11_test %>% 
  group_by(site) %>% 
  summarise(n = length(unique(binomial)))

runs_actual <- aoh_dt_11_test %>% 
  select(site, binomial) %>%
  unique()

# what happened to Rana temporaria
runs <- lapply(1:11, function(i) {
  species_list %>%
    filter(site == site_df$site[i]) %>%
    head(n = 10) %>%
    mutate(index = 1:10)}) %>% bind_rows()

runs %>% print(n = 100)
runs %>% select(site, binomial)
runs_actual

missing_sp <- runs %>% 
  filter(!binomial %in% unique(runs_actual$binomial))

aoh_dt_11_test %>% 
  filter(binomial %in% missing_sp$binomial)

species_ranges %>%
  filter(binomial %in% missing_sp$binomial) %>% .[1,] %>%
  st_geometry() %>%
  plot()

aoh_dt_11_test %>% 
  select(site, binomial) %>% 
  group_by(site) %>%
  unique() %>% 
  print(n = 120)

list.files(paste0(p_derived, "aoh/"))

missing_sp
species_list %>% filter(site == site_df$site[site_index]) %>% head(n = 10)

# -------------------------------------- run function ---------------------------------- #
aoh_test_c <- lapply(1:3, function(i) {
  cc_AOH_data.table(index = i, site_index = site_index, year_index = 2011:2017, 
             calc_lc = TRUE, include_time = TRUE,
             hab_dt = hab_dt,
             range_maps = vert_sites)
}) %>% bind_rows()

aoh_test_c %>% filter(binomial == sp_name)
plot(lc[[site_index]][[31]])
plot(range_sf$geometry, add = T, border = "red")
plot(range_t, add = T)
plot(range_t)



# it's due to a mismatch in species names
non_match
missing_sp

non_match %>% arrange(site, binomial) %>% print(n = 100)

species_synonyms %>%
  filter(binomial == sp_name)

species_synonyms %>%
  filter(synonym == "Babina daunchina")


non_match %>%
  filter(binomial == "Bufotes variabilis")



missing_sp
#  site      vert_class binomial                 index
#   <chr>     <chr>      <chr>                    <int>
# 1 belarus   amp        Rana temporaria              9   # due to elevation data entry error
# 2 chongqing amp        Babina daunchina             3   # due to synonym issue
# 3 iraq      bird       Acrocephalus melanopogon     3   # no suitable habitat within the site
# 4 orenburg  amp        Bufotes variabilis           3   # suitability is unknown - removed due to this.
# 5 orenburg  amp        Rana temporaria              8   # due to elevation data entry error


missing_sp$binomial

habitat_prefs %>%
  filter(binomial %in% missing_sp$binomial) %>%
  print(n = 100)

```



```{r why-NA?}
# some values are NA... what causes this?
# this stems from cases where there is no 
aoh_dt_11_test %>% 
  filter(is.na(adj_IUCN_aoh_ha))

# why is the adjustment NA??
sp_name <- "Bufo bufo"
site_index <- 1

aoh_dt_11_test %>%
  filter(site == site_df$site[site_index], binomial == sp_name)


habitat_prefs %>%
  filter(binomial == sp_name) %>%
  arrange(code)

z1 %>% arrange(code) %>% print(n = 30)
# test_codes <- 
  z1 %>%
  left_join(iucn_crosswalk, by = "code") %>%
  select(binomial, code, map_code, lc, name, IUCNLevel) #%>%
  # print(n = 110) %>%
  # .$lc %>% unique

# based on the habitat_prefs, this species finds 1, 2, 3, and 4 suitable.
# but, there are no 14.4 habitat type at the site.. so when I join to adj_df, it gives an NA
aoh_dt_11_test %>%
  filter(site == site_df$site[site_index], binomial == sp_name) %>%
  select(site:area_ha) %>%
  
  

z1$code %>% sort() %>% length
unique(z1$code) %>% length

habitat_prefs_rcl

jung_hab_type_area_df %>%
  filter(site == site_df$site[site_index],
         #code %in% unique(z1$code)
         ) %>%
  arrange(habitat_type)


freq(site_jung_l2_30$belarus)

# the iucn crosswalk includes just those IUCN habitat types that Jung's map includes at my sites.
# based on the way that my adjustment works, I adjust the area of each of the four land cover types based on the proportion of the broader category at each site that is made up of that particular habitat type.


iucn_crosswalk <- read_csv(paste0(p_derived, "iucn_lc_crosswalk.csv"))
print(iucn_crosswalk, n = 100)
jung_hab_type_area_df %>% filter(site == site_df$site[site_index])
z1 %>% arrange(code) %>% print(n = 100)


# fix the NAs in the summarise function
aoh_dt_11_test <- aoh_dt_11_test %>%
  # filter(site == site_df$site[site_index], binomial == sp_name) %>%
  group_by(site, binomial, year) %>% 
  summarise(IUCN_aoh_ha = sum(area_ha),
            adj_IUCN_aoh_ha = sum(adj_area_ha, na.rm = TRUE)) #%>%
  # filter(is.na(adj_IUCN_aoh_ha))
```


```{r plot-aoh-test}
ggplot(data = aoh_dt_11_test #%>% filter(site == "shaanxi")
       ,
                     mapping = aes(x = year, y = adj_IUCN_aoh_ha, color = binomial)) + 
  geom_line() +
  facet_wrap(vars(site), scales = "free")

```


## Della results for all 31 layers
```{r load-31-layer-results}
run_time <- "_2021_12_05"
aoh_lc_31_files <- list.files(paste0(p_derived, "aoh"), full.names = T) %>% 
  grep(paste0("aoh_tmp", run_time), ., value = T)

aoh_31_df <- lapply(aoh_lc_31_files, read_csv) %>% bind_rows()

aoh_31_df

aoh_31_df %>%
  filter(binomial == "Chlidonias hybrida",
         site == "shaanxi")

aoh_31_df %>%
  filter(binomial == "Agamia agami") %>%
  ggplot(mapping = aes(x = year, y = adj_IUCN_aoh_ha)) +
  geom_line()



s_sp <- aoh_31_df %>% 
  filter(site == site_df$site[9],
         # binomial == "Tscherskia triton",
         year == 2017) %>%
  select(site:year, adj_IUCN_aoh_ha) %>% unique() %>%
  .$binomial

species_to_remove
i<-9

missing_sp_31 <- lapply(1:11, function(i){
  sp_run <- aoh_31_df %>% 
    filter(site == site_df$site[i]) %>%
  select(site:year, adj_IUCN_aoh_ha) %>% unique() %>%
  select(site, binomial) %>% unique()
  
  sp_not_run <- species_list %>% filter(site == site_df$site[i]) %>%
    filter(!binomial %in% sp_run$binomial)
  sp_not_run
}) %>% bind_rows()


# number of species at each site:
species_list %>% 
  group_by(site, #vert_class
           ) %>% 
  summarise(num_sp = n())

#######
species_list
species_to_remove

aoh_31_df %>% filter(binomial == "Chlidonias hybrida",
                     site == site_df$site[9])

# e_tmp1 <- 
  aoh_31_df %>% 
  filter(adj_IUCN_aoh_ha == 0) %>%
  arrange(site, binomial, year, lc) %>% 
  select(site, binomial) %>% unique() %>%
  filter(site == site_df$site[3])
  
species_to_remove %>% filter(site == site_df$site[3]) %>% arrange(binomial)
missing_sp_31 %>% filter(site == site_df$site[3]) %>% arrange(binomial)

jung_hab_type_area_df %>% filter(site == site_df$site[1]) %>% arrange(code)
habitat_prefs %>% filter(binomial == "Anthus pratensis",
                         suitability == "Suitable") %>% arrange(code)
elevation_prefs %>% filter(binomial == "Anthus pratensis")
  
species_to_remove[[1]]


species_list %>% filter(site == site_df$site[9]) %>% .$binomial #%>% unique()

missing_sp_tmp <- species_list %>% 
  filter(site == site_df$site[9]) %>% #.$binomial %>%
  filter(!binomial %in% s_sp) %>% .$binomial %>% sort()

# all of these species are present in the habitat_prefs file and have suitable habitat
habitat_prefs %>%
  filter(binomial %in% missing_sp_tmp) %>% #.$binomial %>% unique() %>% sort() #%>% length()
  print(n = 50)

missing_sp_tmp

species_ranges %>%
  filter(binomial == missing_sp_tmp[5]) %>%
  st_geometry() %>%
  plot()

species_list %>% filter(site == site_df$site[9]) %>% print(n = 210)


plot(lc$shaanxi[[31]])

species_ranges %>%
  filter(site == site_df$site[9],
         binomial == missing_sp_tmp[1]) %>%
  st_geometry() %>%
  plot(add = T)

#
site_elevation_range[9,]

for(i in missing_sp_tmp) {
elevation_prefs %>% filter(binomial == i) %>% print()
habitat_prefs %>% filter(binomial == i) %>% print()
}

jung_hab_type_area_df %>% filter(site == site_df$site[9]) %>% arrange(habitat_type)
```

```{r expl-seff}
txt <- read_csv("scripts/cluster/seff_out.csv")
txt

seff <- tibble(core_index = 1:27,
               time = str_subset(txt$out, "CPU Utilized"), 
               mem = str_subset(txt$out, "Memory Utilized")
               ) %>%
  mutate(time = str_extract(time, "[0-9][0-9]:[0-9][0-9]:[0-9][0-9]"),
         mem = str_extract(mem, "[0-9][0-9].[0-9][0-9]") %>% as.numeric())

seff %>% print(n = 30)

calc_cores

```





# Age of habitat

## IUCN assessment data
```{r prep-habitat-details}
habitat_prefs %>%
  filter(suitability == "Suitable") %>%
  select(binomial) %>% unique()

species_list$binomial %>% unique %>% length

# -----------
# extract a list of all suitable habitats for each species
# -----------
suitable_habitats_extract <- 
  habitat_prefs %>%
  filter(suitability == "Suitable") %>%
  mutate(combined = paste(code, name)) %>%
  arrange(binomial, code) %>% 
  select(binomial:name, combined) %>%
  unique() %>%
  group_by(binomial) %>%
  summarise(suitable_codes = str_c(code, collapse = "; "),
            suitable_habitats = str_c(combined, collapse = "; "))

# -----------
# extract a list of all habitats of Major Importance each species
# -----------
majorImportance_extract <- 
  habitat_prefs %>%
  filter(suitability == "Suitable",
         majorImportance == "Yes") %>%
  mutate(combined = paste(code, name)) %>%
  arrange(binomial, code) %>% 
  select(binomial:name, combined) %>%
  unique() %>%
  group_by(binomial) %>%
  summarise(major_codes = str_c(code, collapse = "; "),
            major_habitats = str_c(combined, collapse = "; "))


# -----------
# make a data.frame of each species with their habitat_description
# -----------

habitat_age_req <-
  species_list %>% # first add the species binomial, class, and site presence
  group_by(binomial, vert_class) %>%
  summarise(site_presence = str_c(site, collapse = "; ")) %>% 
  ungroup() %>%
  
  # then add the common names:
  left_join(common_names %>% group_by(binomial) %>%
              summarise(common_names = str_c(common_name, collapse = "; ")),
            by = "binomial") %>%
  
  # now, add the habitat codes and names for both suitable habitats and major importance habitats
  left_join(suitable_habitats_extract, by = "binomial") %>%
  left_join(majorImportance_extract, by = "binomial") %>% 

  left_join(select(habitat_details, binomial, redlistCategory, habitat), by = "binomial")

# those species without specific habitat descriptions can be treated in two ways:
# 1. conservatively - habitats are not suitable
# 2. all habitats that are said to be suitable can be assumed to be suitable at any age 

# clean up the html tags

text_to_remove <- c('<strong>', '</strong>', '<em>', '</em>', '<p>', '</p>', 
                    '<span style=\"font-weight: bold;\">', 
                    '<span style=\"font-style: italic;\">', 
                    '</span>', 
                    '<B>', '</B>', 
                    '<a name=\"OLE_LINK4\">',
                    '<span lang=\"EN-US\">', 
                    '<span lang=\"en-US\">',
                    '<span lang=\"en\">', 
                    '<span lang=\"EN-GB\">',
                    '<br>', '<br/>', 
                    '<sup>', '</sup>',
                    '<span class=\"quotename\">',
                    '<span class=\"msoIns\">', 
                    '<span style=\"font-style: italic; \">', 
                    '<span class=\"hps\">')

habitat_age_req <- 
  habitat_age_req %>%
  mutate(habitat = gsub(paste(text_to_remove, collapse = "|"), "", habitat),
         
         # remove white space:
         habitat = str_squish(habitat), 
         habitat = str_trim(habitat)
         )


# lots of species do not have specific habitat descriptions - arrange by this
habitat_age_req <- 
  habitat_age_req %>%
  mutate(has_desc = ifelse(is.na(habitat), 1, 0))


# add columns for classification, reorder columns, and arrange
habitat_age_req <- 
  habitat_age_req %>%
  mutate(age_req = NA,
         specialty = NA) %>%
  arrange(#has_desc, 
          vert_class, binomial) %>% 
  select(vert_class, binomial, common_names, 
         suitable_habitats, habitat, age_req, specialty, 
         site_presence,
         everything())

habitat_age_req

# -----------
# write to file
# -----------


write_csv(habitat_age_req, file = paste0(p_derived, "iucn_habitat_age_req.csv"))

```

```{r separating-habitat-specialties}
habitat_prefs %>%
  filter(suitability == "Suitable",
         majorImportance == "Yes") %>%
  .$binomial %>% 
  unique %>%
  length

# see _util_files.R
site_habitats %>% print(n = 34)


# forests exclusively (and majorImportance)

# grasslands exclusively

# testing

site_habitats$IUCNLevel %>% str_subset(regex("forest|plantations", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("grassland|savanna|shrubland|pasture", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("wet", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("arable|pasture|garden", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("urban", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("rocky", ignore_case = TRUE))
site_habitats$IUCNLevel %>% str_subset(regex("desert", ignore_case = TRUE))


# ------------------------- species habitat specialty --------------------------- # 
habitat_age_req <- habitat_age_req %>%
  mutate(forest_occ =     str_detect(suitable_habitats, regex("forest|plantations", ignore_case = TRUE)),
         grass_occ =      str_detect(suitable_habitats, regex("grassland|savanna|shrubland|pasture", ignore_case = TRUE)),
         wetlands_occ =   str_detect(suitable_habitats, regex("wet", ignore_case = TRUE)),
         farmland_occ =   str_detect(suitable_habitats, regex("arable|pasture|garden", ignore_case = TRUE)),
         urban_occ =      str_detect(suitable_habitats, regex("urban", ignore_case = TRUE)),
         rocky_occ =      str_detect(suitable_habitats, regex("rocky", ignore_case = TRUE)),
         desert_occ =     str_detect(suitable_habitats, regex("desert", ignore_case = TRUE)),
         
         # specialty_full = ifelse(forest_occ, ifelse(grass_occ, "both", "forest"), "grass"),
         # comp = ifelse(forest_occ & !grass_occ & !wetlands_occ & !urban_occ & !rocky_occ & !desert_occ, "forest", "no"),
         # sp_sums = rowSums(across(forest_occ:desert_occ)),
         n_spec = rowSums(across(contains("occ"))),
         specialty = case_when(
           n_spec == 1 & forest_occ ~ "forest",
           n_spec == 1 & grass_occ ~ "grass",
           n_spec == 1 & wetlands_occ ~ "wetlands",
           n_spec == 1 & farmland_occ ~ "farmland",
           n_spec == 1 & urban_occ ~ "urban",
           n_spec == 1 & rocky_occ ~ "rocky",
           n_spec == 1 & desert_occ ~ "desert",
           n_spec == 2 & forest_occ & grass_occ ~ "for_grass",
           n_spec >= 5 ~ "generalist",
           TRUE ~ "NA"),
         # stuff = paste(contains(occ))
         ) #%>%
  # select(binomial, forest_occ:n_spec, specialty) %>%
  # filter(n_specialty >= 0) %>%
  # arrange(desc(n_spec)) %>% print(n = 50)


str_detect(habitat_age_req$suitable_habitats[1:10], regex("forest", ignore_case = TRUE) | regex("wetlands", ignore_case = TRUE))



# how many species only use cropland or some sort of farmland?
habitat_age_req %>% filter(farmland_occ, n_spec == 1) %>% nrow() # 0!


names(habitat_age_req)

habitat_age_req %>%
  filter(#vert_class != "amp",
         farmland_occ,
         # n_spec == 1
         ) %>%
  select(vert_class:common_names, redlistCategory, n_spec, suitable_codes, contains("occ")) %>%
  arrange(n_spec, desc(grass_occ), desc(wetlands_occ)) # %>% View() 
  
  
```


```{r majorimportance}


habitat_age_req %>%
  mutate(forest_mi =     str_detect(suitable_habitats, regex("forest|plantations", ignore_case = TRUE)),
         grass_occ =      str_detect(suitable_habitats, regex("grassland|savanna|shrubland|pasture", ignore_case = TRUE)),
         wetlands_occ =   str_detect(suitable_habitats, regex("wet", ignore_case = TRUE)),
         farmland_occ =   str_detect(suitable_habitats, regex("arable|pasture|garden", ignore_case = TRUE)),
         urban_occ =      str_detect(suitable_habitats, regex("urban", ignore_case = TRUE)),
         rocky_occ =      str_detect(suitable_habitats, regex("rocky", ignore_case = TRUE)),
         desert_occ =     str_detect(suitable_habitats, regex("desert", ignore_case = TRUE)),
         
         # specialty_full = ifelse(forest_occ, ifelse(grass_occ, "both", "forest"), "grass"),
         # comp = ifelse(forest_occ & !grass_occ & !wetlands_occ & !urban_occ & !rocky_occ & !desert_occ, "forest", "no"),
         # sp_sums = rowSums(across(forest_occ:desert_occ)),
         n_spec = rowSums(across(contains("occ"))),
         specialty = case_when(
           n_spec == 1 & forest_occ ~ "forest",
           n_spec == 1 & grass_occ ~ "grass",
           n_spec == 1 & wetlands_occ ~ "wetlands",
           n_spec == 1 & farmland_occ ~ "farmland",
           n_spec == 1 & urban_occ ~ "urban",
           n_spec == 1 & rocky_occ ~ "rocky",
           n_spec == 1 & desert_occ ~ "desert",
           n_spec == 2 & forest_occ & grass_occ ~ "for_grass",
           n_spec == 7 ~ "generalist",
           TRUE ~ "NA"),
         # stuff = paste(contains(occ))
         )

```



```{r na}
habitat_age_req$binomial %>% unique %>% length()
habitat_age_req %>%
  filter(!is.na(hab_clean)) %>% unique %>% nrow()

# about 1000 of them have no specific habitat description

habitat_age_req %>% 
  filter(str_detect(suitable_habitats, "[Tt]emperate")) # can also use: filter(grepl("Acris", binomial))

habitat_age_req %>% 
  filter(str_detect(suitable_habitats, "[Tt]emperate")) # can also use: filter(grepl("Acris", binomial))

jung_hab_type_area_df %>%
  select(habitat_type, lc, IUCNLevel, Coarse_Name) %>% unique %>% arrange(habitat_type) %>% print(n = 35)

```



```{r match-text}
species_ranges %>%
  filter(binomial == "Agamia agami") %>%
  st_geometry() %>%
  plot()

plot(site_jung_l2$mato_grosso)

plot(lc$mato_grosso$y2017)

habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(str_detect(hab_clean, "mature|primary|old")) # can also use: filter(grepl("Acris", binomial))

habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(str_detect(suitable_habitats, "forest")) # can also use: filter(grepl("Acris", binomial))

# --------------------------------------- #
# separate species by habitat type
habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(grepl("forest", suitable_habitats, ignore.case = T))



# --------------------------------------- #
# separate species by habitat age preference
habitat_age_req$binomial %>% unique() %>% length

habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(grepl("mature|primary|old", hab_clean, ignore.case = T))

habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(grepl("succession", hab_clean, ignore.case = T))

habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(grepl("old", hab_clean, ignore.case = T))


habitat_age_req %>%
  select(binomial, vert_class, suitable_habitats, hab_clean) %>%
  filter(str_detect(hab_clean, "old")) # can also use: filter(grepl("Acris", binomial))


habitat_age_req %>%
  select(binomial, vert_class, hab_clean) %>%
  mutate(old_sp = ifelse(str_detect(hab_clean, "mature|primary"), 1, 0))
  
t1 <- habitat_age_req %>%
  select(binomial, vert_class, hab_clean) %>%
  filter(str_detect(hab_clean, "mature")) %>% # can also use: filter(grepl("Acris", binomial))
  mutate(hab_clean = str_trim(unlist(hab_clean))) %>%
  head()

t1[2, 3] %>% unlist

t1[2, 3] %>% unlist %>% str_trim()
t1[2, 3] %>% unlist %>% str_squish()
# when finding a record to update:
  

```


# AOH of only Abandoned croplands

```{r species-list-just-2-4}
species_list
  
habitat_prefs %>% 
  filter(suitability != "Suitable")

habitat_prefs %>% .$binomial %>% unique() %>% length() # 2229

# 2017 species of the 2229 species_range layer with 2 or 4
habitat_prefs %>% 
  filter(suitability == "Suitable",
         lc %in% c(2, 4)) %>% 
  .$binomial %>% unique() %>% length() 


# 1122 species have 2 or 4 listed as a habitat of majorImportance
habitat_prefs %>% 
  filter(suitability == "Suitable",
         majorImportance == "Yes",
         lc %in% c(2, 4)) %>% 
  .$binomial %>% unique() %>% length() 




species_list %>% .$binomial %>% unique() %>% length() # 2104 total species in species list

species_list %>%
  filter(binomial %in% (habitat_prefs %>% 
                          filter(suitability == "Suitable",
                                 lc %in% c(2, 4)) %>% 
                          .$binomial %>% unique())
         ) %>% 
  .$binomial %>% unique() %>% length() # 1938 species have grassland (2) or forest (4) listed as suitable habitats




habitat_prefs$code %>% unique() %>% sort()
site_habitats %>% print(n = 40)

iucn_crosswalk %>% filter(code == 5.1)

# having added map_code to habitat_prefs for more exact filtering and joining...
habitat_prefs
site_habitats
iucn_crosswalk



site_habitats
jung_hab_type_area_df %>% select(habitat_type, code, lc, Coarse_Name, IUCNLevel) %>% unique() %>%
  arrange(habitat_type)


```


## lc of abandonment 

```{r age-abn-mask}
# mask the lc map by the age map
plot(age_t[[site_index]][[31]])

tic()
abn_mask <- lapply(1:11, function(i) {
  abn_mask_tmp <- 
    classify(
      age_t[[i]],
      rcl = tibble(from = 5,
                   to = 30,
                   becomes = 0),
      othersNA = TRUE,
      include.lowest = TRUE, right = TRUE,
      filename = paste0("/Users/christophercrawford/work/projects/abandonment_trajectories/data_derived/age_rasters/abn_mask/",
                        site_df$site[i], "_abn_5_30_mask.tif"),
      names = paste0("y", 1987:2017),
      overwrite = TRUE)
})
toc()

abn_mask <- lapply(1:11, function(i){
  rast(paste0("/Users/christophercrawford/work/projects/abandonment_trajectories/data_derived/age_rasters/abn_mask/", site_df$site[i], "_abn_5_30_mask.tif"))
})

names(abn_mask) <- site_df$site


plot(abn_mask$shaanxi[[31]])
plot(lc[[site_index]][[28:31]])
```

```{r lcc-extent}
lcc
site_df$site[7]

plot(abn_mask[[9]][[31]])




for(i in 1:11) {
  cat(site_df$site[i], fill = T)
  print(compareGeom(abn_mask[[i]], lcc[[i]]))
  }

i <- 3
plot(abn_mask[[i]])
plot(lc[[i]][[31]])
plot(lcc[[i]][[31]])

for(i in 1:11) {
  cat(site_df$site[i], fill = T)
  # print(compareGeom(abn_mask[[i]], age_t[[i]]))
  print(ext(abn_mask[[i]]))
  print(ext(lcc[[i]]))
  print(ncell(abn_mask[[i]]))
  print(ncell(lcc[[i]]))
  }

freq(abn_mask[[9]][[31]])

freq(lc[[9]][["y2006"]])
freq(lcc[[9]][["y2006"]])

freq(lc[[7]][["y2006"]])
freq(lcc[[7]][["y2006"]])

ncell(lc[[7]][["y2006"]]) - ncell(lcc[[7]][["y2006"]])

compareGeom(lc[[9]][["y2006"]], lcc[[9]][["y2006"]])

fread()

lcc[[9]]

lcct <- rast("/Users/christophercrawford/Downloads/shaanxi_clean.tif")
lcct 
names(lcct) <- paste0("y", 1987:2017)

plot(lcc[[9]][["y2000"]] - lcct[["y2000"]])
plot(lc[[9]][["y2000"]] - lcc[[9]][["y2000"]])
```


```{r lc-of-abn-terra}
# write code to calculate the land cover in each pixel 5 years and older
i <- 9
print(compareGeom(abn_mask[[i]], age_t[[i]]))
print(compareGeom(abn_mask[[i]], lcc[[i]]))

# Calculate the land cover of abandoned pixels for each year

# redoing this with the cleaned version of lc: lcc
tic()
abn_lcc <- lapply(1:11, function(i) {
  # make sure to restrict lc to only 1987:2017 (Nebraska, Wisconsin)
  # i <- 9
  cat("Masking:", site_df$site[i], "...", fill = TRUE)
  tmp <- abn_mask[[i]] + lcc[[i]][[paste0("y", 1987:2017)]]
  
  cat("Writing SpatRaster to file:", site_df$site[i], "...", fill = TRUE)
  writeRaster(tmp, 
              filename = paste0(p_derived, "abn_lcc/",
                        site_df$site[i], "_abn_lcc.tif"), 
              overwrite = TRUE,
              names = names(tmp))
  cat(site_df$site[i], "done!", fill = TRUE)

})
toc()


# reload
abn_lcc <- lapply(1:11, function(i) {
  rast(paste0(p_derived, "abn_lcc/",
              site_df$site[i], "_abn_lcc.tif"))
  })
names(abn_lcc) <- site_df$site


plot(abn_lcc[[31]])


# check into whether this is the same as abn_lc_rasters as created in "5_biodiversity_dev.Rmd"

tmp_df <- freq(tmp) # some pixels are in cropland... these must have  because these must have 
tmp_df %>% as_tibble() %>% arrange(value) %>% print(n = 100)

raster()

plot(age_t_bins[[site_index]])
test_lc <- terra::mask(x = lc[[site_index]][[31]],
                       mask = age_t_bins[[site_index]],
                       maskvalues = c(1:5), 
                       updatevalue = NA,
                       inverse = TRUE
                       )
plot(test_lc)

plot(lc[[site_index]][[31]])

```

```{r freq-abn-lc}

plot(abn_lc$shaanxi[[1:6]])
abn_lc
tmp <- freq(abn_lc$shaanxi)
i <- 9

nlyr(abn_lc[[i]])
abn_lc[[]]

abn_lc_freq <- lapply(1:11, function(i) {
  # the first five years (1987:1991) are NA, due to abandonment definition.
  tmp <- freq(abn_lc[[i]][[paste0("y", 1992:2017)]]) %>% 
    as_tibble() %>%
    rename(year = layer, lc = value) %>%
    mutate(year = year + 1991,
           site = site_df$site[i]) %>%
    select(site, year, lc, count)
  
  tmp
}
) %>% bind_rows


abn_lcc_freq <- lapply(9, function(i) {
  # the first five years (1987:1991) are NA, due to abandonment definition.
  tmp <- freq(abn_lcc[[paste0("y", 1992:2017)]]) %>% 
    as_tibble() %>%
    rename(year = layer, lc = value) %>%
    mutate(year = year + 1991,
           site = site_df$site[i]) %>%
    select(site, year, lc, count)
  
  tmp
}
) %>% bind_rows

# write to file
write_csv(abn_lc_freq, file = paste0(p_derived, "abn_lc_freq.csv"))

abn_lc_freq

# convert to percentages and plot

abn_lc_freq %>% 
  group_by(site, year) %>%
  summarise(site, year, lc, count,
            total = sum(count)) %>%
  ungroup() %>% 
  mutate(px = count/total * 100) %>%
  # filter(lc == 3) %>%
  ggplot(mapping = aes(x = year, y = px, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Percent of all abandoned pixels", col = "Land cover class") +
  facet_wrap(vars(site), scales = "free") + theme(legend.position = "bottom")




ggplot(data = abn_lcc_freq, 
       mapping = aes(x = year, y = area_ha, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Area (ha)", col = "Land cover class") +
  # facet_wrap(vars(site), scales = "free") + 
  theme(legend.position = "bottom")

ggplot(data = abn_lcc_freq, 
       mapping = aes(x = year, y = count, col = as_factor(lc))) + 
  geom_line() + 
  labs(x = "Year", y = "Pixels", col = "Land cover class") +
  # facet_wrap(vars(site), scales = "free") + 
  theme(legend.position = "bottom")

```



## Temporal Filtering: land cover maps
```{r explore-tmp-filter}
obj_size(dt)

dt[y1987 > 0, ]

dt <- cc_create_dt()
dt1 <- cc_create_bin() + 1
dt2 <- cc_create_bin() + 2
dt3 <- cc_create_bin() + 3

dt1
dt2
dt3

dt <- rbind(dt1, dt2, dt3)
dt <- dt[, ':='(x = 1:nrow(dt), y = 1:nrow(dt))
                           ][, c("x", "y", paste0("V", 1:15))]

dt[V1 %in% c(2, 3)]



5:(ncol(dt) - 2)
i <- 9


# new filter:

dt <- fread(input = paste0(p_dat_derived, "input_data.tables/",
                           site_df$site[9], ".csv"),
            # select = c("x", "y", "y2017"),
            # nrows = 100000
            )

freq_before <- lapply(1987:2017, function(i){
      tmp <- dt[, .N, by = c(paste0("y", i))][,"year" := i]
      names(tmp) <- c("lc", "pixels", "year")
      tmp
    }) %>% bind_rows()

# for loop
tic()
for(lc_class in 1:4) {
  for (i in 5:(ncol(dt) - 2)) {
    dt[get(names(dt)[i-2]) == lc_class &  # subset to 1-1-0-1-1
         get(names(dt)[i-1]) == lc_class & 
         get(names(dt)[i]) %in% c(1:4)[1:4 != lc_class] & 
         get(names(dt)[i+1]) == lc_class & 
         get(names(dt)[i+2]) == lc_class,
       names(dt)[i] := lc_class # update value
    ]
  }
}
toc() # 103.199 seconds for Shaanxi (4.5x to get time for )


freq_after <- lapply(1987:2017, function(i){
      tmp <- dt[, .N, by = c(paste0("y", i))][,"year" := i]
      names(tmp) <- c("lc", "pixels", "year")
      tmp
    }) %>% bind_rows()

bind_rows(
  freq_before %>% as_tibble() %>% mutate(site = "shaanxi", time = "before"),
  freq_after %>% as_tibble() %>% mutate(site = "shaanxi", time = "after")) %>%
  ggplot(mapping = aes(x = year, y = pixels, col = as_factor(lc))) +
  geom_line() + 
  facet_wrap(vars(time))




# 8-year moving window

dt <- data.table(x = "x", y = "x", rbind(
  c(1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1),
  c(1, 1, 1, 1, 2, 3, 3, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1),
  c(2, 3, 3, 2, 2, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1),
  c(2, 3, 3, 2, 2, 2, 3, 3, 2, 2, 2, 1, 2, 1, 1, 1, 1),
  c(4, 1, 1, 1, 3, 3, 1, 1, 3, 3, 3, 1, 1, 3, 3, 3, 4),
  c(4, 1, 1, 1, 4, 3, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1))
)

dt
cc_temporal_filter_lc(dt)
dt

dt[(V1 == 1 & V2 == 1) | (V1 == 4 & V2 == 4), ]
dt[(V1 == 1 & V2 == 1 | V1 == 4 & V2 == 4), ]

i <- 7

for(lc_class in 1:4) {
  blip_values <- c(1:4)[1:4 != lc_class]
  
  for (i in 6:(ncol(dt) - 4)) {
  dt[get(names(dt)[i-3]) == lc_class &
       get(names(dt)[i-2]) == lc_class &
       get(names(dt)[i-1]) == lc_class &
       # .e.g., if lc_class is 1, then these are 
       # (V4 == 2 & V5 == 2) | (V4 == 3 & V5 == 3) | (V4 == 4 & V5 == 4)
       ((get(names(dt)[i]) == blip_values[1] & get(names(dt)[i+1]) == blip_values[1]) | 
          (get(names(dt)[i]) == blip_values[2] & get(names(dt)[i+1]) == blip_values[2]) |
          (get(names(dt)[i]) == blip_values[3] & get(names(dt)[i+1]) == blip_values[3])) &
       get(names(dt)[i+2]) == lc_class &
       get(names(dt)[i+3]) == lc_class &
       get(names(dt)[i+4]) == lc_class, 
     
     c(names(dt)[i], 
       names(dt)[i+1]) := lc_class
     ]
  }
}


```

```{r explore-filtered-results}
# /Users/christophercrawford/work/projects/abandonment_trajectories/data_derived/lc_dt_clean
# /Users/christophercrawford/work/projects/abandonment_trajectories/data_derived/lc_r_clean/shaanxi_clean.tif
```

# Tomorrow
```{r}

```

# Results

```{r load-cluster-results}
run_time <- "_2021_12_05"
aoh_lc_31_files <- list.files(paste0(p_derived, "aoh"), full.names = T) %>% 
  grep(paste0("aoh_tmp", run_time), ., value = T)

aoh_31_df <- lapply(aoh_lc_31_files, read_csv) %>% bind_rows()
aoh_df <- aoh_31_df

# -------------- join IUCN status, common names ------------- #
habitat_details

aoh_df <- aoh_df %>% 
  left_join(select(habitat_details, binomial, redlistCategory), by = "binomial")


missing_sp_31 <- lapply(1:11, function(i){
  sp_run <- aoh_df %>% 
    filter(site == site_df$site[i]) %>%
  select(site:year, adj_IUCN_aoh_ha) %>% unique() %>%
  select(site, binomial) %>% unique()
  
  sp_not_run <- species_list %>% filter(site == site_df$site[i]) %>%
    filter(!binomial %in% sp_run$binomial)
  sp_not_run
}) %>% bind_rows()


# number of species at each site:
species_list %>% 
  group_by(site, 
           vert_class
           ) %>% 
  summarise(num_sp = n())

# number of unique species
species_list %>% 
  group_by(#site, 
           vert_class
           ) %>% 
  summarise(num_sp = n(),
            sp = length(unique(binomial)))
```


```{r prelim-plots}
sp_to_plot <- "Agamia agami"

aoh_df %>%
  filter(binomial == sp_to_plot) %>%
  ggplot(mapping = aes(x = year, y = adj_IUCN_aoh_ha)) +
  geom_line() + 
  labs(x = "Year", y = "AOH (ha)", caption = sp_to_plot)


# -------------- extract just species and yearly aoh ------------- #
aoh_df

aoh_df %>% 
  select(site, binomial, redlistCategory, year, adj_IUCN_aoh_ha) %>% 
  unique() %>% 
  # head(n = 10000) %>%
  filter(binomial == sp_to_plot) %>%
  mutate(binomial = as_factor(binomial)) %>%
  ggplot(mapping = aes(x = year, 
                       y = adj_IUCN_aoh_ha, 
                       group = binomial,
                       col = redlistCategory
                       )) +
  geom_line() + 
  geom_smooth(method = "lm", se = 0.95) + 
  labs(x = "Year", y = "AOH (ha)", title = "All species")


dft <- aoh_df %>% 
  select(site, binomial, redlistCategory, year, adj_IUCN_aoh_ha) %>% 
  unique() %>% 
  mutate(year = year - 1986)
  

dft

# prelim model
tmp_lm <- lm(adj_IUCN_aoh_ha ~ year, data = filter(dft, binomial == sp_to_plot))
tidy(tmp_lm)
glance(tmp_lm)
augment(tmp_lm)


ggplot(data = filter(dft, binomial == sp_to_plot), 
       mapping = aes(x = year, y = adj_IUCN_aoh_ha)) +
  geom_point() + 
  geom_smooth(method = "lm", se = 0.95) + 
  labs(x = "Year", y = "AOH (ha)", title = "All species") + 
  # geom_function(fun = function(x) { (x-4) ^ (mean(coef(lm_log2_l[[9]]), na.rm = TRUE))},
  #               mapping = aes(linetype = "Mean Decay Rate"),
  #               color = "blue", size = 1, #linetype = "dashed", 
  #               inherit.aes = FALSE) 
geom_line(data = augment(tmp_lm), mapping = aes(x = year, y = .fitted), col = "green")


# ---------- calculate trend for all species ---------- #
filter(dft, binomial == sp_to_plot)
tmp_all <- lm(adj_IUCN_aoh_ha ~ year*binomial - 0, 
              data = filter(dft, binomial %in% species_list$binomial[1:5],
                            site == "belarus"))
aoh_lm_df <- tidy(tmp_all)

run_indices <- dft %>%
  left_join(select(species_list, site, binomial, vert_class), by = c("binomial", "site")) %>%
  arrange(site, vert_class, binomial) %>%
  select(site, vert_class, binomial) %>% unique() %>% 
  mutate(run_index = 1:n())

dft <- dft %>%
  left_join(run_indices, by = c("binomial", "site"))

dft$run_index %>% unique() %>% sort() %>% tail
dft %>% select(site, binomial) %>% unique() %>% nrow


# -------------------
# run simple regression on each species' and extract AOH trend over time.
# -------------------
aoh_trends <- lapply(1:length(unique(dft$run_index)), function(i) {
  dft %>% 
    filter(run_index == i) %>%
    lm(adj_IUCN_aoh_ha ~ year, 
       data = .) %>%
    tidy() %>% 
    mutate(run_index = i)
}) %>% bind_rows()

# ------------------
# determine the relative trend
# ------------------
i <- 10
# plot trend for a given species:
dft %>% filter(vert_class != "amp")

dft %>% 
  filter(run_index == i) %>%
  ggplot(mapping = aes(x = year, y = adj_IUCN_aoh_ha)) +
  geom_point() + 
  geom_smooth(method = "lm", se = 0.95) + 
  labs(x = "Year", y = "AOH (ha)", title = unique(filter(dft, run_index == i)$binomial))
  


aoh_change_df <- aoh_trends %>% #filter(run_index == i) %>%
  select(run_index, term, estimate) %>%
  mutate(term = ifelse(term == "(Intercept)", "intercept", "slope")) %>%
  pivot_wider(run_index, names_from = term, values_from = estimate) %>%
  mutate(aoh_start = slope*1 + intercept,
         aoh_end = slope*31 + intercept,
         rel_change = ((aoh_end/aoh_start) - 1))

hist(aoh_change_df$rel_change)
aoh_change_df %>%
  arrange(rel_change) %>%
  filter(rel_change < 5 & rel_change > -1) %>%
  .$rel_change %>%
  hist(breaks = 100)


# ---------- plot histogram ----------- #
aoh_change_df %>% 
  left_join(dft %>% select(run_index, binomial, redlistCategory, vert_class) %>%
              unique(), 
            by = "run_index") %>%
  filter(!is.na(vert_class),
         rel_change < 2 & rel_change > -1) %>%
  ggplot(mapping = aes(x = rel_change)) + 
  geom_histogram(bins = 20
                 ) +
  geom_vline(xintercept = 0, linetype = 2, col = "gray70") +
  theme_classic() +
  facet_wrap(vars(redlistCategory), scales = "free")


dft %>% filter(run_index == i) %>%
  lm(adj_IUCN_aoh_ha ~ year, data = .) %>%
  augment() %>%
  filter(year %in% c(1, 31))


trend_df0 %>% print(n = 35)
trend_df %>% print(n = 30)

# create df of just the increase/decrease trend

trend_df <- aoh_trends %>% 
  left_join(dft %>% 
              select(site, run_index, binomial, redlistCategory, vert_class) %>%
              unique(), 
            by = "run_index") %>%
  filter(term == "year",
         p.value < 0.05,
         !is.na(vert_class)
         # estimate != 0
         ) %>%
  mutate(trend = ifelse(estimate > 0, "gain", "loss")) %>%
  group_by(redlistCategory, trend, vert_class) %>%
  summarise(trend_count = n())

# ----------------------------------- #
# plot the trend per species
# ----------------------------------- #
trend_df %>%
  mutate(y = ifelse(trend == "gain", trend_count, -trend_count))

trend_df %>%
  mutate(y = ifelse(trend == "gain", trend_count, -trend_count)) %>%
  # filter(vert_class) %>%
  
  ggplot(data = ., 
       mapping = aes(x = redlistCategory, 
                     y = trend_count,
                     # group = as_factor(trend), 
                     fill = vert_class,
                     col = vert_class,
                     alpha = as_factor(trend)
                     )) +
  geom_col(
    position = position_dodge2(width = 0.9, preserve = "single")
    # position = position_dodge()
    ) + 
  labs(y = "Number of Species") +
  theme_classic() + 
  scale_alpha_manual(name = "Trend",
                     labels = c("gain" = "Gain",
                                "loss" = "Loss"),
                     values = c("gain" = 1,
                                "loss" = 0.2)
                     ) + 
  facet_wrap(vars(redlistCategory), scales = "free")

# species with zero estimates
zero_index <- aoh_trends %>% 
  filter(estimate == 0) %>%
  .$run_index %>% unique() %>% sort()

aoh_trends %>% filter(run_index %in% zero_index)

dft %>% filter(is.na(vert_class))

# na species:
na_vert <- aoh_df %>% 
  left_join(select(species_list, binomial, vert_class), by = "binomial") %>% 
  filter(is.na(vert_class)) %>%
  select(site, binomial) %>% unique()

species_list %>% filter(binomial %in% na_vert$binomial)


aoh_trends %>% 
  left_join(unique(select(dft, site, binomial, redlistCategory, run_index, vert_class)), 
            by = "run_index") %>%
    filter(estimate == 0)

species_list %>% filter(binomial == "Anthus pratensis")

select(dft, site, binomial, redlistCategory, run_index, vert_class) %>% 
    filter(is.na(vert_class))


# ----------------
# diagnostic plots
i

par(mfrow = c(2,2))
dft %>% 
    filter(run_index == i) %>%
    lm(adj_IUCN_aoh_ha ~ year, 
       data = .) %>% 
  plot(., c(1,2))

#
```

